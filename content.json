{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"changfeng","url":"https://killgc.github.io/shortfeng"},"pages":[],"posts":[{"title":"ReentrantRock","slug":"ReentrantRock","date":"2018-10-21T05:03:23.000Z","updated":"2018-10-21T13:12:18.000Z","comments":true,"path":"2018/10/21/ReentrantRock/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/10/21/ReentrantRock/","excerpt":"","text":"ReentrantRockReentrantRock(可重入锁)分为非公平锁和公平锁，默认为非公平锁,底层通过AQS（AbstractQueueSynchronizer）实现。 公平锁，线程将按照它们发出请求的顺序来获得锁，但在非公平锁上，则允许插队；当一个线程请求非公平锁时，如果在发出请求的同时该锁的状态变为可用，那么这个线程将跳过队列中所有等待线程并获得该锁。在非公平锁上，只有当锁被某个线程持有时，新发出请求的线程才会被放入队列中 ReentrantRock通过继承自AQS的Sync同步器实现锁的功能 12345678910111213141516171819202122232425262728293031public class ReentrantLock implements Lock, java.io.Serializable &#123; private static final long serialVersionUID = 7373984872572414699L; /** Synchronizer providing all implementation mechanics */ private final Sync sync; /** * Creates an instance of &#123;@code ReentrantLock&#125;. * This is equivalent to using &#123;@code ReentrantLock(false)&#125;. */ public ReentrantLock() &#123; sync = new NonfairSync(); &#125; /** * Creates an instance of &#123;@code ReentrantLock&#125; with the * given fairness policy. * * @param fair &#123;@code true&#125; if this lock should use a fair ordering policy */ public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync(); &#125; public void lock() &#123; sync.lock(); &#125; public void unlock() &#123; sync.release(1); &#125; &#125; 抽象类Sync123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; /** * Performs &#123;@link Lock#lock&#125;. The main reason for subclassing * is to allow fast path for nonfair version. */ abstract void lock(); /** * Performs non-fair tryLock. tryAcquire is implemented in * subclasses, but both need nonfair try for trylock method. */ final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don't need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // Methods relayed from outer class final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; final boolean isLocked() &#123; return getState() != 0; &#125; /** * Reconstitutes the instance from a stream (that is, deserializes it). */ private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125; &#125; AQSAQS通过队列实现请求的FIFO（先进先出），AQS的state属性代表锁状态，为0表示锁可次数用，大于0代表锁重入 节点Node的waitStatus的值默认为0，有以下几个状态： 0 默认值，代表当前线程被阻锁 CANCELLED=1 节点代表的线程已被取消 SIGNAL=-1 节点后继节点代表的线程需要唤醒（当线程请求锁被阻锁，需要设置前继节点的waitStatus为-1） CONDITION=-2 节点代表的线程正在等待某个条件 PROPAGATE = -3 代表下一次获取共享锁时，共享锁无条件传播 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; static final class Node &#123; /** Marker to indicate a node is waiting in shared mode */ static final Node SHARED = new Node(); /** Marker to indicate a node is waiting in exclusive mode */ static final Node EXCLUSIVE = null; /** waitStatus value to indicate thread has cancelled */ static final int CANCELLED = 1; /** waitStatus value to indicate successor's thread needs unparking */ static final int SIGNAL = -1; /** waitStatus value to indicate thread is waiting on condition */ static final int CONDITION = -2; /** * waitStatus value to indicate the next acquireShared should * unconditionally propagate */ static final int PROPAGATE = -3; /** * Status field, taking on only the values: * SIGNAL: The successor of this node is (or will soon be) * blocked (via park), so the current node must * unpark its successor when it releases or * cancels. To avoid races, acquire methods must * first indicate they need a signal, * then retry the atomic acquire, and then, * on failure, block. * CANCELLED: This node is cancelled due to timeout or interrupt. * Nodes never leave this state. In particular, * a thread with cancelled node never again blocks. * CONDITION: This node is currently on a condition queue. * It will not be used as a sync queue node * until transferred, at which time the status * will be set to 0. (Use of this value here has * nothing to do with the other uses of the * field, but simplifies mechanics.) * PROPAGATE: A releaseShared should be propagated to other * nodes. This is set (for head node only) in * doReleaseShared to ensure propagation * continues, even if other operations have * since intervened. * 0: None of the above * * The values are arranged numerically to simplify use. * Non-negative values mean that a node doesn't need to * signal. So, most code doesn't need to check for particular * values, just for sign. * * The field is initialized to 0 for normal sync nodes, and * CONDITION for condition nodes. It is modified using CAS * (or when possible, unconditional volatile writes). */ volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; /** * Link to next node waiting on condition, or the special * value SHARED. Because condition queues are accessed only * when holding in exclusive mode, we just need a simple * linked queue to hold nodes while they are waiting on * conditions. They are then transferred to the queue to * re-acquire. And because conditions can only be exclusive, * we save a field by using special value to indicate shared * mode. */ Node nextWaiter; &#125; /** * Head of the wait queue, lazily initialized. Except for * initialization, it is modified only via method setHead. Note: * If head exists, its waitStatus is guaranteed not to be * CANCELLED. */ private transient volatile Node head; /** * Tail of the wait queue, lazily initialized. Modified only via * method enq to add new wait node. */ private transient volatile Node tail; /** * The synchronization state. */ private volatile int state; /** * Acquires in exclusive mode, ignoring interrupts. Implemented * by invoking at least once &#123;@link #tryAcquire&#125;, * returning on success. Otherwise the thread is queued, possibly * repeatedly blocking and unblocking, invoking &#123;@link * #tryAcquire&#125; until success. This method can be used * to implement method &#123;@link Lock#lock&#125;. * * @param arg the acquire argument. This value is conveyed to * &#123;@link #tryAcquire&#125; but is otherwise uninterpreted and * can represent anything you like. */ public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125; /** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; /** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */ private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125; /** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the node * @param arg the acquire argument * @return &#123;@code true&#125; if interrupted while waiting */ final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor();//前继节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125; /** * Checks and updates status for a node that failed to acquire. * Returns true if thread should block. This is the main signal * control in all acquire loops. Requires that pred == node.prev. * * @param pred node's predecessor holding status * @param node the node * @return &#123;@code true&#125; if thread should block */ private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125; /** * Convenience method to park and then check if interrupted * * @return &#123;@code true&#125; if interrupted */ private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted(); &#125; /** * Cancels an ongoing attempt to acquire. * * @param node the node */ private void cancelAcquire(Node node) &#123; // Ignore if node doesn't exist if (node == null) return; node.thread = null; // Skip cancelled predecessors Node pred = node.prev; while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; // If successor needs signal, try to set pred's next-link // so it will get one. Otherwise wake it up to propagate. int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; unparkSuccessor(node); &#125; node.next = node; // help GC &#125; &#125; /** * Queries whether any threads have been waiting to acquire longer * than the current thread. * * &lt;p&gt;An invocation of this method is equivalent to (but may be * more efficient than): * &lt;pre&gt; &#123;@code * getFirstQueuedThread() != Thread.currentThread() &amp;&amp; * hasQueuedThreads()&#125;&lt;/pre&gt; * * &lt;p&gt;Note that because cancellations due to interrupts and * timeouts may occur at any time, a &#123;@code true&#125; return does not * guarantee that some other thread will acquire before the current * thread. Likewise, it is possible for another thread to win a * race to enqueue after this method has returned &#123;@code false&#125;, * due to the queue being empty. * * &lt;p&gt;This method is designed to be used by a fair synchronizer to * avoid &lt;a href=\"AbstractQueuedSynchronizer#barging\"&gt;barging&lt;/a&gt;. * Such a synchronizer's &#123;@link #tryAcquire&#125; method should return * &#123;@code false&#125;, and its &#123;@link #tryAcquireShared&#125; method should * return a negative value, if this method returns &#123;@code true&#125; * (unless this is a reentrant acquire). For example, the &#123;@code * tryAcquire&#125; method for a fair, reentrant, exclusive mode * synchronizer might look like this: * * &lt;pre&gt; &#123;@code * protected boolean tryAcquire(int arg) &#123; * if (isHeldExclusively()) &#123; * // A reentrant acquire; increment hold count * return true; * &#125; else if (hasQueuedPredecessors()) &#123; * return false; * &#125; else &#123; * // try to acquire normally * &#125; * &#125;&#125;&lt;/pre&gt; * * @return &#123;@code true&#125; if there is a queued thread preceding the * current thread, and &#123;@code false&#125; if the current thread * is at the head of the queue or the queue is empty * @since 1.7 */ public final boolean hasQueuedPredecessors() &#123; // The correctness of this depends on head being initialized // before tail and on head.next being accurate if the current // thread is first in queue. Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; /** * Releases in exclusive mode. Implemented by unblocking one or * more threads if &#123;@link #tryRelease&#125; returns true. * This method can be used to implement method &#123;@link Lock#unlock&#125;. * * @param arg the release argument. This value is conveyed to * &#123;@link #tryRelease&#125; but is otherwise uninterpreted and * can represent anything you like. * @return the value returned from &#123;@link #tryRelease&#125; */ public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false; &#125; /** * Wakes up node's successor, if one exists. * * @param node the node */ private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread); &#125; &#125; 非公平锁123456789101112131415161718static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; /** * Performs lock. Try immediate barge, backing up to normal * acquire on failure. */ final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 请求线程首先通过cas获取锁，当锁状态为0，获取锁成功，把锁状态变成1（锁定状态），并把当前线程设置为独占锁拥有线程。如果获取失败，调用AQS的acquire方法，AQS的acquire方法调用子类的tryAcquire方法，tryAcquire方法调用Sync的nonfairTryAcquire重新获取一次锁，如果获取失败，把线程加入队列尾部，把线程加入队列尾部的过程，有可能锁已释放，需要再次尝试获取一次锁，如果还是获取失败，把通过LockSupport.park把当前线程阻塞 公平锁12345678910111213141516171819202122232425262728293031static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(\"Maximum lock count exceeded\"); setState(nextc); return true; &#125; return false; &#125;&#125; 首先判断锁是否可用，如果可用，调用AQS的hasQueuedPredecessors方法得到没有等待线程且cas修改锁状态成功如果不可用，判断当前线程是否与当前锁独占线索是否相同，如果相同，锁获取成功（重入）","categories":[],"tags":[]},{"title":"解决方案","slug":"解决方案","date":"2018-09-05T15:06:00.000Z","updated":"2018-09-05T15:15:46.000Z","comments":true,"path":"2018/09/05/解决方案/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/09/05/解决方案/","excerpt":"","text":"解决方案1、某天在同一商店购买三种以上商品的用户 123456789表tbl_purchase：用户id user_id商店id shop_id商品id commodity_id购买数量 purchase_num单价 priceselect a.user_id from tbl_purchase a group by a.user_id,a.shop_id,DATE_FORMAT(date,'%Y-%m-%d') having count(DISTINCT(a.commodity_id))&gt;=3 2、支付幂等性 3、对账 1234上游下发的对账文件读取对账文件入库到数据库表从入库的数据按业务类型导入中间表与本地数据库数据对账","categories":[],"tags":[]},{"title":"spring事务实践","slug":"spring事务实践","date":"2018-08-31T03:04:12.000Z","updated":"2018-08-31T08:09:47.000Z","comments":true,"path":"2018/08/31/spring事务实践/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/08/31/spring事务实践/","excerpt":"","text":"spring事务实践事务隔离级别为REQUIRED的方法中不能抛出异常，抛出异常就会导致事务回滚，如果对异常进行try catch处理，就不会导致事务回滚 12345678910111213141516171819提交 @Transactional public void testTransaction()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); try&#123; throw new RuntimeException(\"xx\"); &#125;catch (Exception ex)&#123; log.error(\"出现异常\",ex); &#125; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); &#125; 12345678910111213141516171819202122回滚@Transactionalpublic void testTransaction()&#123; updateAdmittanceApplyRecord(); updateAdmittanceApplyCompanyInfo();&#125;public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\");&#125; 123456789101112131415161718192021222324252627提交@Transactionalpublic void testTransaction()&#123; updateAdmittanceApplyRecord(); try &#123; updateAdmittanceApplyCompanyInfo(); &#125;catch (Exception ex)&#123; &#125;&#125;public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\");&#125; 12345678910111213141516171819202122232425262728回滚@Transactional(propagation = Propagation.REQUIRED) public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); try &#123; self.updateAdmittanceApplyCompanyInfo(); &#125;catch (Exception ex)&#123; &#125; &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\"); &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273 回滚 @Transactional(propagation = Propagation.REQUIRED) public void testTransaction()&#123; try &#123; self.updateAdmittanceApplyRecord(); &#125;catch (Exception ex)&#123; &#125; self.updateAdmittanceApplyCompanyInfo(); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); throw new RuntimeException(\"xx\"); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); &#125; 异常信息：org.springframework.transaction.UnexpectedRollbackException: Transaction rolled back because it has been marked as rollback-only at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:724) at org.springframework.transaction.interceptor.TransactionAspectSupport.commitTransactionAfterReturning(TransactionAspectSupport.java:518) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:292) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:96) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:92) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:673) at com.mhc.spyker.core.biz.service.impl.AdmittanceApplyServiceImpl$$EnhancerBySpringCGLIB$$e5ad53cb.testTransaction(&lt;generated&gt;) at com.mhc.spyker.core.biz.facade.AdmittanceCommitFacadeImpl.getApplyInfo(AdmittanceCommitFacadeImpl.java:108) at com.alibaba.dubbo.common.bytecode.Wrapper19.invokeMethod(Wrapper19.java) at com.alibaba.dubbo.rpc.proxy.javassist.JavassistProxyFactory$1.doInvoke(JavassistProxyFactory.java:45) at com.alibaba.dubbo.rpc.proxy.AbstractProxyInvoker.invoke(AbstractProxyInvoker.java:71) at com.alibaba.dubbo.config.invoker.DelegateProviderMetaDataInvoker.invoke(DelegateProviderMetaDataInvoker.java:48) at com.alibaba.dubbo.rpc.protocol.InvokerWrapper.invoke(InvokerWrapper.java:52) at com.alibaba.dubbo.rpc.filter.ExceptionFilter.invoke(ExceptionFilter.java:61) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.monitor.support.MonitorFilter.invoke(MonitorFilter.java:64) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.TimeoutFilter.invoke(TimeoutFilter.java:41) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.filter.TraceFilter.invoke(TraceFilter.java:77) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.ContextFilter.invoke(ContextFilter.java:71) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.GenericFilter.invoke(GenericFilter.java:131) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.ClassLoaderFilter.invoke(ClassLoaderFilter.java:37) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.filter.EchoFilter.invoke(EchoFilter.java:37) at com.alibaba.dubbo.rpc.protocol.ProtocolFilterWrapper$1.invoke(ProtocolFilterWrapper.java:68) at com.alibaba.dubbo.rpc.protocol.dubbo.DubboProtocol$1.reply(DubboProtocol.java:98) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.handleRequest(HeaderExchangeHandler.java:96) at com.alibaba.dubbo.remoting.exchange.support.header.HeaderExchangeHandler.received(HeaderExchangeHandler.java:168) at com.alibaba.dubbo.remoting.transport.DecodeHandler.received(DecodeHandler.java:50) at com.alibaba.dubbo.remoting.transport.dispatcher.ChannelEventRunnable.run(ChannelEventRunnable.java:79) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185第一个更新提交，第二回滚 @Transactional(propagation = Propagation.REQUIRED) public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); try &#123; self.updateAdmittanceApplyCompanyInfo(); &#125;catch (Exception ex)&#123; &#125; &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); &#125; @Transactional(propagation = Propagation.REQUIRES_NEW) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\"); &#125; 两个都回滚 @Transactional(propagation = Propagation.REQUIRED) public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); &#125; @Transactional(propagation = Propagation.REQUIRES_NEW) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\"); &#125; 第一个提交，第二个回滚 //@Transactional(propagation = Propagation.REQUIRED) public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); &#125; @Transactional(propagation = Propagation.REQUIRES_NEW) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\"); &#125; 两个都不提交 //@Transactional(propagation = Propagation.REQUIRED) public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); throw new RuntimeException(\"xx\"); &#125; @Transactional(propagation = Propagation.REQUIRES_NEW) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); &#125; 第一个提交、第二个回滚 public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\"); &#125; 两个都提交成功 public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); &#125; @Transactional(propagation = Propagation.NOT_SUPPORTED) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); &#125; 两个都提交成功 public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); &#125; @Transactional(propagation = Propagation.NOT_SUPPORTED) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\"); &#125; 1234567891011121314151617181920212223242526272829303132333435都回滚了@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.middle();&#125;@Transactional(propagation = Propagation.REQUIRED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(17L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;public void middle()&#123; try &#123; self.updateAdmittanceApplyCompanyInfo(); &#125;catch (Exception ex)&#123; &#125;&#125;@Transactional(propagation = Propagation.REQUIRED)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\");&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960两个更新都提交 @Transactional(propagation = Propagation.REQUIRED) public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); try&#123; throw new RuntimeException(); &#125;catch (Exception ex)&#123; &#125; &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); &#125; @Transactional(propagation = Propagation.SUPPORTS) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); &#125; 两个都回滚 @Transactional(propagation = Propagation.REQUIRED) public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); try &#123; self.updateAdmittanceApplyCompanyInfo(); &#125;catch (Exception ex)&#123; &#125; &#125; @Transactional(propagation = Propagation.REQUIRED) public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); &#125; @Transactional(propagation = Propagation.SUPPORTS) public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\"); &#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182第一个事务提交成功，第二个事务回滚public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo();&#125;@Transactional(propagation = Propagation.REQUIRED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;@Transactional(propagation = Propagation.MANDATORY)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo);&#125;两个都回滚@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); try &#123; self.updateAdmittanceApplyCompanyInfo(); &#125;catch (Exception ex)&#123; &#125;&#125;@Transactional(propagation = Propagation.REQUIRED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;@Transactional(propagation = Propagation.MANDATORY)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\");&#125;第一个提交成功、第二个抛出异常回滚@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); try &#123; self.updateAdmittanceApplyCompanyInfo(); &#125;catch (Exception ex)&#123; log.error(\"异常\",ex); &#125;&#125;@Transactional(propagation = Propagation.REQUIRED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;@Transactional(propagation = Propagation.NEVER)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247第一个提交、第二个回滚@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); try &#123; self.updateAdmittanceApplyCompanyInfo(); &#125;catch (Exception ex)&#123; log.error(\"异常\",ex); &#125;&#125;@Transactional(propagation = Propagation.REQUIRED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\");&#125;两个回滚@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo();&#125;@Transactional(propagation = Propagation.REQUIRED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\");&#125;两个回滚@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); throw new RuntimeException(\"xx\");&#125;@Transactional(propagation = Propagation.REQUIRED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo);&#125;两个都回滚@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; try &#123; self.updateAdmittanceApplyRecord(); &#125;catch (Exception ex)&#123; log.error(\"异常\",ex); &#125; self.updateAdmittanceApplyCompanyInfo();&#125;@Transactional(propagation = Propagation.REQUIRED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); throw new RuntimeException(\"xx\");&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo);&#125;第一个回滚，第二个提交@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; try &#123; self.updateAdmittanceApplyRecord(); &#125;catch (Exception ex)&#123; log.error(\"异常\",ex); &#125; self.updateAdmittanceApplyCompanyInfo();&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record); throw new RuntimeException(\"xx\");&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo);&#125;第一个提交，第二个回滚@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); try &#123; self.updateAdmittanceApplyCompanyInfo(); &#125;catch (Exception ex)&#123; log.error(\"异常\",ex); &#125;&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo); throw new RuntimeException(\"xx\");&#125;两个回滚@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); throw new RuntimeException(\"xx\");&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo);&#125;两个提交@Transactional(propagation = Propagation.REQUIRED)public void testTransaction()&#123; self.updateAdmittanceApplyRecord(); self.updateAdmittanceApplyCompanyInfo(); try &#123; throw new RuntimeException(\"xx\"); &#125;catch (Exception ex)&#123; &#125;&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyRecord()&#123; AdmittanceApplyRecord record = new AdmittanceApplyRecord(); record.setId(18L); record.setPartnerName(\"test\"); admittanceApplyRecordManager.updateById(record);&#125;@Transactional(propagation = Propagation.NESTED)public void updateAdmittanceApplyCompanyInfo()&#123; AdmittanceApplyCompanyInfo companyInfo = new AdmittanceApplyCompanyInfo(); companyInfo.setId(90L); companyInfo.setPartnerId(88L); admittanceApplyCompanyInfoManager.updateById(companyInfo);&#125;","categories":[],"tags":[]},{"title":"性能优化","slug":"性能优化","date":"2018-08-29T07:21:43.000Z","updated":"2018-08-29T08:49:39.000Z","comments":true,"path":"2018/08/29/性能优化/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/08/29/性能优化/","excerpt":"","text":"性能优化一、for、foreach foreach为java语法糖，通过编译生成代码，通过iterator迭代器遍历如果需要遍历的集合为数组，生成与for一样的遍历方式 for适合数组，可以通过下标访问的对象，如：ArrayList；不适合LinkedListforeach性能比较平均 123456789101112for:for(int i=0; i&lt;list.size; i++)&#123;//.....&#125;foreach:List&lt;String&gt; list = new ArrayList&lt;String&gt;();for(String e : list)&#123;//&#125;list.foreach(item-&gt;&#123;int xx=item;&#125;)","categories":[],"tags":[]},{"title":"环境","slug":"环境","date":"2018-08-17T01:51:46.000Z","updated":"2018-08-17T01:55:01.000Z","comments":true,"path":"2018/08/17/环境/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/08/17/环境/","excerpt":"","text":"环境线上环境12345678910mini域名：https://b.maihaoche.com登陆接口地址：https://b.maihaoche.com/v5/auth/login.json登陆接口参数:&#123; &quot;mobile&quot;: &quot;18668170850&quot;, &quot;password&quot;: &quot;83994669b1d5fce39883daf9767e5622&quot;, &quot;imei&quot;: &quot;1399C6BC-3638-4909-8054-E195672FC0DB&quot;&#125;","categories":[],"tags":[]},{"title":"java可见性","slug":"java可见性","date":"2018-08-14T07:47:13.000Z","updated":"2018-08-14T08:52:10.000Z","comments":true,"path":"2018/08/14/java可见性/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/08/14/java可见性/","excerpt":"","text":"java可见性简要的给出JavaCore里面的总结： private：仅对本类是可见的； public：对所有类都是可见的； protected：对本包(package)及所有子类是可见的； friendly：对本包内的所有类是可见的 1、类可见性 在java中类只可被public修饰，或者被默认为包可见性（即不被修饰时），且java中类不可被private，protect修饰符修饰（这是与c++不同的） public修饰类时，说明该类可被任意类访问（实例化，继承，实现）当类不被修饰时，即自动默认为包可见时，意味着该类只能被处于同一个包中的类访问，处于其所属包中的子包中的类是不可以访问的它的。 2、类成员可见性 public修饰类成员时，表明该成员可以通过该类的任意对象进行显示的调用 private修饰类成员时，该成员只能被该类中的实例域，或者类方法调用，不可通过该类对象在外界(即非类定义区)进行显示的调用 当用protected修饰类成员时，该成员可被其所属类的子类以及与其所属类处于同一包中的其他类所访问 不修饰，该成员可被与其所属类处于同一包中的其他类所访问 3、方法重写 方法的重写规则 参数列表必须完全与被重写方法的相同； 返回类型必须完全与被重写方法的返回类型相同； 访问权限不能比父类中被重写的方法的访问权限更低。例如：如果父类的一个方法被声明为public，那么在子类中重写该方法就不能声明为protected。 父类的成员方法只能被它的子类重写。 声明为final的方法不能被重写。 声明为static的方法不能被重写，但是能够被再次声明。 子类和父类在同一个包中，那么子类可以重写父类所有方法，除了声明为private和final的方法。 子类和父类不在同一个包中，那么子类只能够重写父类的声明为public和protected的非final方法。 重写的方法能够抛出任何非强制异常，无论被重写的方法是否抛出异常。但是，重写的方法不能抛出新的强制性异常，或者比被重写方法声明的更广泛的强制性异常，反之则可以。 构造方法不能被重写。 如果不能继承一个方法，则不能重写这个方法。 可以重写静态方法，但重写后的静态方法不支持多态。 其实static根本就没有重写之说。static方法引用的时候应该用类名来引用，而不是对象。同时static方法不参与继承，所以在继承体系里面也不存在重载的说法。 静态的方法可以被继承，但是不能重写。如果父类中有一个静态的方法，子类也有一个与其方法名，参数类型，参数个数都一样的方法，并且也有static关键字修饰，那么该子类的方法会把原来继承过来的父类的方法隐藏，而不是重写。通俗的讲就是父类的方法和子类的方法是两个没有关系的方法，具体调用哪一个方法是看是哪个对象的引用；这种父子类方法也不在存在多态的性质。 java不推荐用对象调用static方法,这会使人混淆,请大家注意。 这也是为什么abstract修饰的method是不可同时是static的原因： abstract修饰方法，子类需要重写去实现，主要用于各个子类的实例对象；static修饰方法，则方法不属于某个对象，属于class，可用class名.方法名（），进行调用； 简单的说abstract实例对象；而static属于类。所以static方法不能是abstract方法 4、抽象与接口的区别从语法层次和编程角度来区分它们之间的关系，这些都是低层次的，要真正使用好抽象类和接口，我们就必须要从较高层次来区分了。只有从设计理念的角度才能看出它们的本质所在。一般来说他们存在如下三个不同点： 1、 抽象层次不同。抽象类是对类抽象，而接口是对行为的抽象。抽象类是对整个类整体进行抽象，包括属性、行为，但是接口却是对类局部（行为）进行抽象。 2、 跨域不同。抽象类所跨域的是具有相似特点的类，而接口却可以跨域不同的类。我们知道抽象类是从子类中发现公共部分，然后泛化成抽象类，子类继承该父类即可，但是接口不同。实现它的子类可以不存在任何关系，共同之处。例如猫、狗可以抽象成一个动物类抽象类，具备叫的方法。鸟、飞机可以实现飞Fly接口，具备飞的行为，这里我们总不能将鸟、飞机共用一个父类吧！所以说抽象类所体现的是一种继承关系，要想使得继承关系合理，父类和派生类之间必须存在&quot;is-a&quot; 关系，即父类和派生类在概念本质上应该是相同的。对于接口则不然，并不要求接口的实现者和接口定义在概念本质上是一致的， 仅仅是实现了接口定义的契约而已。 3、 设计层次不同。对于抽象类而言，它是自下而上来设计的，我们要先知道子类才能抽象出父类，而接口则不同，它根本就不需要知道子类的存在，只需要定义一个规则即可，至于什么子类、什么时候怎么实现它一概不知。比如我们只有一个猫类在这里，如果你这是就抽象成一个动物类，是不是设计有点儿过度？我们起码要有两个动物类，猫、狗在这里，我们在抽象他们的共同点形成动物抽象类吧！所以说抽象类往往都是通过重构而来的！但是接口就不同，比如说飞，我们根本就不知道会有什么东西来实现这个飞接口，怎么实现也不得而知，我们要做的就是事前定义好飞的行为接口。所以说抽象类是自底向上抽象而来的，接口是自顶向下设计出来的。 附：http://blog.51cto.com/qsjming/749100","categories":[],"tags":[]},{"title":"SpringEL","slug":"SpringEL","date":"2018-08-06T07:51:15.000Z","updated":"2018-08-06T07:58:13.000Z","comments":true,"path":"2018/08/06/SpringEL/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/08/06/SpringEL/","excerpt":"","text":"SpringEL${}与#{}区别12345678910111213$&#123;key名称&#125;：1、用户获取外部文件中指定key的值2、可以出现在xml配置文件中，也可以出现在注解@Value中3、获取properties中环境变量#&#123;表达式&#125;：1、SpEL表达式的格式，详情点击[Spring的EL表达式](http://blog.csdn.net/u012834750/article/details/79388294)2、可以出现在xml配置文件中，也可以出现在注解@Value中3、可以任意表达式，支持运算符等在使用的时候也允许#&#123;‘$&#123;key&#125;’&#125;这样使用，比如：@Value(\"#&#123;'$&#123;jdbc.url&#125;'&#125;\")private String jdbcUrl; 12345678910111213141516171819202122232425262728293031323334353637383940@MQConsumer(consumerGroup = \"CONSUMER_DEMO_A\",topic = \"TP_DEMO\",tag = \"A\")public class DemoConsumerA extends AbstractMQPushConsumer&lt;Demo&gt;&#123; @Override public boolean processWithKey(String messageKey, Demo message) &#123; System.out.println(\"DemoConsumerA.processWithKey \"+\"messageKey=【\"+messageKey+\"】,message=【\"+message+\"】\"); return true; &#125;&#125;如果想要在配置文件中配置消息消费者的topic及consumerGroup可以按照以下写法：@MQConsumer(tag = \"A\")public class DemoConsumerA extends AbstractMQPushConsumer&lt;Demo&gt;&#123; @Value(\"$&#123;rocketmq.demoConsumerA.topic&#125;\") private String topic; @Value(\"$&#123;rocketmq.demoConsumerA.consumerGroup&#125;\") private String consumerGroup; @Override public boolean processWithKey(String messageKey, Demo message) &#123; System.out.println(\"DemoConsumerA.processWithKey \"+\"messageKey=【\"+messageKey+\"】,message=【\"+message+\"】\"); try &#123; //模拟业务处理时间 Thread.sleep(50); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return true; &#125;&#125;其中@Value(\"$&#123;rocketmq.demoConsumerA.topic&#125;\")与@Value(\"$&#123;rocketmq.demoConsumerA.consumerGroup&#125;\")对应applicaiton.yml里的如下配置rocketmq: ... demoConsumerA: topic: TP_DEMO consumerGroup: CONSUMER_DEMO_A","categories":[],"tags":[]},{"title":"中间件","slug":"中间件","date":"2018-07-16T15:47:45.000Z","updated":"2018-07-16T15:51:15.000Z","comments":true,"path":"2018/07/16/中间件/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/16/中间件/","excerpt":"","text":"中间件定义：中间件不是最上层的应用，也不是最底层的支撑系统，是处于中间位置的组件。起到桥梁作用，是应用与应用之间的桥梁，也是应用与服务之间的桥梁","categories":[],"tags":[]},{"title":"分布式系统理解","slug":"分布式系统理解","date":"2018-07-15T00:36:16.000Z","updated":"2018-07-15T13:26:58.000Z","comments":true,"path":"2018/07/15/分布式系统理解/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/15/分布式系统理解/","excerpt":"","text":"分布式系统理解CAP简介 C (Consistency) 强一致性系统在执行过某项操作后仍然处于一致的状态。在分布式系统中，更新操作执行成功后所有的用户都应该读到最新的值，这样的系统被认为是具有强一致性的。 等同于所有节点访问同一份最新的数据副本 A (Availability) 可用性每一个操作总是能够在一定的时间内返回结果，这里需要注意的是”一定时间内”和”返回结果”。一定时间指的是，在可以容忍的范围内返回结果，结果可以是成功或者失败 P (Partition tolerance) 分区容忍性理解为在存在网络分区的情况下，仍然可以接受请求（满足一致性和可用性)。这里的网络分区是指由于某种原因，网络被分成若干个孤立的区域，而区域之间互不相通 放弃C.A.P 放弃P：如果想避免分区容错性问题的发生，一种做法是将所有的数据（与事务相关的）都放在一台机器上。虽然无法100%保证系统不会出错，但不会碰到由分区带来的负面效果。当然这个选择会严重的影响系统的扩展性。 放弃A:相对于放弃“分区容错性“来说，其反面就是放弃可用性。一旦遇到分区容错故障，那么受到影响的服务需要等待一定的时间，因此在等待期间系统无法对外提供服务。 放弃C：这里所说的放弃一致性，并不是完全放弃数据一致性，而是放弃数据的强一致性，而保留数据的最终一致性。以网络购物为例，对只剩下一件库存的商品，如果同时接受到了两份订单，那么较晚的订单将被告知商品告罄。 一致性与可用性的决择： 而CAP理论就是说在分布式存储系统中，最多只能实现上面的两点。而由于当前的网络硬件肯定 会出现延迟丢包等问题，所以分区容忍性是我们必须需要实现的。所以我们只能在一致性和可用 性之间进行权衡 流行解释 目前流行的、对CAP理论解释的情形是从同一数据在网络环境中存在多个副本出发为前提的。为了保证数据不会丢失，同时也是为了增加并发访问量（读写分离），在企业级的数据管理方案中，一般必须考虑数据的冗余存储问题，而这应该是通过在网络上的其他独立物理存储节点上保留另一份、或多份数据副本来实现的（如附图所示）。因为在同一个存储节点上的数据冗余明显不能解决单点故障问题，这与通过多节点集群来提供更好的计算可用性的道理是相同的。 如上图的情况，数据在节点A、B、C上保留了三份，如果对节点A上的数据进行了修改，然后再让客户端通过网络对该数据进行读取。那么，客户端的读取操作什么时候返回呢？ 一种情况是要求节点A、B、C的三份数据完全一致后返回。也就是说，这时从任何一个网络节点读取的数据都是一样的，这就是所谓的强一致性读。很明显，这时数据读取的Latency要高一些（因为要等数据在网络中的复制），同时A、B、C三个节点中任何一个宕机，都会导致数据不可用。也就是说，要保证强一致性，网络中的副本越多，数据的可用性就越差。 另一种情况是，允许读操作立即返回，容忍B节点的读取与A节点的读取不一致的情况发生。这样一来，可用性显然得到了提高，网络中的副本也可以多一些，唯一得不到保证的是数据一致性。当然，对写操作同样也有多个节点一致性的情况，在此不再赘述。 可以看出，上述对CAP理论的解释主要是从网络上多个节点之间的读写一致性出发考虑问题的。而这一点，对于关系型数据库意味着什么呢？当然主要是指通常所说的Standby（关于分布式事务，涉及到更多考虑，随后讨论）情况。对此，在实践中我们大多已经采取了弱一致性的异步延时同步方案，以提高可用性。这种情况并不存在关系型数据库为保证C、A而放弃P的情况；而对海量数据管理的需求，关系型数据库扩展过程中所遇到的性能瓶颈，似乎也并不是CAP理论中所描述的那种原因造成的。那么，上述流行的说法中所描述的关系型数据库为保证C、A而牺牲P到底是在指什么呢？ 如果只将CAP当作分布式系统中多个数据副本之间的读写一致性问题的通用理论对待，那么就可以得出结论：CAP既适用于NoSQL数据库，也适用于关系型数据库。它是NoSQL数据库、关系型数据库，乃至一切分布式系统在设计数据多个副本之间读写一致性问题时需要遵循的共同原则。 关于对CAP理论中一致性C的理解，除了上述数据副本之间的读写一致性以外，分布式环境中还有两种非常重要的场景，如果不对它们进行认识与讨论，就永远无法全面地理解CAP，当然也就无法根据CAP做出正确的解释。 分布式场景 1.分布式环境中的事务场景 我们知道，在关系型数据库的事务操作遵循ACID原则，其中的一致性C，主要是指一个事务中相关联的数据在事务操作结束后是一致的。所谓ACID原则，是指在写入/异动资料的过程中，为保证交易正确可靠所必须具备的四个特性：即原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）和持久性（Durability）。 例如银行的一个存款交易事务，将导致交易流水表增加一条记录。同时，必须导致账户表余额发生变化，这两个操作必须是一个事务中全部完成，保证相关数据的一致性。而前文解释的CAP理论中的C是指对一个数据多个备份的读写一致性。表面上看，这两者不是一回事，但实际上，却是本质基本相同的事物：数据请求会等待多个相关数据操作全部完成才返回。对分布式系统来讲，这就是我们通常所说的分布式事务问题。 众所周知，分布式事务一般采用两阶段提交策略来实现，这是一个非常耗时的复杂过程，会严重影响系统效率，在实践中我们尽量避免使用它。在实践过程中，如果我们为了扩展数据容量将数据分布式存储，而事务的要求又完全不能降低。那么，系统的可用性一定会大大降低，在现实中我们一般都采用对这些数据不分散存储的策略。 当然，我们也可以说，最常使用的关系型数据库，因为这个原因，扩展性（分区可容忍性P）受到了限制，这是完全符合CAP理论的。但同时我们应该意识到，这对NoSQL数据库也是一样的。如果NoSQL数据库也要求严格的分布式事务功能，情况并不会比关系型数据库好多少。只是在NoSQL的设计中，我们往往会弱化甚至去除事务的功能，该问题才表现得不那么明显而已。 因此，在扩展性问题上，如果要说关系型数据库是为了保证C、A而牺牲P，在尽量避免分布式事务这一点上来看，应该是正确的。也就是说：关系型数据库应该具有强大的事务功能，如果分区扩展，可用性就会降低；而NoSQL数据库干脆弱化甚至去除了事务功能，因此，分区的可扩展性就大大增加了。 2.分布式环境中的关联场景 初看起来，关系型数据库中常用的多表关联操作与CAP理论就更加不沾边了。但仔细考虑，也可以用它来解释数据库分区扩展对关联所带来的影响。对一个数据库来讲，采用了分区扩展策略来扩充容量，数据分散存储了，很显然多表关联的性能就会下降，因为我们必须在网络上进行大量的数据迁移操作，这与CAP理论中数据副本之间的同步操作本质上也是相同的。 因此，如果要保证系统的高可用性，需要同时实现强大的多表关系操作的关系型数据库在分区可扩展性上就遇到了极大的限制（即使是那些采用了各种优秀解决方案的MPP架构的关系型数据库，如TeraData，Netezza等，其水平可扩展性也是远远不如NoSQL数据库的），而NoSQL数据库则干脆在设计上弱化甚至去除了多表关联操作。那么，从这一点上来理解”NoSQL数据库是为了保证A与P，而牺牲C”的说法，也是可以讲得通的。当然，我们应该理解，关联问题在很多情况下不是并行处理的优点所在，这在很大程度上与Amdahl定律相符合。 所以，从事务与关联的角度来看关系型数据库的分区可扩展性为什么受限的原因是最为清楚的。而NoSQL数据库也正是因为弱化，甚至去除了像事务与关联（全面地讲，其实还有索引等特性）等在分布式环境中会严重影响系统可用性的功能，才获得了更好的水平可扩展性。 那么，如果将事务与关联也纳入CAP理论中一致性C的范畴的话，问题就很清楚了：关于“关系型数据库为了保证一致性C与可用性A，而不得不牺牲分区可容忍性P”的说法便是正确的了。但关于”NoSQL选择了C与P，或者A与P”的说法则是错误的，所有的NoSQL数据库在设计策略的大方向上都是选择了A与P（虽然对同一数据多个副本的读写一致性问题的设计各有不同），从来没有完全选择C与P的情况存在。 现在看来，如果理解CAP理论只是指多个数据副本之间读写一致性的问题，那么它对关系型数据库与NoSQL数据库来讲是完全一样的，它只是运行在分布式环境中的数据管理设施在设计读写一致性问题时需要遵循的一个原则而已，却并不是NoSQL数据库具有优秀的水平可扩展性的真正原因。而如果将CAP理论中的一致性C理解为读写一致性、事务与关联操作的综合，则可以认为关系型数据库选择了C与A，而NoSQL数据库则全都是选择了A与P，但并没有选择C与P的情况存 CAP理论是指多个数据副本之间读写一致性的问题 CAP理论中的一致性C理解为读写一致性、事务与关联操作的综合，则可以认为关系型数据库选择了C与A，而NoSQL数据库则全都是选择了A与P，但并没有选择C与P的情况存在 对于一致性，可以分为从客户端和服务端两个不同的视角。从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。从服务端来看，则是更新如何复制分布到整个系统，以保证数据最终一致。一致性是因为有并发读写才有的问题，因此在理解一致性的问题时，一定要注意结合考虑并发读写的场景 传统的关系型数据库在功能支持上通常很宽泛，从简单的键值查询，到复杂的多表联合查询再到事务机制的支持。而与之不同的是，NoSQL系统通常注重性能和扩展性，而非事务机制（事务就是强一致性的体现） 对于分布式数据系统： N — 数据复制的份数,W — 更新数据是需要保证写完成的节点数,R — 读取数据的时候需要读取的节点数如果W+R&gt;N，写的节点和读的节点重叠，则是强一致性。例如对于典型的一主一备同步复制的关系型数据库，N=2,W=2,R=1，则不管读的是主库还是备库的数据，都是一致的。 如果W+R&lt;=N，则是弱一致性。例如对于一主一备异步复制的关系型数据库，N=2,W=1,R=1，则如果读的是备库，就可能无法读取主库已经更新过的数据，所以是弱一致性。 对于分布式系统，为了保证高可用性，一般设置N&gt;=3。不同的N,W,R组合，是在可用性和一致性之间取一个平衡，以适应不同的应用场景。 如果N=W,R=1，任何一个写节点失效，都会导致写失败，因此可用性会降低，但是由于数据分布的N个节点是同步写入的，因此可以保证强一致性。如果N=R,W=1，只需要一个节点写入成功即可，写性能和可用性都比较高。但是读取其他节点的进程可能不能获取更新后的数据，因此是弱一致性。这种情况下，如果W&lt;(N+1)/2，并且写入的节点不重叠的话，则会存在写冲突。","categories":[],"tags":[]},{"title":"java面试题第五套","slug":"java面试题第五套","date":"2018-07-08T14:05:38.000Z","updated":"2018-07-08T14:06:14.000Z","comments":true,"path":"2018/07/08/java面试题第五套/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/08/java面试题第五套/","excerpt":"","text":"java面试题第五套一、Java相关 乐观悲观锁的设计，如何保证原子性，解决的问题； char和double的字节，以及在内存的分布是怎样； 对象内存布局，然后讲下对象的死亡过程？ 对象头，详细讲下； sync原理详细，sync内抛异常会怎样，死锁吗？还是释放掉？怎么排查死锁？死锁会怎样？有没有什么更好的替代方案？ 详细讲一下集合，HashSet源码，HashMap源码，如果要线程安全需要怎么做？ 多线程是解决什么问题的？线程池解决什么问题？ 线程池，如何设计的，里面的参数有多少种，里面的工作队列和线程队列是怎样的结构，如果给你，怎样设计线程池？ AQS原理，ReentranLock源码，设计原理，整体过程。 继续聊多线程源码，sync原理，然后一个场景设计题； float f = 1.4f;double d = 1.4d; 与 float f = 1.5f;double d = 1.5d; 是否为true，内存是怎样的； split的源码，split(“a|b|c”);得出多少个数组； 把所有认识熟用的JUC( java.util.concurrent(简称JUC)包)下的类写出来，讲下使用，然后讲下原生的线程操作; 开闭原则，解析工厂方法模式，建造者模式，区别。手撸出来。 讲下JVM的大页模式，JVM内存模型; 什么是敏捷开发，防御性编程，并行编程。Team Leader的思考; 逃逸分析是什么，作用是什么，用途是什么; 怎么认为一个类是线程安全？线程安全的定义是什么？Java有多少个关键字进行同步？为什么这样设计？（聊了一大堆，一堆为什么）； 两个线程设计题。记得一个是：t1,t2,t3，让t1，t2执行完才执行t3，原生实现。 写个后缀表达式，为什么要设计后缀表达式，有什么好处？然后写下中缀。 我看你做过性能优化，比如你怎么分析项目里面的OOM的，内存泄露呢？详细说思路; 说下多线程，我们什么时候需要分析线程数，怎么分析，分析什么因素; 抽象方法和类方法的区别，static的抽象方法可以吗？ 说下Java的克隆体系; 涉及OOM、JVM优化、源码问题、数据库优化、多线程等问题; CPU高？什么情况CPU高？解决什么问题？ 你有遇到过临界区问题吗？有遇到过吗？你在项目遇到这个问题是怎样解决的？ volatile关键字作用; Java的多态怎么实现; 解释一下自旋; 解释一下信号量; 什么情况下会触发类加载； Java内存抖动严重，优化的思路； 二、数据库相关 SQL优化思路，联合索引与底层树结构的映像关系，索引结构（B+、B-），为什么用这样的结构； 讲下MySQL的集群？集群遇到过什么问题？sql的优化？ 你目前为止遇到的最大数据量是多少？知道100万时候怎么设计吗？1000万呢？过几十亿呢？ MySQL有多少个参数可调，除了最大连接数。全部列出来，一个个分析。 聊下优化过的索引，怎么优化; 红黑树和平衡树的区别，为什么数据库不用红黑树; mysql有哪些锁，意向锁有什么用; 数据库高并发下的优化思路; 数据库什么情况下索引会失效; 三、数据结构和操作系统相关 数据结构学过吧，聊一下？学过什么结构？讲下树和队列？B树呢？ 操作系统学过吧，聊一下？讲一下系统内存是怎样的？分段分页虚拟内存？ 页面置换算法呢？多少种？有最优的置换算法吗？ 你学过什么课程？然后聊下操作系统，内核、用户之类。 反转链表手撸; 快排，给一串数组，把具体每次patition写下，最终结果也写45, 32, 41, 35, 38, 20, 50; 一个整数status, 判断第K个比特位是否为比特1; 把递归实现的快排改成非递归，你知道非递归有什么好处吗; 举例使用分治思想的算法; 四、网络相关 讲下请求头细节？ Http和Https？Http1.0,1.1,2.0，讲下长连接和短连接？Https是怎样的？如果我篡改了公钥呢？怎么防止？ Get和Post，讲下区别，要我模拟出抓包来。 详细讲下Cookie和Session，Token，OAuth2.0协议; 拥塞算法知道吗？哪些，分别怎样？ 学过计算机网络是吧？socket熟悉吗？对它的读写缓冲区有理解吗？怎么的？那滑动窗口是怎样的？为什么这样设计？ 再聊下Http的Http basic authentication; Https的过程; 五、框架相关 聊下Spring源码，知道多少，都聊一下； 聊下Spring注解，@Autowire，@Resource，以及他们的解析过程； 聊一下架构，接入层架构，服务层架构。聊下技术栈，Spring Boot，Spring Cloud、Docker； Spring ioc的具体优势，和直接New一个对象有什么区别; Servlet生命周期，是否单例，为什么是单例; Spring Mvc初始化过程； 五、分布式相关 多少种RPC框架？ 一致性哈希是干嘛的？ 搭建高并发高可用系统需要怎样设计？考虑哪些东西，有多少说多少。 你对缓存有什么理解？缓存是解决什么问题？后端缓存有哪些，分别解决什么问题？ 聊一下分布式锁； 你是怎么设计系统缓存的，为什么，什么场景； 也来说下，削峰的多种实现，Redis？MQ？ 为什么用mq就能削峰？解决什么问题？ 六、设计题 有几台机器存储着几亿淘宝搜索日志，你只有一台2g的电脑，怎么选出搜索热度最高的十个搜索关键词; 如何设计算法压缩一段URL; 有一个页面能同时展示两个广告，现在有五个广告，设计算法使五个广告展示概率为1:2:3:4:5； 有25匹马，五个赛道，用最少比赛次数将25匹马排序； 七、其他相关 Tomcat缓存，聊下缓存的整体理解，知道多少种缓存； 解释下Mucene原理，倒排索引，怎样进行中文分词，基于什么进行分词； TopN的大数据量题； 你对接入层要思考什么东西？遇到过哪些问题？搭建系统要考量哪些因素？ 然后项目问题，优化问题； 熟悉maven是吧？我们来聊下Maven的源码原理，Maven冲突的时候，怎么选择依赖包，我们怎么查，我们遇到两个不一样的版本，我们应该如何去选择，为什么？ 项目如何分组，性能优化小组应该做哪些; 我们来说下接入层的搭建，认知分析; 问下项目的系统构建，思考，为什么这样构建？ 如何判断一段代码的好坏;","categories":[],"tags":[]},{"title":"java面试题第四套","slug":"java面试题第四套","date":"2018-07-08T14:04:53.000Z","updated":"2018-07-08T14:05:26.000Z","comments":true,"path":"2018/07/08/java面试题第四套/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/08/java面试题第四套/","excerpt":"","text":"java面试题第四套一、Java基础 为什么JVM调优经常会将-Xms和-Xmx参数设置成一样； Java线程池的核心属性以及处理流程； Java内存模型，方法区存什么； CMS垃圾回收过程； Full GC次数太多了，如何优化； 直接内存如何管理的； Java线程池的几个参数的意义和实现机制； Java线程池使用无界任务队列和有界任务队列的优劣对比； CountDownLatch和CyclicBarrier的区别； Java中有哪些同步方案（重量级锁、显式锁、并发容器、并发同步器、CAS、volatile、AQS等） 如果你的项目出现了内存泄露，怎么监控这个问题呢； 标记清除和标记整理的区别和优缺点，为何标记整理会发生stop the world； 线程池，如何根据CPU的核数来设计线程大小，如果是计算机密集型的呢，如果是IO密集型的呢？ 让你设计一个cache如何设计； String中hashcode是怎么实现的； JDK中哪些实现了单例模式？ 多个线程同时读写，读线程的数量远远⼤于写线程，你认为应该如何解决并发的问题？你会选择加什么样的锁？ 线程池内的线程如果全部忙，提交⼀个新的任务，会发⽣什么？队列全部塞满了之后，还是忙，再提交会发⽣什么？ synchronized关键字锁住的是什么东西？在字节码中是怎么表示的？在内存中的对象上表现为什么？ wait/notify/notifyAll⽅法需不需要被包含在synchronized块中？这是为什么？ ExecutorService你一般是怎么⽤的？是每个Service放一个还是个项目放一个？有什么好处？ 二、数据库 InnoDB的插入缓冲和两次写的概率和意义； 如果建了⼀个单列索引，查询的时候查出2列，会⽤到这个单列索引吗？（会用到） 如果建了⼀个包含多个列的索引，查询的时候只⽤了第⼀列，能不能⽤上这个索引？查三列呢？ 接上题，如果where条件后⾯带有⼀个 i + 5 &lt; 100 会使⽤到这个索引吗？ like %aaa%会使⽤索引吗? like aaa%呢? drop、truncate、delete的区别？ 平时你们是怎么监控数据库的? 慢SQL是怎么排查的？（慢查询日志） 你们数据库是否⽀持emoji表情，如果不⽀持，如何操作?选择什么编码方式？如果支持一个表情占几个字节?(utf8mb4)； 如果查询很慢，你会想到的第⼀个⽅式是什么？（数据库索引） 三、Linux基础 Linux下可以在/proc目录下可以查看CPU的核心数等；cat /proc/下边会有很多系统内核信息可供显示； 说一下栈的内存是怎么分配的； Linux各个目录有了解过吗？/etc、/bin、/dev、/lib、/sbin这些常见的目录主要作用是什么？ 说一下栈帧的内存是怎么分配的； Linux下排查某个死循环的线程； 动态链接和静态链接的区别； 进程的内存分布； 如何查找一个进程打开所有的文件； 说一下常使用的协议及其对应的端口； 为什么会有内核态，保护模式你知道吗? 文件是怎么在磁盘上存储的？ 有了进程为何还要线程呢，不同进程和线程他们之间有什么不同。（进程是资源管理的最小单位，线程是程序执行的最小单位。在操作系统设计上，从进程演化出线程，最主要的目的就是更好的支持SMP以及减小（进程/线程）上下文切换开销。） InnoDB聚集索引B+树叶子节点和磁盘什么顺序相同; 文件系统，进程管理和调度，内存管理机制、虚地址保护模式； 四、网络基础 HTTP1.0和HTTP1.1的区别； DHCP如何实现分配IP的； 发现阶段（DHCP客户端在网络中广播发送DHCP DISCOVER请求报文，发现DHCP服务器，请求IP地址租约）、提供阶段（DHCP服务器通过DHCP OFFER报文向DHCP客户端提供IP地址预分配）、选择阶段（DHCP客户端通过DHCP REQUEST报文确认选择第一个DHCP服务器为它提供IP地址自动分配服务）和确认阶段（被选择的DHCP服务器通过DHCP ACK报文把在DHCP OFFER报文中准备的IP地址租约给对应DHCP客户端）。 OSI七层模型，每层都说下自己的理解和知道的，说的越多越好； 五、框架相关 Servlet如何保证单例模式,可不可以编程多例的哪？ Dubbo请求流程以及原理； Spring框架如何实现事务的； 如果一个接⼝有2个不同的实现, 那么怎么来Autowire一个指定的实现？(可以使用Qualifier注解限定要注入的Bean，也可以使用Qualifier和Autowire注解指定要获取的bean，也可以使用Resource注解的name属性指定要获取的Bean) Spring框架中需要引用哪些jar包，以及这些jar包的用途； Spring Boot没有放到web容器⾥为什么能跑HTTP服务？ Spring中循环注入是什么意思，可不可以解决，如何解决； Spring的声明式事务 @Transaction注解⼀般写在什么位置? 抛出了异常会⾃动回滚吗？有没有办法控制不触发回滚? MyBatis怎么防止SQL注入； Tomcat本身的参数你⼀般会怎么调整？ 了解哪几种序列化协议？如何选择合适的序列化协议； Redis渐进式rehash过程？ 比如我有个电商平台，做每日订单的异常检测，服务端代码应该写；","categories":[],"tags":[]},{"title":"java面试题第三套","slug":"java面试题第三套","date":"2018-07-08T14:03:56.000Z","updated":"2018-07-08T14:04:41.000Z","comments":true,"path":"2018/07/08/java面试题第三套/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/08/java面试题第三套/","excerpt":"","text":"java面试题第三套一、基础题 怎么解决Hash冲突；（开放地址法、链地址法、再哈希法、建立公共溢出区等） 写出一个必然会产生死锁的伪代码； Spring IoC涉及到的设计模式；（工厂模式、单利模式。。） toString()方法什么情况下需要重写； 判断对象相等时，什么情况下只需要重写 equals()，什么情况下需要重写 equals(),hashcode()？ Set内存放的元素为什么不可以重复，内部是如何保证和实现的？ 如何保证分布式缓存的一致性(分布式缓存一致性hash算法?)？分布式session实现？ Java 8流式迭代的好处？ 项目中用到的JDK的哪些特性？ 说一下TreeMap的实现原理？红黑树的性质？红黑树遍历方式有哪些？如果key冲突如何解决？setColor()方法在什么时候用？什么时候会进行旋转和颜色转换？ Spring的bean的创建时机？依赖注入的时机？ ArrayList和LinkList的删除一个元素的时间复杂度；（ArrayList是O(N)，LinkList是O(1)）； CopyOnWriteArrayList是什么； 序列化和反序列化底层如何实现的（ObjectOutputStream 、ObjectInputStream、 readObject writeObject）； 如何调试多线程的程序； 一个线程连着调用start两次会出现什么情况？（由于状态只有就绪、阻塞、执行，状态是无法由执行转化为执行的，所以会报不合法的状态！） HashMap在什么时候时间复杂度是O（1），什么时候是O（n），什么时候又是O（logn）； wait方法能不能被重写？（wait是final类型的，不可以被重写，不仅如此，notify和notifyall都是final类型的），wait能不能被中断； 一个Controller调用两个Service，这两Service又都分别调用两个Dao，问其中用到了几个数据库连接池的连接？ 二、网络基础 HTTP、TCP、UDP的区别和联系； TCP和UDP各自的优势，知道哪些使用UDP协议的成功案例； TCP和UDP各用了底层什么协议； 单个UDP报文最大容量； 单个TCP报文最大容量； TCP报头格式、UDP报头格式； Server遭遇SYN Flood应当怎么处理； Web开发中如何防范XSS？ 拆包和粘包的问题，如何解决，如果我们的包没有固定长度的话，我们的应用程序应该如何解决； 三、操作系统 为什么要内存对齐； 为什么会有大端小端，htol这一类函数的作用； top显示出来的系统信息都是什么含义；（重要！） Linux地址空间，怎么样进行寻址的； Linux如何查找目录或者文件的； 四、分布式其他 分库与分表带来的分布式困境与应对之策； Solr如何实现全天24小时索引更新； 五、Redis Redis插槽的分配（key的有效部分使用CRC16算法计算出哈希值，再将哈希值对16384取余，得到插槽值）; Redis主从是怎么选取的（一种是主动切换，另一种是使用sentinel自动方式）; Redis复制的过程; Redis队列应用场景； Redis主节点宕机了怎么办，还有没有同步的数据怎么办; 六、系统设计开放性题目 秒杀系统设计，超卖怎么搞; 你们的图片时怎么存储的，对应在数据库中时如何保存图片的信息的？ 假如成都没有一座消防站，现在问你要建立几座消防站，每个消防站要配多少名消防官兵，多少辆消防车，请你拿出一个方案； 基于数组实现一个循环阻塞队列； 常见的ipv4地址的展现形式如“168.0.0.1”，请实现ip地址和int类型的相互转换。（使用位移的方式） 现网某个服务部署在多台Liunx服务器上，其中一台突然出现CPU 100%的情况，而其他服务器正常，请列举可能导致这种情况发生的原因？如果您遇到这样的情况，应如何定位？内存？CPU？发布？debug？请求量？ 七、大数据量问题（后边会有专题单独讨论） 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？ 海量日志数据，提取出某日访问百度次数最多的那个IP； 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。 此话题后边会有专门的文章探讨，如果有等不及的小伙伴，可以移步参考： 1、https://blog.csdn.net/v_july_v/article/details/6279498 2、https://blog.csdn.net/v_july_v/article/details/7382693 八、逻辑思维题 有两根粗细均匀的香（烧香拜佛的香），每一根烧完都花一个小时，怎么样能够得到15min？ 假定你有8个撞球，其中有1个球比其他的球稍重,如果只能利用天平来断定哪一个球重,要找到较重的球,要称几次?（2次）； 实验室里有1000个一模一样的瓶子，但是其中的一瓶有毒。可以用实验室的小白鼠来测试哪一瓶是毒药。如果小白鼠喝掉毒药的话，会在一个星期的时候死去，其他瓶子里的药水没有任何副作用。请问最少用多少只小白鼠可以在一个星期以内查出哪瓶是毒药；（答案是10只） 假设有一个池塘，里面有无穷多的水。现有2个空水壶，容积分别为5升和6升。问题是如何只用这2个水壶从池塘里取得3升的水；","categories":[],"tags":[]},{"title":"java面试题第二套","slug":"java面试题第二套","date":"2018-07-08T14:02:06.000Z","updated":"2018-07-08T14:03:35.000Z","comments":true,"path":"2018/07/08/java面试题第二套/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/08/java面试题第二套/","excerpt":"","text":"java面试题第二套一、Java相关 Arraylist与LinkedList默认空间是多少； Arraylist与LinkedList区别与各自的优势List 和 Map 区别； 谈谈HashMap，哈希表解决hash冲突的方法； 为什么要重写hashcode()和equals()以及他们之间的区别与关系； Object的hashcode()是怎么计算的？ 若hashcode方法永远返回1或者一个常量会产生什么结果？ Java Collections和Arrays的sort方法默认的排序方法是什么； 引用计数法与GC Root可达性分析法区别； 浅拷贝和深拷贝的区别； String s=”abc”和String s=new String(“abc”)区别； HashSet方法里面的hashcode存在哪，如果重写equals不重写hashcode会怎么样？ 反射的作用与实现原理； Java中的回调机制； 模板方法模式； 开闭原则说一下； 发布/订阅使用场景； KMP算法（一种改进的字符串匹配算法）； JMM里边的原子性、可见性、有序性是如何体现出来的，JMM中内存屏障是什么意思， 二、多线程 AtomicInteger底层实现原理； synchronized与ReentraLock哪个是公平锁； CAS机制会出现什么问题； 用过并发包下边的哪些类； 一个线程连着调用start两次会出现什么情况？ wait方法能不能被重写，wait能不能被中断； 线程池的实现？四种线程池？重要参数及原理？任务拒接策略有哪几种？ 线程状态以及API怎么操作会发生这种转换； 常用的避免死锁方法； 三、JVM Minor GC与Full GC分别在什么时候发生？什么时候触发Full GC; GC收集器有哪些？CMS收集器与G1收集器的特点。 Java在什么时候会出现内存泄漏； Java中的大对象如何进行存储； rt.jar被什么类加载器加载，什么时间加载； 自己写的类被什么加载，什么时间加载； 自己写的两个不同的类是被同一个类加载器加载的吗？为什么？ 为什么新生代内存需要有两个Survivor区？ 几种常用的内存调试工具：jmap、jstack、jconsole； 类加载的五个过程：加载、验证、准备、解析、初始化； G1停顿吗，CMS回收步骤，CMS为什么会停顿，停顿时间； 栈主要存的数据是什么，堆呢？ 堆分为哪几块，比如说新生代老生代，那么新生代又分为什么？ 软引用和弱引用的使用场景（软引用可以实现缓存，弱引用可以用来在回调函数中防止内存泄露）； 四、数据库 数据库索引，什么是全文索引，全文索引中的倒排索引是什么原理； 数据库最佳左前缀原则是什么？ 数据库的三大范式； 悲观锁和乐观锁的原理和应用场景； 左连接、右连接、内连接、外连接、交叉连接、笛卡儿积等； 一般情况下数据库宕机了如何进行恢复（什么是Write Ahead Log机制，什么是Double Write机制，什么是Check Point）； 什么是redo日志、什么是undo日志； 数据库中的隔离性是怎样实现的；原子性、一致性、持久性又是如何实现的； 什么是组合索引，组合索引什么时候会失效； 关系型数据库和非关系型数据库区别； 数据库死锁如何解决； MySQL并发情况下怎么解决（通过事务、隔离级别、锁）； MySQL中的MVCC机制是什么意思，根据具体场景，MVCC是否有问题； MySQL数据库的隔离级别，以及如何解决幻读； 五、缓存服务器 Redis中zSet跳跃表问题； Redis的set的应用场合？ Redis高级特性了解吗？ Redis的pipeline有什么用处？ Redis集群宕机如何处理，怎么样进行数据的迁移； Redis的集群方案； Redis原子操作怎么用比较好； Redis过期策略是怎么实现的呢？ 六、SSM相关 Spring中@Autowired和@Resource注解的区别？ Spring声明一个 bean 如何对其进行个性化定制； MyBatis有什么优势； MyBatis如何做事务管理； 七、操作系统 Linux静态链接和动态链接； 什么是IO多路复用模型（select、poll、epoll）； Linux中的grep管道用处？Linux的常用命令？ 操作系统中虚拟地址、逻辑地址、线性地址、物理地址的概念及区别； 内存的页面置换算法； 内存的页面置换算法； 进程调度算法，操作系统是如何调度进程的； 父子进程、孤儿进程、僵死进程等概念； fork进程时的操作； kill用法，某个进程杀不掉的原因（僵死进程；进入内核态，忽略kill信号）； 系统管理命令（如查看内存使用、网络情况）； find命令、awk使用； Linux下排查某个死循环的线程； 八、网络相关 数据链路层是做什么的? 数据链路层的流量控制？ 网络模型的分层、IP和Mac地址在那个层、TCP和HTTP分别在那个层； TCP滑动窗口； TCP为什么可靠； TCP的同传，拆包与组装包是什么意思； Https和Http有什么区别； Http 为什么是无状态的； TCP三次握手，为什么不是三次，为什么不是四次； TCP的拥塞控制、流量控制详细说明？ Http1.0和Http2.0的区别； 两个不同ip地址的计算机之间如何通信； 地址解析协议ARP； OSI七层模型分别对应着五层模型的哪一部分； TCP三次握手数据丢失了怎么办？那如果后面又找到了呢？ 九、分布式相关 消息队列使用的场景介绍和作用（应用耦合、异步消息、流量削锋等）； 如何解决消息队列丢失消息和重复消费问题； Kafka使用过吗，什么是幂等性？怎么保证一致性，持久化怎么做，分区partition的理解，LEO是什么意思，如何保证多个partition之间数据一致性的（ISR机制），为什么Kafka可以这么快（基于磁盘的顺序读写）； 异步队列怎么实现； 你项目的并发是多少？怎么解决高并发问题？单机情况下Tomcat的并发大概是多少，MySQL的并发大致是多少？ 什么是C10K问题； 高并发情况下怎么办； 分布式理论，什么是CAP理论，什么是Base理论，什么是Paxos理论； 分布式协议的选举算法； 说一下你对微服务的理解，与SOA的区别； Dubbo的基本原理，RPC，支持哪些通信方式，服务的调用过程； Dubbo如果有一个服务挂掉了怎么办； 分布式事务，操作两个表不在一个库，如何保证一致性。 分布式系统中，每台机器如何产生一个唯一的随机值； 系统的量级、pv、uv等； 什么是Hash一致性算法？分布式缓存的一致性，服务器如何扩容（哈希环）； 正向代理、反向代理； 什么是客户端负载均衡策略、什么是服务器端负载均衡策略； 如何优化Tomcat，常见的优化方式有哪些； Nginx的Master和Worker，Nginx是如何处理请求的； 十、系统设计相关 如何防止表单重复提交（Token令牌环等方式）； 有一个url白名单，需要使用正则表达式进行过滤，但是url量级很大，大概亿级，那么如何优化正则表达式？如何优化亿级的url匹配呢？ 常见的Nginx负载均衡策略；已有两台Nginx服务器了，倘若这时候再增加一台服务器，采用什么负载均衡算法比较好？ 扫描二维码登录的过程解析； 如何设计一个生成唯一UUID的算法？ 实现一个负载均衡的算法，服务器资源分配为70%、20%、10%； 有三个线程T1 T2 T3，如何保证他们按顺序执行； 三个线程循环输出ABCABCABC…. 十一、安全相关 什么是XSS攻击，XSS攻击的一般表现形式有哪些？如何防止XSS攻击；","categories":[],"tags":[]},{"title":"java面试题第一套","slug":"java面试题第一套","date":"2018-07-08T13:54:34.000Z","updated":"2018-07-13T15:46:23.000Z","comments":true,"path":"2018/07/08/java面试题第一套/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/08/java面试题第一套/","excerpt":"","text":"java面试题第一套一、基础篇 1.1、Java基础 面向对象的特征：继承、封装和多态 final, finally, finalize 的区别 Exception、Error、运行时异常与一般异常有何异同 请写出5种常见到的runtime exception int 和 Integer 有什么区别，Integer的值缓存范围 包装类，装箱和拆箱 String、StringBuilder、StringBuffer 重载和重写的区别 抽象类和接口有什么区别 说说反射的用途及实现 说说自定义注解的场景及实现 HTTP请求的GET与POST方式的区别 Session与Cookie区别 列出自己常用的JDK包 MVC设计思想 equals与==的区别 hashCode和equals方法的区别与联系 什么是Java序列化和反序列化，如何实现Java序列化？或者请解释Serializable 接口的作用 Object类中常见的方法，为什么wait notify会放在Object里边？ 三个方法都必须在synchronized 同步关键字所限定的作用域中调用，否则会报错java.lang.IllegalMonitorStateException ，意思是因为没有同步，所以线程对对象锁的状态是不确定的，不能调用这些方法 Java的平台无关性如何体现出来的 JDK和JRE的区别 Java 8有哪些新特性 1.2、Java常见集合 List 和 Set 区别 Set和hashCode以及equals方法的联系 List 和 Map 区别 Arraylist 与 LinkedList 区别 ArrayList 与 Vector 区别 HashMap 和 Hashtable 的区别 HashSet 和 HashMap 区别 HashMap 和 ConcurrentHashMap 的区别 HashMap 的工作原理及代码实现，什么时候用到红黑树 多线程情况下HashMap死循环的问题 HashMap出现Hash DOS攻击的问题 ConcurrentHashMap 的工作原理及代码实现，如何统计所有的元素个数 手写简单的HashMap 看过那些Java集合类的源码 1.3、进程和线程 线程和进程的概念、并行和并发的概念 创建线程的方式及实现 进程间通信的方式 说说 CountDownLatch、CyclicBarrier 原理和区别 说说 Semaphore 原理 说说 Exchanger 原理 ThreadLocal 原理分析，ThreadLocal为什么会出现OOM，出现的深层次原理 讲讲线程池的实现原理 线程池的几种实现方式 线程的生命周期，状态是如何转移的 可参考：《Java多线程编程核心技术》1.4、锁机制 说说线程安全问题，什么是线程安全，如何保证线程安全 重入锁的概念，重入锁为什么可以防止死锁 产生死锁的四个条件（互斥、请求与保持、不剥夺、循环等待） 如何检查死锁（通过jConsole检查死锁） volatile 实现原理（禁止指令重排、刷新内存） synchronized 实现原理（对象监视器） synchronized 与 lock 的区别 AQS同步队列 CAS无锁的概念、乐观锁和悲观锁 常见的原子操作类 什么是ABA问题，出现ABA问题JDK是如何解决的 乐观锁的业务场景及实现方式 Java 8并法包下常见的并发类 偏向锁、轻量级锁、重量级锁、自旋锁的概念 可参考：《Java多线程编程核心技术》 1.5、JVM JVM运行时内存区域划分 内存溢出OOM和堆栈溢出SOE的示例及原因、如何排查与解决 如何判断对象是否可以回收或存活 常见的GC回收算法及其含义 常见的JVM性能监控和故障处理工具类：jps、jstat、jmap、jinfo、jconsole等 JVM如何设置参数 JVM性能调优 类加载器、双亲委派模型、一个类的生命周期、类是如何加载到JVM中的 类加载的过程：加载、验证、准备、解析、初始化 强引用、软引用、弱引用、虚引用 Java内存模型JMM 1.6、设计模式 常见的设计模式 设计模式的的六大原则及其含义 常见的单例模式以及各种实现方式的优缺点，哪一种最好，手写常见的单利模式 设计模式在实际场景中的应用 Spring中用到了哪些设计模式 MyBatis中用到了哪些设计模式 你项目中有使用哪些设计模式 说说常用开源框架中设计模式使用分析 动态代理很重要！！！ 1.7、数据结构 树（二叉查找树、平衡二叉树、红黑树、B树、B+树） 深度有限算法、广度优先算法 克鲁斯卡尔算法、普林母算法、迪克拉斯算法 什么是一致性Hash及其原理、Hash环问题 常见的排序算法和查找算法：快排、折半查找、堆排序等 1.8、网络/IO基础 BIO、NIO、AIO的概念 什么是长连接和短连接 Http1.0和2.0相比有什么区别，可参考《Http 2.0》 Https的基本概念 三次握手和四次挥手、为什么挥手需要四次 从游览器中输入URL到页面加载的发生了什么？可参考《从输入URL到页面加载发生了什么》 二、数据存储和消息队列 2.1、数据库 MySQL 索引使用的注意事项 DDL、DML、DCL分别指什么 explain命令 left join，right join，inner join 数据库事物ACID（原子性、一致性、隔离性、持久性） 事物的隔离级别（读未提交、读以提交、可重复读、可序列化读） 脏读、幻读、不可重复读 数据库的几大范式 数据库常见的命令 说说分库与分表设计 分库与分表带来的分布式困境与应对之策（如何解决分布式下的分库分表，全局表？） 说说 SQL 优化之道 MySQL遇到的死锁问题、如何排查与解决 存储引擎的 InnoDB与MyISAM区别，优缺点，使用场景 索引类别（B+树索引、全文索引、哈希索引）、索引的原理 什么是自适应哈希索引（AHI） 为什么要用 B+tree作为MySQL索引的数据结构 聚集索引与非聚集索引的区别 遇到过索引失效的情况没，什么时候可能会出现，如何解决 limit 20000 加载很慢怎么解决 如何选择合适的分布式主键方案 选择合适的数据存储方案 常见的几种分布式ID的设计方案 常见的数据库优化方案，在你的项目中数据库如何进行优化的 2.2、Redis Redis 有哪些数据类型，可参考《Redis常见的5种不同的数据类型详解》 Redis 内部结构 Redis 使用场景 Redis 持久化机制，可参考《使用快照和AOF将Redis数据持久化到硬盘中》 Redis 集群方案与实现 Redis 为什么是单线程的？ 缓存雪崩、缓存穿透、缓存预热、缓存更新、缓存降级 使用缓存的合理性问题 Redis常见的回收策略 2.3、消息队列 消息队列的使用场景 消息的重发补偿解决思路 消息的幂等性解决思路 消息的堆积解决思路 自己如何实现消息队列 如何保证消息的有序性 三、开源框架和容器 3.1、SSM/Servlet Servlet的生命周期 转发与重定向的区别 BeanFactory 和 ApplicationContext 有什么区别 Spring Bean 的生命周期 Spring IOC 如何实现 Spring中Bean的作用域，默认的是哪一个 说说 Spring AOP、Spring AOP 实现原理 动态代理（CGLib 与 JDK）、优缺点、性能对比、如何选择 Spring 事务实现方式、事务的传播机制、默认的事务类别 Spring 事务底层原理 Spring事务失效（事务嵌套），JDK动态代理给Spring事务埋下的坑，可参考《JDK动态代理给Spring事务埋下的坑！》 如何自定义注解实现功能 Spring MVC 运行流程 Spring MVC 启动流程 Spring 的单例实现原理 Spring 框架中用到了哪些设计模式 Spring 其他产品（Srping Boot、Spring Cloud、Spring Secuirity、Spring Data、Spring AMQP 等） 有没有用到Spring Boot，Spring Boot的认识、原理 MyBatis的原理 可参考《为什么会有Spring》 可参考《为什么会有Spring AOP》 3.2、Netty 为什么选择 Netty 说说业务中，Netty 的使用场景 原生的 NIO 在 JDK 1.7 版本存在 epoll bug 什么是TCP 粘包/拆包 TCP粘包/拆包的解决办法 Netty 线程模型 说说 Netty 的零拷贝 Netty 内部执行流程 Netty 重连实现 3.3、Tomcat Tomcat的基础架构（Server、Service、Connector、Container） Tomcat如何加载Servlet的 Pipeline-Valve机制 可参考：《四张图带你了解Tomcat系统架构！》 四、分布式 4.1、Nginx 请解释什么是C10K问题或者知道什么是C10K问题吗？ Nginx简介，可参考《Nginx简介》 正向代理和反向代理. Nginx几种常见的负载均衡策略 Nginx服务器上的Master和Worker进程分别是什么 使用“反向代理服务器”的优点是什么? 4.2、分布式其他 谈谈业务中使用分布式的场景 Session 分布式方案 Session 分布式处理 分布式锁的应用场景、分布式锁的产生原因、基本概念 分布是锁的常见解决方案 分布式事务的常见解决方案 集群与负载均衡的算法与实现 说说分库与分表设计，可参考《数据库分库分表策略的具体实现方案》 分库与分表带来的分布式困境与应对之策 4.3、Dubbo 什么是Dubbo，可参考《Dubbo入门》 什么是RPC、如何实现RPC、RPC 的实现原理，可参考《基于HTTP的RPC实现》 Dubbo中的SPI是什么概念 Dubbo的基本原理、执行流程 五、微服务 5.1、微服务 前后端分离是如何做的？ 微服务哪些框架 Spring Could的常见组件有哪些？可参考《Spring Cloud概述》 领域驱动有了解吗？什么是领域驱动模型？充血模型、贫血模型 JWT有了解吗，什么是JWT，可参考《前后端分离利器之JWT》 你怎么理解 RESTful 说说如何设计一个良好的 API 如何理解 RESTful API 的幂等性 如何保证接口的幂等性 说说 CAP 定理、BASE 理论 怎么考虑数据一致性问题 说说最终一致性的实现方案 微服务的优缺点，可参考《微服务批判》 微服务与 SOA 的区别 如何拆分服务、水平分割、垂直分割 如何应对微服务的链式调用异常 如何快速追踪与定位问题 如何保证微服务的安全、认证 5.2、安全问题 如何防范常见的Web攻击、如何方式SQL注入 服务端通信安全攻防 HTTPS原理剖析、降级攻击、HTTP与HTTPS的对比 5.3、性能优化 性能指标有哪些 如何发现性能瓶颈 性能调优的常见手段 说说你在项目中如何进行性能调优 六、其他 6.1、设计能力 说说你在项目中使用过的UML图 你如何考虑组件化、服务化、系统拆分 秒杀场景如何设计 可参考：《秒杀系统的技术挑战、应对策略以及架构设计总结一二！》6.2、业务工程 说说你的开发流程、如何进行自动化部署的 你和团队是如何沟通的 你如何进行代码评审 说说你对技术与业务的理解 说说你在项目中遇到感觉最难Bug，是如何解决的 介绍一下工作中的一个你认为最有价值的项目，以及在这个过程中的角色、解决的问题、你觉得你们项目还有哪些不足的地方 6.3、软实力 说说你的优缺点、亮点 说说你最近在看什么书、什么博客、在研究什么新技术、再看那些开源项目的源代码 说说你觉得最有意义的技术书籍 工作之余做什么事情、平时是如何学习的，怎样提升自己的能力 说说个人发展方向方面的思考 说说你认为的服务端开发工程师应该具备哪些能力 说说你认为的架构师是什么样的，架构师主要做什么 如何看待加班的问题","categories":[],"tags":[]},{"title":"队列","slug":"队列","date":"2018-07-06T02:26:52.000Z","updated":"2018-07-10T16:10:46.000Z","comments":true,"path":"2018/07/06/队列/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/06/队列/","excerpt":"","text":"队列BlockingQueue 阻塞队列当一个线程试图对一个已经满了的队列进行入队列操作时，它将会被阻塞，除非有另一个线程做了出队列操作；同样，当一个线程试图对一个空队列进行出队列操作时，它将会被阻塞，除非有另一个线程进行了入队列操作，阻塞队列是线程安全的 123456789101112131415161718public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; &#123; boolean add(E e); boolean offer(E e); void put(E e) throws InterruptedException; boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException; E take() throws InterruptedException; E poll(long timeout, TimeUnit unit) throws InterruptedException; boolean remove(Object o);//获取并移除表头元素&#125;public interface Queue&lt;E&gt; extends Collection&lt;E&gt; &#123; E poll();//获取并移除表头元素 E element();//获取表头元素，不移除 E peek();//获取表头元素，不移除&#125; - Throws Exception Special Value Blocks Times Out Insert add(o) offer(o) 返回true or false put(o) offer(o, timeout, timeunit) Remove remove(o) poll() 返回null take() poll(timeout, timeunit) Examine element() peek() 返回null 1234561. ThrowsException：如果操作不能马上进行，则抛出异常2. SpecialValue：如果操作不能马上进行，将会返回一个特殊的值，一般是true或者false3. Blocks:如果操作不能马上进行，操作会被阻塞4. TimesOut:如果操作不能马上进行，操作会被阻塞指定的时间，如果指定时间没执行，则返回一个特殊值，一般是true或者false需要注意的是，我们不能向BlockingQueue中插入null，否则会报NullPointerException。","categories":[],"tags":[]},{"title":"线程池","slug":"线程池","date":"2018-07-04T16:26:18.000Z","updated":"2018-07-10T15:06:23.000Z","comments":true,"path":"2018/07/05/线程池/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/05/线程池/","excerpt":"","text":"线程池Java中的线程池类有两个，分别是：ThreadPoolExecutor和ScheduledThreadPoolExecutor，这两个类都继承自ExecutorService。利用这两个类，可以创建各种不同的Java线程池，为了方便我们创建线程池，Java API提供了Executors工厂类来帮助我们创建各种各样的线程池。 1234567891011public class ThreadPoolExecutor extends AbstractExecutorService public abstract class AbstractExecutorService implements ExecutorService public interface ExecutorService extends Executorpublic interface Executor &#123; void execute(Runnable command);&#125; 123456789101112131415161718192021public class ScheduledThreadPoolExecutor extends ThreadPoolExecutor implements ScheduledExecutorService public interface ScheduledExecutorService extends ExecutorService &#123; public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit); public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit); public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit); &#125; 1、ThreadPoolExecutor 1234567891011121314151617181920212223242526272829303132333435363738 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125;- corePoolSize：线程池维护线程的最少数量- maximumPoolSize：线程池维护线程的最大数量- keepAliveTime： 线程池维护线程所允许的空闲时间- unit： 线程池维护线程所允许的空闲时间的单位- workQueue： 线程池所使用的缓冲队列- handler： 线程池对拒绝任务的处理策略线程数量控制：1. 如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处理被添加的任务。2. 如果此时线程池中的数量等于 corePoolSize，但是缓冲队列 workQueue未满，那么任务被放入缓冲队列。3. 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于maximumPoolSize，建新的线程来处理被添加的任务。4. 如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于maximumPoolSize，那么通过 handler所指定的策略来处理此任务。也就是：处理任务的优先级为：核心线程corePoolSize、任务队列workQueue、最大线程maximumPoolSize，如果三者都满了，使用handler处理被拒绝的任务。5. 当线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。unit 可选的参数为java.util.concurrent.TimeUnit中的几个静态属性：- NANOSECONDS- MICROSECONDS- MILLISECONDS- SECONDSworkQueue：workQueue是一个BlockingQueue，默认是LinkedBlockingQueue&lt;Runnable&gt;handler 是线程池拒绝处理任务的方式，主要有四种类型：ThreadPoolExecutor.AbortPolicy()（系统默认）：抛出java.util.concurrent.RejectedExecutionException异常ThreadPoolExecutor.CallerRunsPolicy()：当抛出RejectedExecutionException异常时，会调用rejectedExecution方法ThreadPoolExecutor.DiscardOldestPolicy()：抛弃旧的任务ThreadPoolExecutor.DiscardPolicy()：抛弃当前的任务 2、ScheduledThreadPoolExecutor 最主要的功能就是可以对其中的任务进行调度，比如延迟执行、定时执行 123456789101112131415161718192021222324252627282930313233public interface ScheduledExecutorService extends ExecutorService &#123; public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit); public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command,long initialDelay, long period, TimeUnit unit); public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command,long initialDelay, long delay,TimeUnit unit);&#125;1、schedule (Callable task, long delay, TimeUnit timeunit)这个方法与schedule (Runnable task)类似，也是在指定延迟之后运行task，不过它接收的是一个Callable实例，此方法会返回一个ScheduleFuture对象，通过ScheduleFuture我们可以取消一个未执行的task，也可以获得这个task的执行结果。2、scheduleAtFixedRate (Runnable, long initialDelay, long period, TimeUnit timeunit)这个方法的作用是周期性的调度task执行。task第一次执行的延迟根据initialDelay参数确定，以后每一次执行都间隔period时长。如果task的执行时间大于定义的period，那么下一个线程将在当前线程完成之后再执行。整个调度保证不会出现一个以上任务同时执行。3、scheduleWithFixedDelay (Runnable, long initialDelay, long period, TimeUnit timeunit)scheduleWithFixedDelay的参数和scheduleAtFixedRate参数完全一致，它们的不同之处在于对period调度周期的解释。在scheduleAtFixedRate中，period指的两个任务开始执行的时间间隔，也就是当前任务的开始执行时间和下个任务的开始执行时间之间的间隔。而在scheduleWithFixedDelay中，period指的当前任务的结束执行时间到下个任务的开始执行时间。4、ScheduledExecutorService的关闭和ExecutorService类似, 我们在使用完ScheduledExecutorService时需要关闭它。如果不关闭的话，JVM会一直运行直，即使所有线程已经关闭了。关闭ScheduledExecutorService可以使用其继承自ExecutorService接口的shutdown()和shutdownNow()方法，两者的区别请参考 1234567ScheduledThreadPoolExecutor继承自ThreadPoolExecutor，构造参数很简单，只有3个： public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler); &#125; 3、Executors 123456789101112131415161718192021222324252627282930313233public class Executors &#123; public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); &#125; public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; public static ScheduledExecutorService newSingleThreadScheduledExecutor() &#123; return new DelegatedScheduledExecutorService (new ScheduledThreadPoolExecutor(1)); &#125; &#125; 12341. newCachedThreadPool 创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。2. newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。3. newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。4. newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。 创建一个什么样的ExecutorService的实例（即线程池）需要我们的具体应用场景而定，不过Java给我们提供了一个Executors工厂类，它可以帮助我们很方便的创建各种类型ExecutorService线程池，Executors一共可以创建下面这四类线程池 备注：Executors只是一个工厂类，它所有的方法返回的都是ThreadPoolExecutor、ScheduledThreadPoolExecutor这两个类的实例。 4、ExecutorService接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public interface ExecutorService extends Executor &#123; void shutdown(); &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125;submit(Runnable)和execute(Runnable)区别是前者可以返回一个Future对象，通过返回的Future对象，我们可以检查提交的任务是否执行完毕 submit(Callable)和submit(Runnable)类似，也会返回一个Future对象，但是除此之外，submit(Callable)接收的是一个Callable的实现，Callable接口中的call()方法有一个返回值，可以返回任务的执行结果，而Runnable接口中的run()方法是void的，没有返回值 invokeAny(...)方法接收的是一个Callable的集合，执行这个方法不会返回Future，但是会返回所有Callable任务中其中一个任务的执行结果。这个方法也无法保证返回的是哪个任务的执行结果，反正是其中的某一个 invokeAll(...)与 invokeAny(...)类似也是接收一个Callable集合，但是前者执行之后会返回一个Future的List，其中对应着每个Callable任务执行后的Future对象 ExecutorService.shutdown()方法。在调用shutdown()方法之后，ExecutorService不会立即关闭，但是它不再接收新的任务，直到当前所有线程执行完成才会关闭，所有在shutdown()执行之前提交的任务都会被执行 如果我们想立即关闭ExecutorService，我们可以调用ExecutorService.shutdownNow()方法。这个动作将跳过所有正在执行的任务和被提交还没有执行的任务。但是它并不对正在执行的任务做任何保证，有可能它们都会停止，也有可能执行完成。Future future = executorService.submit(new Runnable() &#123;public void run() &#123; System.out.println(\"Asynchronous task\");&#125;&#125;);future.get(); //returns null if the task has finished correctly.Future future = executorService.submit(new Callable()&#123;public Object call() throws Exception &#123; System.out.println(\"Asynchronous Callable\"); return \"Callable Result\";&#125;&#125;);System.out.println(\"future.get() = \" + future.get());","categories":[],"tags":[]},{"title":"工作中遇到的问题","slug":"工作中遇到的问题","date":"2018-07-04T15:15:35.000Z","updated":"2018-09-29T12:15:36.000Z","comments":true,"path":"2018/07/04/工作中遇到的问题/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/04/工作中遇到的问题/","excerpt":"","text":"工作中遇到的问题1、架包冲突（经常出现）今天遇到了很奇葩的问题，应用部署到预发环境，报mybatis的某个类的方法不存在，检查应用中的mybatis依赖包中是有该方法的，后面尝试用线上的部署应用程序包部署到预发环境，还是报相同的问题；后面检查mvn依赖包关系图，也没有发现有mybatis的包有多个版本，后面实在没有办法，把应用程序包从服务器上下载下来，检查程序包中lib下面有哪些架包，发现mybatis架包版本是低版本的，后面最终定位是应用依赖的api包中也引入mybatis架包并且版本就是这个低版本。本来线上运行的程序包是好的，后面部署到什么环境都是报相同的错误，最终定位到本应用依赖的api版本是snapshot，该snapshot版本被重新打过，引发该问题。 环境上的各种奇葩的问题，大多数时候可以从架包冲突方面入手 从下面两个方面规避架包冲突： a、不引入api的snapshot版本 b、本地mvn设置每次获取最新的snapshot架包，这样在本地环境启动就能发现。这次在本地环境启动过没有报该错误，是因为没有重新获取snapshot架包对应版本的最新文件，而是使用的之前获取的架包，导致本地未出现该问题。 设置snapshot架包实时更新 always always(实时更新) 2、大视频文件通过dubbo接口传输的问题 大视频文件通过dubbo接口的byte类型参数把文件字节流传到服务，发现会报dubbo最大只支持发送8M数据的错误；dubbo协议是长连接，适合发送小数据，不适合传输大数据 换一种思路解决，先把文件传输到七牛云上，再把七牛云上文件的url地址传入dubbo接口，dubbo接口里面通过url从七牛云中获取，再处理，这样就避免了文件字节流之间在dubbo接口之间传输 3、事务问题 某个带Transactional注解的方法里面有个代码块，通过try catch包入，但是该代码块抛出的异常还是会使整个方法的事物回滚。在方法中的代码有抛出异常，不管有没有做异常处理，都会回滚方法的事务。 4、自定义对象作为Map的key，需要实现自定义对象的equals和hashcode方法 5、.properties文件的中文，在代码里面读取的是乱码，需要使用java native2ascii工具进行编码转换native2ascii -encoding utf-8 6、两次相同查询中间插入数据，第一次查询没有查到数据，第二次查询也没有查到数据 正常结果为第二次查询要能查到数据，导致的原因为mybatis默认针对相同的statementId+sql作为key缓存查询结果，导致第二次查询未到数据执行查询，直接返回缓存中的数据 解决方法，把mapper中的查询statement的useCache设置成false mybatis缓存：（1）、一级缓存 针对sqlsession，相同sqlsession会缓存相同查询的结果（2）、二级缓存 针对mapper，全局sqlsession共享 7、mysqlYou can’t specify target table for update in FROM clause 解决方法：select的结果再通过一个中间表select多一次，就可以避免这个错误 8、service事务方法上有切面，在切面上有对service方法进行try catch，导致方法抛出异常后事务未回滚 解决方法： （1）、在切面处理中不对service方法调用进行try catch （2）、@Order定义service方法的@Transactional注解及切面的执行顺序 9、service（实现接口）实现方法有自定义注解并且有切面，在切面中获取方法签名，导致通过方法签名获取注解获取不到 123456789101112131415161718MethodSignature methodSignature = (MethodSignature) pjp.getSignature();InterfaceLog interfaceLog = methodSignature.getMethod().getAnnotation(InterfaceLog.class);解决方法：（1）private Datasource getDatasource(JoinPoint joinPoint) throws SecurityException,NoSuchMethodException&#123;Method proxyMethod = ((MethodSignature)joinPoint.getSignature()).getMethod();Method soruceMethod = joinPoint.getTarget().getClass().getMethod(proxyMethod.getName(), proxyMethod.getParameterTypes());Datasource datasource = soruceMethod.getAnnotation(Datasource.class);if(datasource!=null)&#123; return datasource ;&#125;datasource = joinPoint.getTarget().getClass().getAnnotation(Datasource.class);return datasource;&#125;（2)、&lt;aop:aspectj-autoproxy proxy-target-class=\"true\"/&gt; 改成动态代理","categories":[],"tags":[]},{"title":"Java-Map","slug":"Java-Map","date":"2018-07-02T16:32:48.000Z","updated":"2018-07-17T01:41:11.000Z","comments":true,"path":"2018/07/03/Java-Map/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/03/Java-Map/","excerpt":"","text":"Map一、LinkedHashMap通过维护一个运行于所有条目的双向链表，LinkedHashMap保证了元素迭代的顺序。该迭代顺序可以是插入顺序或者是访问顺序 HashMap + LinkedList，以LinkedList维护插入或访问的顺序，默认都采用插入顺序来维持取出键值对的次序 1、特点： 非线程安全 Key和Value都允许空 有序 2、底层结构 LinkedHashMap只定义了两个属性: 123456789101112131415/** * The head of the doubly linked list. * 双向链表的头节点 */ private transient Entry&lt;K,V&gt; header;/** * The iteration ordering method for this linked hash map: true * for access-order, false for insertion-order. * true表示最近最少使用次序，false表示插入顺序 */ private final boolean accessOrder; Entry的属性： 1234567891011121、K key2、V value3、Entry&lt;K, V&gt; next4、int hash5、Entry&lt;K, V&gt; before6、Entry&lt;K, V&gt; after 注意该循环双向链表的头部存放的是最久访问的节点或最先插入的节点，尾部为最近访问的或最近插入的节点，迭代器遍历方向是从链表的头部开始到链表尾部结束，在链表尾部有一个空的header节点，该节点不存放key-value内容，为LinkedHashMap类的成员属性，循环双向链表的入口 12345678910111213141516171819public LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) &#123; super(initialCapacity, loadFactor); this.accessOrder = accessOrder;&#125;accessOrder，它表示：（1）false，所有的Entry按照插入的顺序排列（2）true，所有的Entry按照访问的顺序排列\"访问\"，这个词有两层意思：1、根据Key拿到Value，也就是get方法2、修改Key对应的Value，也就是put方法 3、读取 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 通过key获取value，与HashMap的区别是：当LinkedHashMap按访问顺序排序的时候，会将访问的当前节点移到链表尾部(头结点的前一个节点) */public V get(Object key) &#123; // 调用父类HashMap的getEntry()方法，取得要查找的元素。 Entry&lt;K,V&gt; e = (Entry&lt;K,V&gt;)getEntry(key); if (e == null) return null; // 记录访问顺序。 e.recordAccess(this); return e.value;&#125;/** * 在HashMap的put和get方法中，会调用该方法，在HashMap中该方法为空 * 在LinkedHashMap中，当按访问顺序排序时，该方法会将当前节点插入到链表尾部(头结点的前一个节点)，否则不做任何事 */void recordAccess(HashMap&lt;K,V&gt; m) &#123; LinkedHashMap&lt;K,V&gt; lm = (LinkedHashMap&lt;K,V&gt;)m; //当LinkedHashMap按访问排序时 if (lm.accessOrder) &#123; lm.modCount++; //移除当前节点 remove(); //将当前节点插入到头结点前面 addBefore(lm.header); &#125;&#125;/** * 移除节点，并修改前后引用 */private void remove() &#123; before.after = after; after.before = before;&#125;private void addBefore(Entry&lt;K,V&gt; existingEntry) &#123; after = existingEntry; before = existingEntry.before; before.after = this; after.before = this;&#125; 4、put 1234567891011121314151617181920public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); int hash = hash(key.hashCode()); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null;&#125; 二、TreeMap 特点： 1、根据key排序 如果没有指定比较器，则根据key执行自然排序；如果指定了比较器则按照比较器来进行排序 2、 TreeMap继承关系： 123public class TreeMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements NavigableMap&lt;K,V&gt;, Cloneable, java.io.Serializable &#123;&#125; TreeMap属性： 12345678910111213141516171819/** * The comparator used to maintain order in this tree map, or * null if it uses the natural ordering of its keys. * * @serial */private final Comparator&lt;? super K&gt; comparator;private transient Entry&lt;K,V&gt; root;/** * The number of entries in the tree */private transient int size = 0;/** * The number of structural modifications to the tree. */private transient int modCount = 0; Entry节点 123456789static final class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; K key; V value; Entry&lt;K,V&gt; left; Entry&lt;K,V&gt; right; Entry&lt;K,V&gt; parent; boolean color = BLACK; &#125; 三、HashMapHashMap的key和value都能为null，HashTable的key和value都不能为null，HashMap的key为null的元素放在table[0] 当元素个数超过HashMap的阈值，resize扩容为当前容量的两倍 HashMap在并发执行put操作时会引起死循环，是因为多线程会导致HashMap的Entry链表形成环形数据结构，查找时会陷入死循环 resize()方法中的transfer（）方法对旧数组中元素转移到新数组。","categories":[],"tags":[]},{"title":"spring cloud","slug":"spring-cloud","date":"2018-07-01T13:34:56.000Z","updated":"2018-07-01T13:45:15.000Z","comments":true,"path":"2018/07/01/spring-cloud/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/01/spring-cloud/","excerpt":"","text":"spring cloud一、Eureka Netflix 注册中心Eureka [juˈri:kə] 二、Hystrix Netflix 熔断器Hystrix [hɪst’rɪks] 三、Zuul Netflix api网关四、Consul HashiCorp五、Ribbon Netflix 负载均衡Ribbon [ˈrɪbən]","categories":[],"tags":[]},{"title":"git命令","slug":"git命令","date":"2018-07-01T12:27:12.000Z","updated":"2018-10-12T08:54:25.000Z","comments":true,"path":"2018/07/01/git命令/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/07/01/git命令/","excerpt":"","text":"git命令1、推送本地新建的分支 git push –set-upstream origin hotfix/corpname_changfeng_20180629D 2、sourceTree和idea 拉取和提交代码反复提示输入用户名和密码 在命令终端执行以下命令解决git config –global credential.helper store 3、回退git库上已经推送的提交git pullgit reset –hard [commit] [commit]为前一个提交$ git push [remote] –force #强行推送当前分支到远程仓库，即使有冲突 4、提交文件报“0 files committed, 1 file failed to commit”删除.git文件夹中的index.lock 即可","categories":[],"tags":[]},{"title":"mysql优化","slug":"mysql优化","date":"2018-06-27T07:11:35.000Z","updated":"2018-06-27T07:37:43.000Z","comments":true,"path":"2018/06/27/mysql优化/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/06/27/mysql优化/","excerpt":"","text":"mysql优化 1、为查询缓存优化你的查询 // 查询缓存不开启$r = mysql_query(“SELECT username FROM user WHERE signup_date &gt;= CURDATE()”); // 开启查询缓存$today = date(“Y-m-d”);$r = mysql_query(“SELECT username FROM user WHERE signup_date &gt;= ‘$today’”); 2、当只要一行数据时使用 LIMIT 1 3、在Join表的时候使用相当类型的列，并将其索引 如果你的应用程序有很多 JOIN 查询，你应该确认两个表中Join的字段是被建过索引的 4、使用 ENUM 而不是 VARCHAR ENUM 类型是非常快和紧凑的。在实际上，其保存的是 TINYINT，但其外表上显示为字符串 5、尽可能的使用 NOT NULL 6、把IP地址存成 UNSIGNED INT 你可以使用 INET_ATON() 来把一个字符串IP转成一个整形，并使用 INET_NTOA() 把一个整形转成一个字符串IP 7、拆分大的 DELETE 或 INSERT 语句 如果你需要在一个在线的网站上去执行一个大的 DELETE 或 INSERT 查询，你需要非常小心，要避免你的操作让你的整个网站停止相应。因为这两个操作是会锁表的，表一锁住了，别的操作都进不来了。 8、分页limit太大，导致查询慢 limit10000,20的意思扫描满足条件的10020行，扔掉前面的10000行，返回最后的20行 123456日常分页SQL语句select id,name,content from users order by id asc limit 100000,20扫描100020行如果记录了上次的最大IDselect id,name,content from users where id&gt;100073 order by id asc limit 20扫描20行。 12345678优化前： select * from wl_tagindex where byname=&apos;f&apos; order by id limit 300000,10 执行时间是 3.21s优化后：select * from ( select id from wl_tagindex where byname=&apos;f&apos; order by id limit 300000,10) aleft join wl_tagindex b on a.id=b.id","categories":[],"tags":[]},{"title":"java性能优化","slug":"java性能优化","date":"2018-06-25T03:08:00.000Z","updated":"2018-06-25T06:10:58.000Z","comments":true,"path":"2018/06/25/java性能优化/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/06/25/java性能优化/","excerpt":"","text":"java性能优化 1、随机访问使用for循环，顺序访问使用Iterator或foreach实现RandomAccess接口的类实例比如ArrayList，假如是随机访问的，使用普通for循环效率将高于使用foreach循环；反过来，如果是顺序访问的，则使用Iterator会效率更高 foreach循环的底层实现原理就是迭代器Iterator 2、循环内不要不断创建对象引用 例如： 1234for (int i = 1; i &lt;= count; i++)&#123; Object obj = new Object(); &#125; 这种做法会导致内存中有count份Object对象引用存在，count很大的话，就耗费内存了，建议为改为： 12345Object obj = null;for (int i = 0; i &lt;= count; i++)&#123; obj = new Object();&#125; 这样的话，内存中只有一份Object对象引用，每次new Object()的时候，Object对象引用指向不同的Object罢了，但是内存中只有一份，这样就大大节省了内存空间了 3、尽量减少对变量的重复计算 明确一个概念，对方法的调用，即使方法中只有一句语句，也是有消耗的，包括创建栈帧、调用方法时保护现场、调用方法完毕时恢复现场等。所以例如下面的操作： 1234567for (int i = 0; i &lt; list.size(); i++)&#123;...&#125;建议替换为：for (int i = 0, length = list.size(); i &lt; length; i++)&#123;...&#125;这样，在list.size()很大的时候，就减少了很多的消耗 4、如果能估计到待添加的内容长度，为底层以数组方式实现的集合、工具类指定初始长度 比如ArrayList、LinkedLlist、StringBuilder、StringBuffer、HashMap、HashSet等等 5、把一个基本数据类型转为字符串，基本数据类型.toString()是最快的方式、String.valueOf(数据)次之、数据+””最慢 （1）、String.valueOf()方法底层调用了Integer.toString()方法，但是会在调用前做空判断 （2）、Integer.toString()方法就不说了，直接调用了 （3）、i + “”底层使用了StringBuilder实现，先用append方法拼接，再用toString()方法获取字符串 三者对比下来，明显是2最快、1次之、3最慢 6、对资源的close()建议分开操作 12345678910111213141516171819202122232425262728try&#123; XXX.close(); YYY.close();&#125;catch (Exception e)&#123; ...&#125;建议修改为：try&#123; XXX.close();&#125;catch (Exception e)&#123; ...&#125;try&#123; YYY.close();&#125;catch (Exception e)&#123; ...&#125; 7、对于ThreadLocal使用前或者使用后一定要先remove 当前基本所有的项目都使用了线程池技术，这非常好，可以动态配置线程数、可以重用线程。 然而，如果你在项目中使用到了ThreadLocal，一定要记得使用前或者使用后remove一下。这是因为上面提到了线程池技术做的是一个线程重用，这意味着代码运行过程中，一条线程使用完毕，并不会被销毁而是等待下一次的使用。我们看一下Thread类中，持有ThreadLocal.ThreadLocalMap的引用： 123/* ThreadLocal values pertaining to this thread. This map is maintained by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null;线程不销毁意味着上条线程set的ThreadLocal.ThreadLocalMap中的数据依然存在，那么在下一条线程重用这个Thread的时候，很可能get到的是上条线程set的数据而不是自己想要的内容。 这个问题非常隐晦，一旦出现这个原因导致的错误，没有相关经验或者没有扎实的基础非常难发现这个问题，因此在写代码的时候就要注意这一点，这将给你后续减少很多的工作量。","categories":[],"tags":[]},{"title":"Comparable接口、Comparator接口","slug":"Comparable接口与Comparator","date":"2018-06-22T09:36:17.000Z","updated":"2018-06-22T09:38:01.000Z","comments":true,"path":"2018/06/22/Comparable接口与Comparator/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/06/22/Comparable接口与Comparator/","excerpt":"","text":"Comparable接口、Comparator接口 1、元素自身具备比较性 元素自身具备比较性，需要元素实现Comparable接口，重写compareTo方法，也就是让元素自身具备比较性，这种方式叫做元素的自然排序也叫做默认排序 2、容器具备比较性 当元素自身不具备比较性，或者自身具备的比较性不是所需要的。那么此时可以让容器自身具备。需要定义一个类实现接口Comparator，重写compare方法，并将该接口的子类实例对象作为参数传递给TreeMap集合的构造方法。 注意：当Comparable比较方式和Comparator比较方式同时存在时，以Comparator的比较方式为主；","categories":[],"tags":[]},{"title":"跨域问题","slug":"跨域问题","date":"2018-04-04T02:48:32.000Z","updated":"2018-04-04T15:01:36.000Z","comments":true,"path":"2018/04/04/跨域问题/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/04/04/跨域问题/","excerpt":"","text":"跨域问题 同源同源政策的目的，是为了保证用户信息的安全，防止恶意的网站窃取数据 同源是指以下三个信息都必须相同： 协议相同 域名相同 端口相同 如果非同源，共有三种行为受到限制： Cookie、LocalStorage 和 IndexDB 无法读取 DOM 无法获得 AJAX 请求不能发送 虽然这些限制是必要的，但是有时很不方便，合理的用途也受到影响。如何规避上面三种限制 设置document.domain这种方案只适用Cookie与iframe A网页是http://w1.example.com/a.html，B网页是http://w2.example.com/b.html，那么只要设置相同的document.domain，两个网页就可以共享Cookie 1document.domain = 'example.com'; Cookie 是服务器写入浏览器的一小段信息，只有同源的网页才能共享。但是，两个网页一级域名相同，只是二级域名不同，浏览器允许通过设置document.domain共享 Cookie 如果两个网页不同源，就无法拿到对方的DOM。典型的例子是iframe窗口和window.open方法打开的窗口，它们与父窗口无法通信 完全不同源 window.name window.postMessage：HTML5为了解决这个问题，引入了一个全新的API：跨文档通信 API（Cross-document messaging）。这个API为window对象新增了一个window.postMessage方法，允许跨窗口通信，不论这两个窗口是否同源 AJAX： JSONP ： 简单适用，老式浏览器全部支持，服务器改造非常小;网页通过添加一个script元素，向服务器请求JSON数据，这种做法不受同源政策限制；服务器收到请求后，将数据放在一个指定名字的回调函数里传回来 WebSocket：WebSocket是一种通信协议，使用ws://（非加密）和wss://（加密）作为协议前缀。该协议不实行同源政策，只要服务器支持，就可以通过它进行跨源通信 CORS：跨源资源分享（Cross-Origin Resource Sharing）的缩写。它是W3C标准，是跨源AJAX请求的根本解决方法。相比JSONP只能发GET请求，CORS允许任何类型的请求 JSONP例子: 1234567891011121314function addScriptTag(src) &#123; var script = document.createElement('script'); script.setAttribute(\"type\",\"text/javascript\"); script.src = src; document.body.appendChild(script);&#125;window.onload = function () &#123; addScriptTag('http://example.com/ip?callback=foo');&#125;function foo(data) &#123; console.log('Your public IP address is: ' + data.ip);&#125;; X-Frame-Optionsnginx中设置X-Frame-Options ，防止网站被别人用iframe嵌入使用 X-Frame-Options 响应头 X-Frame-Options HTTP 响应头是用来给浏览器指示允许一个页面可否在 iframe 或者 object标签中展现的标记。网站可以使用此功能，来确保自己网站的内容没有被嵌到别人的网站中去，也从而避免了点击劫持 (clickjacking) 的攻击。 X-Frame-Options 有三个值: DENY表示该页面不允许在 frame 中展示，即便是在相同域名的页面中嵌套也不允许。 SAMEORIGIN表示该页面可以在相同域名页面的 frame 中展示。 ALLOW-FROM uri表示该页面可以在指定来源的 frame 中展示。换一句话说，如果设置为 DENY，不光在别人的网站 frame 嵌入时会无法加载，在同域名页面中同样会无法加载。另一方面，如果设置为 SAMEORIGIN，那么页面就可以在同域名页面的 frame 中嵌套。","categories":[],"tags":[]},{"title":"支付","slug":"支付","date":"2018-04-03T16:03:00.000Z","updated":"2018-04-03T16:36:19.000Z","comments":true,"path":"2018/04/04/支付/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/04/04/支付/","excerpt":"","text":"支付系统的思考 支付系统特点： 写多读少，读写分离方案效果不明显 事务强一致性，事务ACID，强调Consistency（一致性）和Availability（可用性），数据库一般用关系数据库。 防重提交策略 乐观锁：通过唯一索引锁住记录（行级锁），UPDATE tab1 SET col1=1,version=version+1 WHERE id=#id# and version=#version# 悲观锁：select * from table_xxx where id=’xxx’ for update，id字段一定是主键或者唯一索引，不然是锁表，悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，根据实际情况选用 防重表：唯一索引导致插入失败 分布式锁：redis分布式锁 Token：分为两步，第一步申请Token，第二步拿申请到Token发起请求。可以设置Token过期时间 支付缓冲：把支付请求快速接下来，后续再启异步任务处理，可以过滤掉重复的支付订单。优点是高吞吐；缺点是不能及时返回处理结果，后续需要监听支付结果的异步返回 状态机：如果状态机已经处于下一个状态，这时候来了一个上一个状态的变更，理论上是不能够变更的","categories":[],"tags":[]},{"title":"redis","slug":"redis","date":"2018-04-01T11:58:26.000Z","updated":"2018-04-01T13:05:09.000Z","comments":true,"path":"2018/04/01/redis/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/04/01/redis/","excerpt":"","text":"Redis Redis持久化 RDB持久化：在指定的时间间隔内生成数据集的时间点快照 AOF持久化：记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾 RDB优点： 适合用于备份 适用于灾难恢复 父进程在保存RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘I/O操作 RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快 缺点： 如果你需要尽量避免在服务器故障时丢失数据，那么 RDB 不适合你。 虽然 Redis 允许你设置不同的保存点（save point）来控制保存 RDB 文件的频率， 但是， 因为RDB 文件需要保存整个数据集的状态， 所以它并不是一个轻松的操作。 因此你可能会至少 5 分钟才保存一次 RDB 文件。 在这种情况下， 一旦发生故障停机， 你就可能会丢失好几分钟的数据 每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失 AOFappend-only file，AOF 优点： 使用 AOF 持久化会让 Redis 变得非常耐久，AOF 的默认策略为每秒钟 fsync 一次 redis-check-aof 工具也可以轻易地修复因为某些原因而包含了未写入完整的命令 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写，整个重写操作是绝对安全的 AOF 文件有序地保存了对数据库执行的所有写入操作，容易被人读懂 缺点： 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 修改配置文件来打开 AOF 功能：appendonly yes 配置 Redis 多久才将数据 fsync 到磁盘一次。有三个选项： 每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。 每秒 fsync 一次：足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据。 从不 fsync ：将数据交给操作系统来处理。更快，也更不安全的选择。推荐（并且也是默认）的措施为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性","categories":[],"tags":[]},{"title":"分布式事务","slug":"分布式事务","date":"2018-03-30T15:40:48.000Z","updated":"2018-04-01T11:49:33.000Z","comments":true,"path":"2018/03/30/分布式事务/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/30/分布式事务/","excerpt":"","text":"分布式事务 事务补偿机制：事务链中的任何一个正向事务操作，都必须存在一个完全符合回滚规则的可逆事务，补偿过程作为一个服务调用过程同样存在调用不成功的情况，这个时候需要通过重试的机制来保证补偿的成功率。当然这也就要求补偿操作本身具备幂等性 柔性事务：分布式事务适用柔性事务 刚性事务：本地事务采用刚性事务 幂等性：不具有幂等性的操作，需要存储操作的执行结果，当执行操作的时候，查询是否已执行过，如果执行过直接返回上一次执行的结果，否则执行操作 重试策略如果只是一味的失败就立即重试会给工作服务造成不必要的压力，我们要根据服务执行失败的原因来选择不同的重试策略 重试操作一般会指定重试次数上线，如果重试次数达到了上限就不再进行重试了。这个时候应该通过一种手段通知相关人员进行处理。 对于等待重试的策略如果重试时仍然错误，可逐渐增加等待的时间，直到达到一个上限后，以上限作为等待时间。 如果某个时刻聚集了大量需要重试的操作，补偿框架需要控制请求的流量，以防止对工作服务造成过大的压力 如果失败的原因不是暂时性的，由于业务因素导致（如业务要素检查失败）的业务错误，这类错误是不会重发就能自动恢复的，那么应该立即终止重试 如果错误的原因是一些罕见的异常，比如因为网络传输过程出现数据丢失或者错误，应该立即再次重试，因为类似的错误一般很少会再次发生 如果错误的原因是系统繁忙（比如http协议返回的500或者另外约定的返回码）或者超时，这个时候需要等待一些时间再重试。 分布式事务实现方案： 两阶段提交(2PC) TCC(Try-Confirm-Cancel) 异步确保型 最大努力通知型 两阶段提交TCC适用场景： 严格一致性 执行时间较短 实时性要求高 异步确保型消息可靠、消息重复消费适用场景： 执行周期较长 实时性要求不高 最大努力通知型","categories":[],"tags":[]},{"title":"Dubbo","slug":"Dubbo","date":"2018-03-27T15:00:36.000Z","updated":"2018-03-29T15:30:32.000Z","comments":true,"path":"2018/03/27/Dubbo/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/27/Dubbo/","excerpt":"","text":"dubbo 循环依赖问题1、check属性 默认check=true：dubbo缺省会在启动时检查依赖的服务是否可用（是否有提供者），不可用时会抛出异常，阻止Spring初始化完成，以便上线时，能及早发现问题 check=false：关闭检查依赖的服务是否可用 以下场景需关闭检查： 出现循环依赖，必须有一方先启动时；或者测试时，有些服务不关心；Spring容器是懒加载或者通过API编程延迟引用服务 123456789101112131415161718192021222324关闭某个服务的启动检查：&lt;dubbo:referenceinterface=\"com.foo.BarService\"check=\"false\"/&gt;关闭所有服务的启动时检查：&lt;dubbo:consumercheck=\"false\"/&gt;关闭注册中心启动时检查：(注册订阅失败时报错)&lt;dubbo:registrycheck=\"false\"/&gt;java -D参数：dubbo.reference.com.foo.BarService.check=falsedubbo.reference.check=falsedubbo.consumer.check=falsedubbo.registry.check=falsedubbo.properties配置：dubbo.reference.com.foo.BarService.check=falsedubbo.reference.check=falsedubbo.consumer.check=falsedubbo.registry.check=false 区别： dubbo.reference.check=false，强制改变所有reference的check值，就算配置中有声明，也会被覆盖。 dubbo.consumer.check=false，是设置check的缺省值，如果配置中有显式的声明，如：，不会受影响。 dubbo.registry.check=false，前面两个都是指订阅成功，但提供者列表是否为空是否报错，如果注册订阅失败时，也允许启动，需使用此选项，将在后台定时重试。 2、init属性 如果需要饥饿加载，即没有人引用也立即生成动态代理，可用配置： 12&lt;dubbo:reference interface=\"com.foo.BarService\" init=\"true\"/&gt; 集群容错集群调用失败时，dubbo提供了多种容错方案，默认为failover重试 各节点关系： 这里的Invoker是Provider的一个可调用Service的抽象，Invoker封装了Provider地址及Service接口信息。 Directory代表多个Invoker，可以把它看成List，但与List不同的是，它的值可能是动态变化的，比如注册中心推送变更。 Cluster将Directory中的多个Invoker伪装成一个Invoker，对上层透明，伪装过程包含了容错逻辑，调用失败后，重试另一个。 Router负责从多个Invoker中按路由规则选出子集，比如读写分离，应用隔离等。 LoadBalance负责从多个Invoker中选出具体的一个用于本次调用，选的过程包含了负载均衡算法，调用失败后，需要重选。 集群容错模式： Failover Cluster：失败自动切换，当出现失败，重试其它服务器。(缺省)，通常用于读操作，但重试会带来更长延迟。可通过retries=”2”来设置重试次数(不含第一次)。 Failfast Cluster：快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。 Failsafe Cluster：失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。 Failback Cluster：失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。 Forking Cluster：并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过forks=”2”来设置最大并行数。 Broadcast Cluster：广播调用所有提供者，逐个调用，任意一台报错则报错。(2.1.0开始支持)，通常用于通知所有提供者更新缓存或日志等本地资源信息。 1234567891011121314151617181920重试次数配置（failover集群模式生效）：&lt;dubbo:serviceretries=\"2\"/&gt;&lt;dubbo:referenceretries=\"2\"/&gt;&lt;dubbo:reference&gt;&lt;dubbo:methodname=\"findFoo\"retries=\"2\"/&gt;&lt;/dubbo:reference&gt;集群模式配置：&lt;dubbo:servicecluster=\"failsafe\"/&gt;&lt;dubbo:referencecluster=\"failsafe\"/&gt; 负载均衡在集群负载均衡时，Dubbo提供了多种均衡策略，缺省为random随机调用。 Random LoadBalance：随机，按权重设置随机概率。在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance轮循，按公约后的权重设置轮循比率。存在慢的提供者累积请求问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive LoadBalance最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance一致性Hash，相同参数的请求总是发到同一提供者。当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 1234缺省只对第一个参数Hash，如果要修改，请配置&lt;dubbo:parameter key=\"hash.arguments\" value=\"0,1\" /&gt;缺省用160份虚拟节点，如果要修改，请配置&lt;dubbo:parameter key=\"hash.nodes\" value=\"320\" /&gt; 1234567891011121314151617&lt;dubbo:service interface=\"...\" loadbalance=\"roundrobin\"/&gt;&lt;dubbo:referenceinterface=\"...\"loadbalance=\"roundrobin\"/&gt;&lt;dubbo:serviceinterface=\"...\"&gt;&lt;dubbo:service interface=\"...\"&gt; &lt;dubbo:method name=\"...\" loadbalance=\"roundrobin\"/&gt;&lt;/dubbo:service&gt;&lt;dubbo:reference interface=\"...\"&gt;&lt;dubbo:method name=\"...\" loadbalance=\"roundrobin\"/&gt;&lt;/dubbo:reference&gt; 线程模型 如果事件处理的逻辑能迅速完成，并且不会发起新的IO请求，比如只是在内存中记个标识，则直接在IO线程上处理更快，因为减少了线程池调度。 但如果事件处理逻辑较慢，或者需要发起新的IO请求，比如需要查询数据库，则必须派发到线程池，否则IO线程阻塞，将导致不能接收其它请求。 如果用IO线程处理事件，又在事件处理过程中发起新的IO请求，比如在连接事件中发起登录请求，会报“可能引发死锁”异常，但不会真死锁。 Dispatcher all 所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等。 direct 所有消息都不派发到线程池，全部在IO线程上直接执行。 message 只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在IO线程上执行。 execution 只请求消息派发到线程池，不含响应，响应和其它连接断开事件，心跳等消息，直接在IO线程上执行。 connection 在IO线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池。 ThreadPool fixed 固定大小线程池，启动时建立线程，不关闭，一直持有。(缺省) cached 缓存线程池，空闲一分钟自动删除，需要时重建。 limited 可伸缩线程池，但池中的线程数只会增长不会收缩。(为避免收缩时突然来了大流量引起的性能问题)。 1234&lt;dubbo:protocol name=\"dubbo\"dispatcher=\"all\"threadpool=\"fixed\"threads=\"100\"/&gt; 直连提供者在开发及测试环境下，经常需要绕过注册中心，只测试指定服务提供者，这时候可能需要点对点直连，点对点直联方式，将以服务接口为单位，忽略注册中心的提供者列表 12345678910111213141516171819配置url指向提供者，将绕过注册中心，多个地址用分号隔开&lt;dubbo:referenceid=\"xxxService\"interface=\"com.alibaba.xxx.XxxService\"url=\"dubbo://localhost:20890\"/&gt;在JVM启动参数中加入-D参数映射服务地址，此配置优先级最高java -Dcom.alibaba.xxx.XxxService=dubbo://localhost:20890 如果服务比较多，也可以用文件映射 用-Ddubbo.resolve.file指定映射文件路径， 此配置优先级高于&lt;dubbo:reference&gt;中的配置 如： java -Ddubbo.resolve.file=xxx.properties 然后在映射文件xxx.properties中加入： com.alibaba.xxx.XxxService=dubbo://localhost:20890 注意为了避免复杂化线上环境，不要在线上使用这个功能，只应在测试阶段使用 只订阅问题为方便开发测试，经常会在线下共用一个所有服务可用的注册中心，这时，如果一个正在开发中的服务提供者注册，可能会影响消费者不能正常运行。 解决方案可以让服务提供者开发方，只订阅服务(开发的服务可能依赖其它服务)，而不注册正在开发的服务，通过直连测试正在开发的服务。 123456789禁用注册配置：&lt;dubbo:registryaddress=\"10.20.153.10:9090\"register=\"false\"/&gt;或者&lt;dubbo:registryaddress=\"10.20.153.10:9090?register=false\"/&gt; 只注册问题如果有两个镜像环境，两个注册中心，有一个服务只在其中一个注册中心有部署，另一个注册中心还没来得及部署，而两个注册中心的其它应用都需要依赖此服务，所以需要将服务同时注册到两个注册中心，但却不能让此服务同时依赖两个注册中心的其它服务。 解决方案可以让服务提供者方，只注册服务到另一注册中心，而不从另一注册中心订阅服务 1234567891011121314151617181920&lt;dubbo:registryid=\"hzRegistry\"address=\"10.20.153.10:9090\"/&gt;&lt;dubbo:registryid=\"qdRegistry\"address=\"10.20.141.150:9090\"subscribe=\"false\"/&gt;或者&lt;dubbo:registryid=\"hzRegistry\"address=\"10.20.153.10:9090\"/&gt;&lt;dubbo:registryid=\"qdRegistry\"address=\"10.20.141.150:9090?subscribe=false\"/&gt; 静态服务有时候希望人工管理服务提供者的上线和下线，此时需将注册中心标识为非动态管理模式 服务提供者初次注册时为禁用状态，需人工启用，断线时，将不会被自动删除，需人工禁用 123456789&lt;dubbo:registryaddress=\"10.20.141.150:9090\"dynamic=\"false\"/&gt;或者&lt;dubbo:registryaddress=\"10.20.141.150:9090?dynamic=false\"/&gt; 多协议(1) 不同服务不同协议 不同服务在性能上适用不同协议进行传输，比如大数据用短连接协议，小数据大并发用长连接协议 123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://code.alibabatech.com/schema/dubbohttp://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;dubbo:application name=\"world\" /&gt; &lt;dubbo:registry id=\"registry\" address=\"10.20.141.150:9090\" username=\"admin\" password=\"hello1234\" /&gt; &lt;!-- 多协议配置 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\" /&gt; &lt;dubbo:protocol name=\"rmi\" port=\"1099\" /&gt; &lt;!-- 使用dubbo协议暴露服务 --&gt; &lt;dubbo:service interface=\"com.alibaba.hello.api.HelloService\" version=\"1.0.0\" ref=\"helloService\" protocol=\"dubbo\" /&gt; &lt;!-- 使用rmi协议暴露服务 --&gt; &lt;dubbo:service interface=\"com.alibaba.hello.api.DemoService\" version=\"1.0.0\" ref=\"demoService\" protocol=\"rmi\" /&gt; &lt;/beans&gt; (2) 多协议暴露服务 consumer.xml 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://code.alibabatech.com/schema/dubbohttp://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;&lt;dubbo:application name=\"world\" /&gt; &lt;dubbo:registry id=\"registry\" address=\"10.20.141.150:9090\" username=\"admin\" password=\"hello1234\" /&gt; &lt;!-- 多协议配置 --&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\" /&gt; &lt;dubbo:protocol name=\"hessian\" port=\"8080\" /&gt; &lt;!-- 使用多个协议暴露服务 --&gt; &lt;dubbo:service id=\"helloService\" interface=\"com.alibaba.hello.api.HelloService\" version=\"1.0.0\" protocol=\"dubbo,hessian\" /&gt; &lt;/beans&gt; 多注册中心(1) 多注册中心注册 比如：中文站有些服务来不及在青岛部署，只在杭州部署，而青岛的其它应用需要引用此服务，就可以将服务同时注册到两个注册中心。 consumer.xml 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://code.alibabatech.com/schema/dubbohttp://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;&lt;dubbo:application name=\"world\" /&gt; &lt;!-- 多注册中心配置 --&gt; &lt;dubbo:registry id=\"hangzhouRegistry\" address=\"10.20.141.150:9090\" /&gt; &lt;dubbo:registry id=\"qingdaoRegistry\" address=\"10.20.141.151:9010\" default=\"false\" /&gt; &lt;!-- 向多个注册中心注册 --&gt; &lt;dubbo:service interface=\"com.alibaba.hello.api.HelloService\" version=\"1.0.0\" ref=\"helloService\" registry=\"hangzhouRegistry,qingdaoRegistry\" /&gt; &lt;/beans&gt; (2) 不同服务使用不同注册中心 比如：CRM有些服务是专门为国际站设计的，有些服务是专门为中文站设计的。 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://code.alibabatech.com/schema/dubbohttp://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;dubbo:application name=\"world\" /&gt; &lt;!-- 多注册中心配置 --&gt; &lt;dubbo:registry id=\"chinaRegistry\" address=\"10.20.141.150:9090\" /&gt; &lt;dubbo:registry id=\"intlRegistry\" address=\"10.20.154.177:9010\" default=\"false\" /&gt; &lt;!-- 向中文站注册中心注册 --&gt; &lt;dubbo:service interface=\"com.alibaba.hello.api.HelloService\" version=\"1.0.0\" ref=\"helloService\" registry=\"chinaRegistry\" /&gt; &lt;!-- 向国际站注册中心注册 --&gt; &lt;dubbo:service interface=\"com.alibaba.hello.api.DemoService\" version=\"1.0.0\" ref=\"demoService\" registry=\"intlRegistry\" /&gt; &lt;/beans&gt; (3) 多注册中心引用 比如：CRM需同时调用中文站和国际站的PC2服务，PC2在中文站和国际站均有部署，接口及版本号都一样，但连的数据库不一样。 12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://code.alibabatech.com/schema/dubbohttp://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt;&lt;dubbo:application name=\"world\" /&gt; &lt;!-- 多注册中心配置 --&gt; &lt;dubbo:registry id=\"chinaRegistry\" address=\"10.20.141.150:9090\" /&gt; &lt;dubbo:registry id=\"intlRegistry\" address=\"10.20.154.177:9010\" default=\"false\" /&gt; &lt;!-- 引用中文站服务 --&gt; &lt;dubbo:reference id=\"chinaHelloService\" interface=\"com.alibaba.hello.api.HelloService\" version=\"1.0.0\" registry=\"chinaRegistry\" /&gt; &lt;!-- 引用国际站站服务 --&gt; &lt;dubbo:reference id=\"intlHelloService\" interface=\"com.alibaba.hello.api.HelloService\" version=\"1.0.0\" registry=\"intlRegistry\" /&gt; &lt;/beans&gt; 如果只是测试环境临时需要连接两个不同注册中心，使用竖号分隔多个不同注册中心地址： 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beanshttp://www.springframework.org/schema/beans/spring-beans.xsdhttp://code.alibabatech.com/schema/dubbohttp://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;dubbo:application name=\"world\" /&gt; &lt;!-- 多注册中心配置，竖号分隔表示同时连接多个不同注册中心，同一注册中心的多个集群地址用逗号分隔 --&gt; &lt;dubbo:registry address=\"10.20.141.150:9090|10.20.154.177:9010\" /&gt; &lt;!-- 引用服务 --&gt; &lt;dubbo:reference id=\"helloService\" interface=\"com.alibaba.hello.api.HelloService\" version=\"1.0.0\" /&gt; &lt;/beans&gt; 服务分组当一个接口有多种实现时，可以用group区分。 12345678910111213141516171819202122&lt;dubbo:servicegroup=\"feedback\"interface=\"com.xxx.IndexService\"/&gt;&lt;dubbo:servicegroup=\"member\"interface=\"com.xxx.IndexService\"/&gt;&lt;dubbo:referenceid=\"feedbackIndexService\"group=\"feedback\"interface=\"com.xxx.IndexService\"/&gt;&lt;dubbo:referenceid=\"memberIndexService\"group=\"member\"interface=\"com.xxx.IndexService\"/&gt; 多版本当一个接口实现，出现不兼容升级时，可以用版本号过渡，版本号不同的服务相互间不引用。 在低压力时间段，先升级一半提供者为新版本再将所有消费者升级为新版本然后将剩下的一半提供者升级为新版本 12345678910111213141516171819202122232425262728&lt;dubbo:serviceinterface=\"com.foo.BarService\"version=\"1.0.0\"/&gt;&lt;dubbo:serviceinterface=\"com.foo.BarService\"version=\"2.0.0\"/&gt;&lt;dubbo:referenceid=\"barService\"interface=\"com.foo.BarService\"version=\"1.0.0\"/&gt;&lt;dubbo:referenceid=\"barService\"interface=\"com.foo.BarService\"version=\"2.0.0\"/&gt;不区分版本&lt;dubbo:referenceid=\"barService\"interface=\"com.foo.BarService\"version=\"*\"/&gt; 分组聚合按组合并返回结果，比如菜单服务，接口一样，但有多种实现，用group区分，现在消费方需从每种group中调用一次返回结果，合并结果返回，这样就可以实现聚合菜单项。 从2.1.0版本开始支持 1234567891011121314151617181920212223242526272829303132333435搜索所有分组：&lt;dubbo:referenceinterface=\"com.xxx.MenuService\"group=\"*\"merger=\"true\"/&gt;合并指定分组：&lt;dubbo:referenceinterface=\"com.xxx.MenuService\"group=\"aaa,bbb\"merger=\"true\"/&gt;指定方法合并结果，其它未指定的方法，将只调用一个Group：&lt;dubbo:referenceinterface=\"com.xxx.MenuService\"group=\"*\"&gt; &lt;dubbo:method name=\"getMenuItems\" merger=\"true\" /&gt;&lt;/dubbo:service&gt;某个方法不合并结果，其它都合并结果：&lt;dubbo:referenceinterface=\"com.xxx.MenuService\"group=\"*\"merger=\"true\"&gt; &lt;dubbo:method name=\"getMenuItems\" merger=\"false\" /&gt;&lt;/dubbo:service&gt; 参数验证参数验证功能是基于JSR303实现的，用户只需标识JSR303标准的验证Annotation，并通过声明filter来实现验证。 2.1.0以上版本支持 完整示例代码参见：https://github.com/alibaba/dubbo/tree/master/dubbo-test/dubbo-test-examples/src/main/java/com/alibaba/dubbo/examples/validation 验证方式可扩展，参见：Validation扩展点","categories":[],"tags":[]},{"title":"ConcurrentHashMap","slug":"ConcurrentHashMap","date":"2018-03-22T14:56:26.000Z","updated":"2018-03-25T14:58:41.000Z","comments":true,"path":"2018/03/22/ConcurrentHashMap/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/22/ConcurrentHashMap/","excerpt":"","text":"ConcurrentHashMap HashMap为非线程安全的，多线程并发下put操作有可能引起死循环，而HashTable、Collections.synchronizedMap(hashMap)是线程安全的。 JDK6实现 使用锁分段实现多个线程间并发写操作，采用数组+链表结构的存储结构 包含两个静态内部类Segment和HashEntry Segment继承ReentrantLock，用来充当锁的角色，每个Segment对象守护一个散列映射表的若干桶，每个段实质是一个小的HashMap 每个桶是由若干个HashEntry对象链接起来的链表 不允许null作为映射值 定位： 假设ConcurrentHashMap一共分为2^n个段，每个段中有2^m个桶，那么段的定位方式是将key的hash值的高n位与(2^n-1)相与。在定位到某个段后，再将key的hash值的低m位与(2^m-1)相与，定位到具体的桶位 内部结构： 1、HashEntry HashEntry的next属性为final，所有新节点只能在链表的表头插入 12345678910111213static final class HashEntry&lt;K,V&gt; &#123; final K key; // 声明 key 为 final 型 final int hash; // 声明 hash 值为 final 型 volatile V value; // 声明 value 为 volatile 型 final HashEntry&lt;K,V&gt; next; // 声明 next 为 final 型 HashEntry(K key, int hash, HashEntry&lt;K,V&gt; next, V value) &#123; this.key = key; this.hash = hash; this.next = next; this.value = value; &#125; &#125; 2、Segment 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; /** * 在本 segment 范围内，包含的 HashEntry 元素的个数 * 该变量被声明为 volatile 型 */ transient volatile int count; /** * table 被更新的次数 */ transient int modCount; /** * 当 table 中包含的 HashEntry 元素的个数超过本变量值时，触发 table 的再散列 */ transient int threshold; /** * table 是由 HashEntry 对象组成的数组 * 如果散列时发生碰撞，碰撞的 HashEntry 对象就以链表的形式链接成一个链表 * table 数组的数组成员代表散列映射表的一个桶 * 每个 table 守护整个 ConcurrentHashMap 包含桶总数的一部分 * 如果并发级别为 16，table 则守护 ConcurrentHashMap 包含的桶总数的 1/16 */ transient volatile HashEntry&lt;K,V&gt;[] table; /** * 装载因子 */ final float loadFactor; Segment(int initialCapacity, float lf) &#123; loadFactor = lf; setTable(HashEntry.&lt;K,V&gt;newArray(initialCapacity)); &#125; /** * 设置 table 引用到这个新生成的 HashEntry 数组 * 只能在持有锁或构造函数中调用本方法 */ void setTable(HashEntry&lt;K,V&gt;[] newTable) &#123; // 计算临界阀值为新数组的长度与装载因子的乘积 threshold = (int)(newTable.length * loadFactor); table = newTable; &#125; /** * 根据 key 的散列值，找到 table 中对应的那个桶（table 数组的某个数组成员） */ HashEntry&lt;K,V&gt; getFirst(int hash) &#123; HashEntry&lt;K,V&gt;[] tab = table; // 把散列值与 table 数组长度减 1 的值相“与”，// 得到散列值对应的 table 数组的下标 // 然后返回 table 数组中此下标对应的 HashEntry 元素 return tab[hash &amp; (tab.length - 1)]; &#125; &#125; 3、ConcurrentHashMap 默认并发数为16 映射表的默认初始容量为16,即16个桶 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class ConcurrentHashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implements ConcurrentMap&lt;K, V&gt;, Serializable &#123; /** * 散列映射表的默认初始容量为 16，即初始默认为 16 个桶 * 在构造函数中没有指定这个参数时，使用本参数 */ static final int DEFAULT_INITIAL_CAPACITY= 16; /** * 散列映射表的默认装载因子为 0.75，该值是 table 中包含的 HashEntry 元素的个数与* table 数组长度的比值 * 当 table 中包含的 HashEntry 元素的个数超过了 table 数组的长度与装载因子的乘积时，* 将触发 再散列 * 在构造函数中没有指定这个参数时，使用本参数 */ static final float DEFAULT_LOAD_FACTOR= 0.75f; /** * 散列表的默认并发级别为 16。该值表示当前更新线程的估计数 * 在构造函数中没有指定这个参数时，使用本参数 */ static final int DEFAULT_CONCURRENCY_LEVEL= 16; /** * segments 的掩码值 * key 的散列码的高位用来选择具体的 segment */ final int segmentMask; /** * 偏移量 */ final int segmentShift; /** * 由 Segment 对象组成的数组 */ final Segment&lt;K,V&gt;[] segments; /** * 创建一个带有指定初始容量、加载因子和并发级别的新的空映射。 */ public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if(!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if(concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // 寻找最佳匹配参数（不小于给定参数的最接近的 2 次幂） int sshift = 0; int ssize = 1; while(ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; segmentShift = 32 - sshift; // 偏移量值 segmentMask = ssize - 1; // 掩码值 this.segments = Segment.newArray(ssize); // 创建数组 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if(c * ssize &lt; initialCapacity) ++c; int cap = 1; while(cap &lt; c) cap &lt;&lt;= 1; // 依次遍历每个数组元素 for(int i = 0; i &lt; this.segments.length; ++i) // 初始化每个数组元素引用的 Segment 对象this.segments[i] = new Segment&lt;K,V&gt;(cap, loadFactor); &#125; /** * 创建一个带有默认初始容量 (16)、默认加载因子 (0.75) 和 默认并发级别 (16) * 的空散列映射表。 */ public ConcurrentHashMap() &#123; // 使用三个默认参数，调用上面重载的构造函数来创建空散列映射表this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); &#125; put方法ConcurrentHashMap: 根据 key 计算出对应的 hash 值 1234567public V put(K key, V value) &#123; if (value == null) //ConcurrentHashMap 中不允许用 null 作为映射值 throw new NullPointerException(); int hash = hash(key.hashCode()); // 计算键对应的散列码 // 根据散列码找到对应的 Segment return segmentFor(hash).put(key, hash, value, false); &#125; 根据 hash 值找到对应的 Segment 12345678910/** * 使用 key 的散列码来得到 segments 数组中对应的 Segment */ final Segment&lt;K,V&gt; segmentFor(int hash) &#123; // 将散列值右移 segmentShift 个位，并在高位填充 0 // 然后把得到的值与 segmentMask 相“与”// 从而得到 hash 值对应的 segments 数组的下标值// 最后根据下标值返回散列码对应的 Segment 对象 return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask]; &#125; Segment: 在 Segment 中执行具体的 put 操作 12345678910111213141516171819202122232425262728293031323334353637V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; lock(); // 加锁，这里是锁定某个 Segment 对象而非整个 ConcurrentHashMap try &#123; int c = count; if (c++ &gt; threshold) // 如果超过再散列的阈值 rehash(); // 执行再散列，table 数组的长度将扩充一倍 HashEntry&lt;K,V&gt;[] tab = table; // 把散列码值与 table 数组的长度减 1 的值相“与” // 得到该散列码对应的 table 数组的下标值 int index = hash &amp; (tab.length - 1); // 找到散列码对应的具体的那个桶 HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue; if (e != null) &#123; // 如果键 / 值对以经存在 oldValue = e.value; if (!onlyIfAbsent) e.value = value; // 设置 value 值 &#125; else &#123; // 键 / 值对不存在 oldValue = null; ++modCount; // 要添加新节点到链表中，所以 modCont 要加 1 // 创建新节点，并添加到链表的头部 tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); count = c; // 写 count 变量 &#125; return oldValue; &#125; finally &#123; unlock(); // 解锁 &#125; &#125; HashEntry 对象的不变性来降低读操作对加锁的需求 HashEntry的next属性声明为final：不能把节点添加到链接的中间和尾部，也不能在链接的中间和尾部删除节点，访问某个节点时，这个节点之后链接不会被改变。 HashEntry的value属性声明为volatile，某个写线程对 value 属性的写入马上可以被后续的某个读线程“看”到；ConcurrentHashMap 中，不允许用 null 作为键和值，当读线程读到某个 HashEntry 的 value 属性的值为 null 时，便知道产生了冲突——发生了重排序现象，需要加锁后重新读入这个 value 值 对散列表做非结构性修改的操作：只是更改某个 HashEntry 的 value 域的值；写线程对链表的非结构性修改能够被后续不加锁的读线程“看到 对散列表做结构性修改：实质上是对某个桶指向的链表做结构性修改,如果能够确保：在读线程遍历一个链表期间，写线程对这个链表所做的结构性修改不影响读线程继续正常遍历这个链表。那么读 / 写线程之间就可以安全并发访问这个 ConcurrentHashMap clear操作：只是把 ConcurrentHashMap 中所有的桶“置空”，每个桶之前引用的链表依然存在，只是桶不再引用到这些链表（所有链表的结构并没有被修改）。正在遍历某个链表的读线程依然可以正常执行对该链表的遍历 put操作：put 操作如果需要插入一个新节点到链表中时 , 会在链表头部插入这个新节点。此时，链表中的原有节点的链接并没有被修改。也就是说：插入新健 / 值对到链表中的操作不会影响读线程正常遍历这个链表 remove操作： 待删除节点之后的节点原样保留在链表中，待删除节点之前的节点被克隆到新链表，链表的新头节点为待删除节点之前的那个节点；在执行 remove 操作时，原始链表并没有被修改，也就是说：读线程不会受同时执行 remove 操作的并发写线程的干扰 删除C节点前： 删除C节点后： Segment的remove方法： 123456789101112131415161718192021222324252627282930313233343536V remove(Object key, int hash, Object value) &#123; lock(); // 加锁 try&#123; int c = count - 1; HashEntry&lt;K,V&gt;[] tab = table; // 根据散列码找到 table 的下标值 int index = hash &amp; (tab.length - 1); // 找到散列码对应的那个桶 HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while(e != null&amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if(e != null) &#123; V v = e.value; if(value == null|| value.equals(v)) &#123; // 找到要删除的节点 oldValue = v; ++modCount; // 所有处于待删除节点之后的节点原样保留在链表中 // 所有处于待删除节点之前的节点被克隆到新链表中 HashEntry&lt;K,V&gt; newFirst = e.next;// 待删节点的后继结点 for(HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value); // 把桶链接到新的头结点 // 新的头结点是原链表中，删除节点之前的那个节点 tab[index] = newFirst; count = c; // 写 count 变量 &#125; &#125; return oldValue; &#125; finally&#123; unlock(); // 解锁 &#125; &#125; Segment的volatile修饰的count属性用来统计Segment中HashEntry的个数 在 ConcurrentHashMap 中，所有执行写操作的方法（put, remove, clear），在对链表做结构性修改之后，在退出写方法前都会去写这个 count 变量。所有未加锁的读操作（get, contains, containsKey）在读方法中，都会首先去读取这个 count 变量 Segment中的get方法：12345678910111213141516V get(Object key, int hash) &#123; if(count != 0) &#123; // 首先读 count 变量 HashEntry&lt;K,V&gt; e = getFirst(hash); while(e != null) &#123; if(e.hash == hash &amp;&amp; key.equals(e.key)) &#123; V v = e.value; if(v != null) return v; // 如果读到 value 域为 null，说明发生了重排序，加锁后重新读取 return readValueUnderLock(e); &#125; e = e.next; &#125; &#125; return null; &#125; ConcurrentHashMap的size操作先尝试2次通过不锁住Segment的方式来统计各个Segment大小，如果统计的过程中，容器的count发生了变化，则再采用加锁的方式来统计所有Segment的大小 在put , remove和clean方法里操作元素前都会将变量modCount进行加1，那么在统计size前后比较modCount是否发生变化，从而得知容器的大小是否发生变化 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Returns the number of key-value mappings in this map. If the * map contains more than &lt;tt&gt;Integer.MAX_VALUE&lt;/tt&gt; elements, returns * &lt;tt&gt;Integer.MAX_VALUE&lt;/tt&gt;. * * @return the number of key-value mappings in this map */ public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; long sum = 0; long check = 0; int[] mc = new int[segments.length]; // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. for (int k = 0; k &lt; RETRIES_BEFORE_LOCK; ++k) &#123; check = 0; sum = 0; int mcsum = 0; for (int i = 0; i &lt; segments.length; ++i) &#123; sum += segments[i].count; mcsum += mc[i] = segments[i].modCount; // 在统计size时记录modCount &#125; if (mcsum != 0) &#123; for (int i = 0; i &lt; segments.length; ++i) &#123; check += segments[i].count; if (mc[i] != segments[i].modCount) &#123; // 统计size后比较各段的modCount是否发生变化 check = -1; // force retry break; &#125; &#125; &#125; if (check == sum)// 如果统计size前后各段的modCount没变，且两次得到的总数一致，直接返回 break; &#125; if (check != sum) &#123; // Resort to locking all segments // 加锁统计 sum = 0; for (int i = 0; i &lt; segments.length; ++i) segments[i].lock(); for (int i = 0; i &lt; segments.length; ++i) sum += segments[i].count; for (int i = 0; i &lt; segments.length; ++i) segments[i].unlock(); &#125; if (sum &gt; Integer.MAX_VALUE) return Integer.MAX_VALUE; else return (int)sum; &#125; ConcurrentHashMap的重哈希操作ConcurrentHashMap的重哈希实际上是对ConcurrentHashMap的某个段的重哈希，因此ConcurrentHashMap的每个段所包含的桶位自然也就不尽相同 由于扩容是按照2的幂次方进行的，所以扩展前在同一个桶中的元素，现在要么还是在原来的序号的桶里，或者就是原来的序号再加上一个2的幂次方，就这两种选择 JDK8实现","categories":[],"tags":[]},{"title":"HashMap","slug":"HashMap","date":"2018-03-21T04:57:47.000Z","updated":"2018-03-21T05:06:23.000Z","comments":true,"path":"2018/03/21/HashMap/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/21/HashMap/","excerpt":"","text":"HashMap 特点： 允许null键/值 非同步 不保证有序（比如插入顺序） 不保证顺序不随时间变化","categories":[],"tags":[]},{"title":"JVM","slug":"JVM","date":"2018-03-19T14:22:30.000Z","updated":"2018-03-22T14:28:16.000Z","comments":true,"path":"2018/03/19/JVM/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/19/JVM/","excerpt":"","text":"内存区域 Java内存粗糙的分为堆内存、栈内存 运行时数据区域： 程序计数器 当前线程所执行的字节码的行号指示器，用于线程切换后能恢复到正确的执行位置，线程私有的 Java虚拟机栈 为虚拟机执行Java方法服务，线程私有的 本地方法栈 为虚拟机执行Native方法服务，线程私有的 Java堆 别名GC堆，内存中最大的一块，垃圾收集器管理的主要区域，细分为新生代和老年代，所有线程共享 方法区 别名叫非堆(永久代），用于存储已被虚拟机加载的类信息、常量、静态变量、即使编译器编译后的代码等数据，所有线程共享。运行时常量池畏方法区的一部分。回收的目标主要是针对常量池回收和对类型卸载。 内存相关的异常： StackOverflowError异常 线程请求的栈深度大于虚拟机允许的深度，Java虚拟机栈、本地方法栈区域可能会抛出该异常 OutOfMemoryError异常 虚拟机栈可以动态扩张，如果扩展时无法申请足够的内存。或者在堆中没有内存来分配给对象，并且堆也无法再扩展。或者常量池无法再申请到内存。Java虚拟机栈、本地方法栈、Java堆、常量池区域可能会抛出该异常 垃圾收集算法 最基础的算法为标记-清除，其它收集算法都是基于这种思路并对其不足进行改进而得道。 常用算法： 引用计数算法 存在循环引用问题 标记-清除(mark-sweep)算法 首先标记出所有需要回收的对象，在标记完后统一回收所有被标记的对象。最大的问题为标记和清除的两个过程效率都不高、回收后存在大量不连续的内存碎片、不利于大对象分配 复制算法 将内存空间划分为大小相等的两块，每次只使用其中一块，当一块内存用完，将存活的对象复制到另外一块内存中，然后把用完的一块内存一次清理掉。比标记-清除算法效率高，但是缺点是内存使用率不高（内存缩小为原来的一半）。这种收集算法主要用来收集新生代内存，如果对象存活率较高，就要进行较多的复制操作，效率会变低。 标记-整理(mark-compact)算法 标记过程与标记-清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象向一端移动，然后直接清理边界以外的内存。适合老年代内存回收。 新生代： 特点 每次垃圾回收时都会有大批对象死去，只有少量对象存活 组成 将内存分为一块较大的Eden空间和两块较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活的对象一次性复制到另外一块Survivor空间，最后清理掉Eden和刚才用过的Survivor空间。HotSpot虚拟机默认Eden和Survivor的大小比例为8:1。当Survivor空间不够用，需要依赖其它内存（老年代）进行分配担保 采用复制算法 老年代： 特点 老年代中对象存活率高、没有额外空间对它进行分配担保 采用标记-清理、标记-整理算法 内存分配与回收策略 1、对象优先在Eden分配： 大多数情况，对象在新生代Eden区中分配。当Eden区没有足够内存空间来分配时，虚拟机将发起一次Minor GC。 2、大对象直接进入老年代: 大对象 需要大量连续内存空间的Java对象(典型的如长字符串及数组)，短命大对象，经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来安置它们。 3、长期存活的对象将进入老年代： 给每个对象定义一个对象年龄计算器，对象在Survivor区中每熬过一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认15岁），将会晋升到老年代。 4、动态对象年龄判定 虚拟机并不是永远地要求对象的年龄必须达到MaxTenuringThreshold才能晋升老年代 如果Suvivor空间中相同年龄所有对象大小总和大于Survivor空间的一半时，年龄大于或等于该年龄的对象就直接进入老年代，无须等到MaxTenuringThreshold要求的年龄 5、空间分配担保 在发生Minor GC之前，虚拟机会先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立，那么Minor GC可用确保时安全的，如果不成立，则虚拟机会查看HandlePromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次Minor GC，尽管这次Minor GC时有风险的；如果效应，或者HandlePromotionFailure设置不允许冒险，那这时也要改为进行一次Full GC。 两种GC： Minor GC 新生代GC，Minor GC非常频繁，一般回收速度也比较快 Major GC／Full GC 老年代GC，出现了Major GC，经常会伴随至少一次Minor GC，Major GC的速度一般比Minor GC慢10倍以上。 虚拟机参数 -XX:+option 开启option参数 -XX:-option 关闭option参数 -XX:option=value 将option参数的值设置为value 整个堆大小=年轻代大小 + 年老代大小 + 持久代大小 配置参数： -Xms 初始堆大小 -Xmx 最大堆大小 -Xmn(1.4or lator) 年轻代大小 为eden+ 2个Survivor,增大年轻代后,将会减小年老代大小.此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8 -XX:NewSize(1.3/1.4) 年轻代大小 -XX:MaxNewSize(1.3/1.4) 年轻代最大值 -XX:PermSize 持久代(perm gen)初始值 -XX:MaxPermSize 持久代最大值 -Xss 每个线程的堆栈大小 -XX:NewRatio 年轻代与年老代的比值 -XX:SurvivorRatio Eden区与Survivor区的大小比值 内存管理参数： -XX:PretenureSizeThreshold 大小超过这个设置值的对象直接在老年代分配，默认值为15 -XX:MaxTenuringThreshold 对象晋升老年代的年龄阀值 调试参数： -XX:+PrintFlagsFinal 输出索引参数的名称及默认值 -XX:+PrintGC 打印GC信息 -XX:+PrintGCDetails 发生垃圾收集行为时打印内存回收日志 -XX:+HeapDumpOnOutOfMemoryError 虚拟机在OOM异常出现之后自动生成dump文件* -XX:+HeapDumpOnCtrlBreak 使用【Ctrl】+【Break】键让虚拟机生成dump文件 JVM优化命令 1、ps：虚拟机进程状况工具 2、jstat：虚拟机统计信息监视工具 显示本地或远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据 定位运行期虚拟机性能问题 3、jinfo：Java配置信息工具 4、jmap：Java内存映像工具 用于生产堆转储快照（heapdump或dump文件） 5、jhat：虚拟机堆转储快照分析工具 6、jstack：Java堆栈跟踪工具 用于生成虚拟机当前时刻的线程快照（threaddump或javacore文件） 用于定位线程出现长时间停顿的原因，如果线程间死锁、死循环、请求外部资源导致的长时间等待 类加载机制 类加载器: 类在虚拟机中的唯一性，由加载它的类加载器和这个类本身一同确立；比较两个类是否“相等”，只有这两个类是由同一类加载器加载的前提下才意义，否则，即使两个类来源于同一个class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。 启动类加载器: 或称引导类加载器，Bootstrap ClassLoader，由C++语言实现，是虚拟机自身的一部分，负责将\\lib目录中或被-Xbootclasspath参数所指定的路径中的类库加载到虚拟机内存,启动类加载器无法被Java程序直接引用 扩展类加载器: Extension ClassLoader，由sun.misc.Launcher$ExtClassLoader实现，负责加载\\lib\\ext目录中或被java.ext.dirs系统变量所指定逻辑中的所有类库。 应用程序类加载器: 或称系统类加载器，Applicatiion ClassLoader，由sun.misc.Launcher$AppClassLoader实现，负责加载用户类路径(ClassPath)所指定的类库，一般情况下程序默认使用应用程序类加载器。 由Java实现的类加载器都继承自抽象类java.lang.ClassLoader。 双亲委派模型： 工作过程是：如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此，因此索引额加载请求最终都应该传送到顶层的启动类加载器中，只有当父类加载器反馈自己无法完成这个加载请求时，子加载器才会尝试自己去加载。 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125; 内存模型java内存模型(java memory model JMM)来屏蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。 1、主内存与工作内存 定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节 每个线程有自己的工作内存，工作内存中保存了线程使用到的变量的主内存工作副本，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行；不能直接读写主内存中的变量。 主内存对应Java堆中的对象实例数据部分，而工作内存则对应虚拟机栈中的部分区域。 2、内存交互操作 lock(锁定)：把变量标识为一条线程独占的状态。 unlock(解锁)：把处于锁定状态的变量释放出来。 read(读取)：把变量的值从主内存传输到线程的工作内存中 load(载入)：把read操作从主内存中得到的变量值放入工作内存的变量副本。 use(使用)：把工作内存的变量值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。 assign(赋值) 把从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到给变量赋值的字节码指令时执行这个操作 store(存储) 把工作内存的值传送到主内存中 write(写入）把store操作从工作内存中得到的变量的值放入主内存的变量中 变量从主内存复制到工作内存，要顺序执行read和load，变量从工作内存同步回主内存，要顺序执行store和write，只要求两个操作顺序执行，而没有保证是连续执行。read和load之间、store和write之间是可以插入其他指令的。如read a、read b、load b、load a。 3、volatile型变量 最轻量级的同步机制 特性： 保证变量对所有线程的可见性，可见性是指一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得到的 每次使用之前都要刷新 新值立即同步到主内存 语义是禁止指令重排序优化 不符合以下规则的运算场景，仍然要通过加锁(synchronized或java.util.concurrent中的原子类)来保证原子性： 运算结果并不依赖当前变量的当前值，或者能够确保只有单一线程修改变量的值。 变量不需要与其他的状态变量共同参与不变约束。 4、long和double型变量的非原子协定 5、原子性、可见性与有序性 原子性： 可见性：除了volatile外，synchronized和final也能实现可见性。 有序性：如果在本线程内观察，所有操作都是有序的；如果在一个线程中观察另外一个线程，所有操作都是无序的。前半句是指线程内表现为串行的语义，后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。volatile和synchronized能保证线程之间操作的有序性。 6、先行发生原则(happen-before) 先行发生是Java内存模型中定义的两项操作之间的偏序关系，如果说操作A先行发生与操作B，其实是说在发生操作B之前，操作A产生的影响能被操作B观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法","categories":[],"tags":[]},{"title":"mysql","slug":"mysql","date":"2018-03-18T08:23:56.000Z","updated":"2018-03-18T14:55:18.000Z","comments":true,"path":"2018/03/18/mysql/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/18/mysql/","excerpt":"","text":"并发控制mysql通过加锁进行并发控制。mysql有两种锁，分别是共享锁和排它锁，也叫读锁和写锁。读锁是共享的，写锁是排它的。多个读锁可以同时存在，但是写锁不能和读锁和写锁共存。在读多写少的场景比较适合读写锁。 按锁的粒度，分为表级锁和行级锁。 Myisam与InnoDB区别 InnoDB支持事务，Myisam不支持 InnoDB支持外键，Myisam不支持 InnoDB是聚集索引，数据文件和索引绑在一起，必须要主键索引；Myisam是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的 InnoDB不保存表的具体行数，执行select count(*) from table是需要全表扫描；而Myisam用一个变量保存整个表的行数，执行上述语句只需要读出该变量即可，速度很快。 InnoDB不支持全文索引，而Myisam支持全文索引。 InnoDB支持行级锁，而Myisam只支持表级锁 聚簇索引和非聚簇索引myisam的主键索引和其它索引没有什么不同，都只是存储了数据的物理位置指针，innoDB的聚簇索引和非聚簇索引很不相同。 聚簇索引：InnoDB一定会建立聚簇索引，把实际数据行与相关的键值保存在一起。 一个表只能有一个聚簇索引 有主键时，根据主键创建聚簇索引 没有主键时，会用一个唯一且不为空的索引列作为主键创建聚簇索引 以上都不满足，隐式定义一个主键作为聚簇索引 主键不能太大 按主键顺序插入行对应高并发，按主键顺序插入行可能会造成主键争用，主键的上限会成为热点，并发插入会导致间隙锁经侦；另外一个热点是auto_increment锁机制 非聚簇索引：非聚簇索引（二级索引），也称为辅助索引 叶子节点保存的不是行的物理位置指针，而是是主键值，当行移动或数据页分裂时无需更新二级索引的物理位置指针。 访问数据需要两次索引查找 B树、B+树、B*树InnoDB使用的是B+树。 B树(B-Tree）：B树作为一种多路搜索树（并不是二叉的） 定义任意非叶子结点最多只有M个儿子；且M&gt;2； 根结点的儿子数为[2, M]； 除根结点以外的非叶子结点的儿子数为[M/2, M]； 每个结点存放至少M/2-1（取上整）和至多M-1个关键字；(至少2个关键字） 非叶子结点的关键字个数=指向儿子的指针个数-1； 非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]；&gt; * v非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树； 所有叶子结点位于同一层； B+树(B+tree)：B+树是B树的变体，也是一种多路搜索树，其定义基本与B-树相同，除了： 非叶子结点的子树指针与关键字个数相同； 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）； 为所有叶子结点增加一个链指针； 所有关键字都在叶子结点出现； B+树性质： 所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是有序的； 不可能在非叶子结点命中； 非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层； 更适合文件索引系统。 B∗树：B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针，将结点的最低利用率从1/2提高到2/3 B∗树定义了非叶子结点关键字个数至少为23M，即块的最低使用率为2/3（代替B+树的1/2）； B+树的分裂：当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针； B∗树的分裂：当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针； 所以，B∗树分配新结点的概率比B+树要低，空间使用率更高。","categories":[],"tags":[]},{"title":"spring事务传播机制和隔离级别","slug":"spring事务传播机制和隔离级别","date":"2018-03-15T15:24:57.000Z","updated":"2018-09-30T06:24:59.000Z","comments":true,"path":"2018/03/15/spring事务传播机制和隔离级别/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/15/spring事务传播机制和隔离级别/","excerpt":"","text":"spring事务传播机制和隔离级别事务传播机制 propagation_required 支持当前事务，如果不存在事务，则新建一个事务 propagation_supports 支持当前事务，如果不存在事务，则以非事务方式执行 propagation_mandatory 支持当前事务，如果不存在事务，则抛出异常 propagation_required_new 新建事务，如果当前存在事务，则挂起当前事务 propagation_not_supported 以非事务方式执行，如果当前存在事务，则把当前事务挂起 propagation_never 以非事务方式执行，如果当前存在事务，则抛出异常 propagation_nested 如果当前存在事务，则在嵌套事务内执行，如果当前没有事务，则其行为与propagation_required一样。嵌套的事务可以独立于当前事务进行单独的提交或回滚。内部事务的回滚不会对外部事务造成影响，如果外部事务commit, 嵌套事务也会被commit, 这个规则同样适用于 roll back 事务隔离级别 数据库事务并发的三个问题： 脏读 脏读发生在一个事务读取另外一个事务改写未提交的数据，如果改写在稍后被回滚，就有可能出现数据不一致。 不可重复读 一个事务执行相同的查询两次或两次以上，每次得到不同的数据，通常是由于另外一个事务在两次查询期间进行更新。通过锁住满足条件的记录来解决。重点在于update和delete 幻读 一个事务读取了几行数据，另外一个事务插入了一些数据，在后面的查询，第一个事务会发现多了一些原本不存在的记录。通过锁住满足条件及其相近的记录。重点在于insert spring中对应数据库的隔离级别： isolation_default 使用数据库默认的隔离级别 isolation_read_uncommited 读未提交，可能出现脏读、不可重复读、幻读 isolation_read_commited 读已提交，避免了脏读，可能会出现不可重复读、幻读 isolation_repeatable_read 可重复读，避免了脏读、不可重复读，可能出现幻读 isolation_seriablizable 串行访问，避免脏读、不可重复读、幻读。读加共享锁，写加排他锁，读写互斥 数据库隔离级别： mysql数据库的默认隔离级别为repeatable_read，并且解决了幻读问题。 oracle数据库的默认隔离级别为read_commited 回滚机制回滚规则用于定义哪些异常会导致回滚，哪些异常不会导致回滚默认情况下，只有遇到运行时异常才会回滚，遇到受检异常不回滚。 MVCC(多版本并发控制)全称为Multi-Version Currency Control，为了查询一些正在被另外事务更新的行，并且可以看到它们被更新之前的值。可以增强并发，实现查询不用等待另外事务释放锁。 在InnoDB中,给每行增加两个隐藏字段来实现mvcc，一个用来记录行的创建时间，一个用了记录行的过期时间（删除时间）。在实际实现中，存储的并不是时间，而是事务版本号，每开启一个新的事务，事务的版本号就会递增。mysql的默认隔离级别repeatable read下，增删查改的实现为： select 读取创建版本号小于或等于当前事务版本号，且删除版本号为空或大于当前事务版本号的记录，这样可以保证在读取之前记录是存在的 insert 创建版本号为当前事务版本号 update 插入一条新记录，新记录的创建版本号为当前事务版本号，原记录的删除版本号为当前事务版本号 delete 删除版本号为当前事务版本号 Mvcc只支持repeatable read和read commited隔离级别。read uncommited与Mvcc不兼容，因为不能找到适合它们事务版本的行版本，每次读取都是最新版本。serailizable与Mvcc也不兼容，因为每次读操作都会锁定它们返回的每一行数据 快照读和当前读： 快照读 读取的快照版本，也就是历史版本。普通的select是快照读 当前读 读取的是最新版本。update、insert、delete、select .. for update、select .. lock in share mode是当前读 锁定读和一致性非锁定读： 锁定读 事务中标准的select语句是不会加锁的，select .. for update（与update加锁一样）、select .. lock in share mode（加共享锁，其它事务只读不能修改，直到当前事务提交）两种除外。 一致性非锁定读 简称一致性读，读的是数据库某个时间点的快照。如果隔离级别是repeatable_read，同一个事务中的所有一致性非锁定读都读的是事务中第一个读读到的快照版，如果隔离级别为read_commited，那么事务的每一个一致性非锁定读都会读到自己刷新的快照版本。一致性非锁定读不会给它访问的表加任何形式的锁，因此其它事务可以并发的修改它们。 悲观锁和乐观锁： 悲观锁 数据库总是认为别人会修改它所操作的数据，因此在操作数据过程中将数据加锁 乐观锁 总是认为别人不会修改，通过版本来实现 锁： record lock（记录锁） 在索引记录上加锁 grap locks（间隙锁） 在索引记录之间加锁，或者在第一个索引记录之前加锁，或者在最后一个索引记录之后加锁 next key lock 在索引记录上加锁，并且在索引记录之间的间隙加锁，相当于record lock与grap locks的结合 一致性读保证了可重复读，间隙锁防止了幻读。 遇到的问题同一service两个方法之间调用，被调用方法的@Transaction配置会被忽略解决方法：1、通过AopProxy上下文获取代理对象（1）SpringBoot配置方式：注解开启 exposeProxy = true，暴露代理对象 (否则AopContext.currentProxy()) 会抛出异常。 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;@SpringBootApplication@EnableAspectJAutoProxy(exposeProxy=true)public class TransactionApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(GwSpykerApplication.class, args); &#125;&#125;调用地方修改为:((TestService)AopContext.currentProxy()).child() (2）传统Spring XML配置文件只需要添加依赖个设置如下配置即可，使用方式一样： 2、通过ApplicationContext上下文进行解决12345678910111213141516171819202122232425262728293031323334353637383940@Servicepublic class TestServiceImpl implements TestService &#123; @Autowired private UserMapper userMapper; /** * Spring应用上下文 */ @Autowired private ApplicationContext context; private TestService proxy; @PostConstruct public void init() &#123; //从Spring上下文中获取AOP代理对象 proxy = context.getBean(TestService.class); &#125; @Override @Transactional public void parent() &#123; User parent = new User(\"张大壮 Parent\", \"123456\", 45); userMapper.insert(parent); try &#123; proxy.child(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override @Transactional(propagation = Propagation.REQUIRES_NEW) public void child() &#123; User child = new User(\"张大壮 Child\", \"654321\", 25); userMapper.insert(child); throw new RuntimeException(\"child Exception....................\"); &#125;&#125; 12345678910111213141516171819202122232425262728migration方法调用singleProcess方法singleProcess方法的事务配置会被忽略出现的结果是两个方法执行的数据库操作都成功了 @Transactional @Override public void migration() &#123; B2bPartnerTmpDO record = new B2bPartnerTmpDO(); record.setId(100008001L); record.setCorpDescription(\"22\"); partnerTmpManager.updateByPrimaryKeySelective(record); try &#123; singleProcess();//调用目标对象的方法，不能触发对singleProcess方法的事务增强 &#125;catch (Exception ex)&#123; log.error(\"出现异常:\"+ex.getMessage()); &#125; &#125; @Transactional(propagation=Propagation.REQUIRES_NEW) public void singleProcess()&#123; B2bPartnerTmpDO record = new B2bPartnerTmpDO(); record.setId(100008002L); record.setCorpDescription(\"33\"); partnerTmpManager.updateByPrimaryKeySelective(record); throw new RuntimeException(\"singleProcess出现异常\"); &#125; 123456789101112131415161718192021222324migration方法调用singleProcess方法，singleProcess方法的事务配置会被忽略出现的结果是两个方法的代码合并在一起了，执行的数据库操作都回滚了 @Transactional @Override public void migration() &#123; B2bPartnerTmpDO record = new B2bPartnerTmpDO(); record.setId(100008001L); record.setCorpDescription(\"22\"); partnerTmpManager.updateByPrimaryKeySelective(record); singleProcess();//调用目标对象的方法，不能触发对singleProcess方法的事务增强 throw new RuntimeException(\"migration出现异常\"); &#125; @Transactional(propagation=Propagation.REQUIRES_NEW) public void singleProcess()&#123; B2bPartnerTmpDO record = new B2bPartnerTmpDO(); record.setId(100008002L); record.setCorpDescription(\"33\"); partnerTmpManager.updateByPrimaryKeySelective(record); &#125; 123456789101112131415161718192021222324252627282930结果是migration的sql执行成功，singleProcess方法是新启一个事务，事务出现异常进行回滚，singleProcess方法sql执行回滚了。 @Autowired private MigrationService migrationService;//引用代理自身的代理对象 @Transactional @Override public void migration() &#123; B2bPartnerTmpDO record = new B2bPartnerTmpDO(); record.setId(100008001L); record.setCorpDescription(\"22\"); partnerTmpManager.updateByPrimaryKeySelective(record); try &#123; //调用代理对象的方法，能触发对singleProcess方法的事务增强 migrationService.singleProcess(); &#125;catch (Exception ex)&#123; log.error(\"出现异常:\"+ex.getMessage()); &#125; &#125; @Transactional(propagation=Propagation.REQUIRES_NEW) public void singleProcess()&#123; B2bPartnerTmpDO record = new B2bPartnerTmpDO(); record.setId(100008002L); record.setCorpDescription(\"33\"); partnerTmpManager.updateByPrimaryKeySelective(record); throw new RuntimeException(\"singleProcess出现异常\"); &#125; 12345678910111213141516171819202122232425262728293031323334353637虽然在migration方法中对singleProcess方法出现的异常进行catch了，catch后面的sql语句也能执行下去，但是最终的结果是所有数据库操作都回滚了。 @Autowired private MigrationService migrationService; @Transactional @Override public void migration() &#123; B2bPartnerTmpDO record = new B2bPartnerTmpDO(); record.setId(100008001L); record.setCorpDescription(\"22\"); partnerTmpManager.updateByPrimaryKeySelective(record); //migrationService.singleProcess(); try &#123; migrationService.singleProcess(); &#125;catch (Exception ex)&#123; log.error(\"出现异常:\"+ex.getMessage()); &#125; B2bPartnerTmpDO record2 = new B2bPartnerTmpDO(); record2.setId(100008003L); record2.setCorpDescription(\"44\"); partnerTmpManager.updateByPrimaryKeySelective(record2); &#125; @Transactional public void singleProcess()&#123; B2bPartnerTmpDO record = new B2bPartnerTmpDO(); record.setId(100008002L); record.setCorpDescription(\"33\"); partnerTmpManager.updateByPrimaryKeySelective(record); throw new RuntimeException(\"singleProcess出现异常\"); &#125;","categories":[],"tags":[]},{"title":"性能优化相关linux命令","slug":"性能优化相关linux命令","date":"2018-03-13T08:48:10.000Z","updated":"2018-03-14T12:56:36.000Z","comments":true,"path":"2018/03/13/性能优化相关linux命令/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/13/性能优化相关linux命令/","excerpt":"","text":"性能优化相关linux命令 top命令top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器，查看系统平均负载和 CPU 使用率 平均负载有三个数字：63.66，58.39，57.18，分别表示过去 1 分钟、5 分钟、15 分钟机器的负载。按照经验，若数值小于 0.7*CPU 个数，则系统工作正常；若超过这个值，甚至达到 CPU 核数的四五倍，则系统的负载就明显偏高 命令格式：top [参数] 命令功能：显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 默认以pid倒序排序命令参数： top [-a | -d | -e | -c &lt;mode&gt;] [-F | -f] [-h] [-i &lt;interval&gt;] [-l &lt;samples&gt;] [-ncols &lt;columns&gt;] [-o &lt;key&gt;] [-O &lt;skey&gt;] [-R | -r] [-S] [-s &lt;delay&gt;] [-n &lt;nprocs&gt;] [-stats &lt;keys&gt;] [-pid &lt;processid&gt;] [-user &lt;username&gt;] [-U &lt;username&gt;] [-u] [-a | -d | -e | -c &lt;mode&gt;] -c &lt;mode&gt; a 累积模式,从top命令执行开始计算 d delta模式 e 绝对模式，计算事件的绝对数量 n 无事件模式，为默认模式 -a 等同与-c a，类似的-d、-e 分别等同与-c d、-c e [-F | -f] -F 不计算共享内存 -f 计算共享内存，默认 [-h] 打印信息并退出 **这个参数执行不了** [-i &lt;interval&gt;] 每隔多少秒更新信息 [-l &lt;samples&gt;] [-ncols &lt;columns&gt;] [-o &lt;key&gt;] [-O &lt;secondaryKey&gt;] -o &lt;key&gt; 第一排序字段 -O &lt;secondaryKey&gt; 第二排序字段 支持以下key，key前面可以带上+或-，用于说明倒序还是正序： pid 默认 cpu cpu_me CPU time charged to me by other processes. cpu_others CPU time charged to other processes by me csw 上下文切换次数 time 执行时间 threads 别名为th，线程数量（总的线程数/运行中线程数） ports 别名prt，机器端口数量 mregion 别名mreg, reg，内存区数量 mem 内存大小 rprvt 常驻私有地址空间大小 purg 可移除内存大小 vsize Total memory size. vprvt Private address space size. kprvt Private kernel memory size. kshrd Shared kernel memory size. pgrp Process group id. ppid Parent process id. state alias: pstate Process state. uid User ID. wq alias: #wq, workqueue The workqueue total/running. faults alias: fault The number of page faults. cow alias: cow_faults The copy-on-write faults. user alias: username Username. msgsent Total number of mach messages sent. msgrecv Total number of mach messages received. sysbsd Total BSD syscalls. sysmach Total Mach syscalls. -R Do not traverse and report the memory object map for each process. -r Traverse and report the memory object map for each process (de- fault). -S Display the global statistics for swap and purgeable memory. -s &lt;delay&gt; 每隔多少秒更新显示 Set the delay between updates to &lt;delay&gt; seconds. The default delay between updates is 1 second. -stats &lt;keys&gt; Only display the comma separated statistics. See the -o flag for the valid &lt;keys&gt;. -pid &lt;processid&gt; Only display &lt;processid&gt; in top. This option may be specified multiple times. -user &lt;user&gt; Only display processes owned by &lt;user&gt;. -U &lt;user&gt; This is an alias for -user. -u This is an alias equivalent to: -o cpu -O time. 交互式命令： ? Display the help screen. Any character exits help screen mode. This command always works, even in the middle of a command. ^L Redraw the screen. c&lt;mode&gt; Set output mode to &lt;mode&gt;. The supported modes are: a Accumulative mode. d Delta mode. e Event mode. n Non-event mode. O&lt;skey&gt; Use &lt;skey&gt; as a secondary key when ordering the process display. See the -o option for key names. o&lt;key&gt; Order the process display by sorting on &lt;key&gt; in descending or- der. A + or - can be prefixed to the key name to specify as- cending or descending order, respectively. The supported keys and alises are listed with the -o option above. q Quit. r Toggle traversal and reporting of the memory object map for each process. S&lt;signal&gt;&lt;pid&gt; Send &lt;sig&gt; to &lt;pid&gt;. &lt;sig&gt; can be specified either as a number or as a name (for example, HUP). The default signal starts out as TERM. Each time a signal is successfully sent, the default signal is updated to be that signal. &lt;pid&gt; is a process id. s&lt;delay&gt; Set the delay between updates to &lt;delay&gt; seconds. U&lt;user&gt; Only display processes owned by &lt;user&gt;. Either the username or uid number can be specified. To display all processes, press enter without entering a username or uid number. 示例： top -o cpu -O +rsize -s 5 -n 20 Sort the processes according to CPU usage (descending) and resi- dent memory size (ascending), sample and update the display at 5 second intervals, and limit the display to 20 processes. top -c d Run top in delta mode. top -stats pid,command,cpu,th,pstate,time Display only the specified statistics, regardless of any growth of the terminal. If the terminal is too small, only the statis- tics that fit will be displayed. 相关命令： kill(2), vm_stat(1), signal(3), vmmap(1)","categories":[],"tags":[]},{"title":"多线程","slug":"多线程","date":"2018-03-12T11:51:15.000Z","updated":"2018-03-12T11:54:36.000Z","comments":true,"path":"2018/03/12/多线程/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/多线程/","excerpt":"","text":"##多线程三种来实现线程安全的手段: 互斥同步通过加锁来实现对临界资源的访问限制。加锁方式有Synchorized和Lock 非阻塞同步前面提到的互斥同步属于一种悲观锁机制，非阻塞同步属于乐观锁机制。典型的实现方式就是CAS操 作 无同步方案要保证线程安全，并不是一定就需要同步，两者没有因果关系，同步只是保证共享数据征用时正确性的手段，如果一个方法本来就不涉及共享数据，那它就不需要任何同步措施去保证正确性。ThreadLocal就是这张实现方案","categories":[],"tags":[]},{"title":"jdk 8 lambda","slug":"java lambda","date":"2018-03-12T09:36:17.000Z","updated":"2018-06-25T15:33:19.000Z","comments":true,"path":"2018/03/12/java lambda/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/java lambda/","excerpt":"","text":"jdk 8 lambda 1、匿名类 12345678910111213141516171、匿名类new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"Before Java8, too much code for too little to do\"); &#125;&#125;).start();2、lambdanew Thread( () -&gt; System.out.println(\"In Java8, Lambda expression rocks !!\") ).start();lambda可以写出如下代码：(params) -&gt; expression(params) -&gt; statement(params) -&gt; &#123; statements &#125; 2、事件 1234567891011121314// Java 8之前：JButton show = new JButton(\"Show\");show.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println(\"Event handling without lambda expression is boring\"); &#125;&#125;);// Java 8方式：show.addActionListener((e) -&gt; &#123; System.out.println(\"Light, Camera, Action !! Lambda expressions Rocks\");&#125;); 3、迭代 12345678910111213// Java 8之前：List features = Arrays.asList(\"Lambdas\", \"Default Method\", \"Stream API\", \"Date and Time API\");for (String feature : features) &#123; System.out.println(feature);&#125;// Java 8之后：List features = Arrays.asList(\"Lambdas\", \"Default Method\", \"Stream API\", \"Date and Time API\");features.forEach(n -&gt; System.out.println(n)); // 使用Java 8的方法引用更方便，方法引用由::双冒号操作符标示，// 看起来像C++的作用域解析运算符features.forEach(System.out::println); 4、函数式接口Predicate 12345678910111213141516171819202122232425262728293031323334353637383940414243public static void main(args[])&#123; List languages = Arrays.asList(\"Java\", \"Scala\", \"C++\", \"Haskell\", \"Lisp\"); System.out.println(\"Languages which starts with J :\"); filter(languages, (str)-&gt;str.startsWith(\"J\")); System.out.println(\"Languages which ends with a \"); filter(languages, (str)-&gt;str.endsWith(\"a\")); System.out.println(\"Print all languages :\"); filter(languages, (str)-&gt;true); System.out.println(\"Print no language : \"); filter(languages, (str)-&gt;false); System.out.println(\"Print language whose length greater than 4:\"); filter(languages, (str)-&gt;str.length() &gt; 4);&#125; public static void filter(List names, Predicate condition) &#123; for(String name: names) &#123; if(condition.test(name)) &#123; System.out.println(name + \" \"); &#125; &#125;&#125;// 更好的办法public static void filter(List names, Predicate condition) &#123; names.stream().filter((name) -&gt; (condition.test(name))).forEach((name) -&gt; &#123; System.out.println(name + \" \"); &#125;);&#125;将两个或更多的 Predicate 合成一个// 甚至可以用and()、or()和xor()逻辑函数来合并Predicate，// 例如要找到所有以J开始，长度为四个字母的名字，你可以合并两个Predicate并传入Predicate&lt;String&gt; startsWithJ = (n) -&gt; n.startsWith(\"J\");Predicate&lt;String&gt; fourLetterLong = (n) -&gt; n.length() == 4;names.stream() .filter(startsWithJ.and(fourLetterLong)) .forEach((n) -&gt; System.out.print(\"nName, which starts with 'J' and four letter long is : \" + n)); 5、map、reduce reduce() 函数可以将所有值合并成一个 12345678910111213141516171819202122232425262728293031323334353637383940414243// 不使用lambda表达式为每个订单加上12%的税List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);for (Integer cost : costBeforeTax) &#123; double price = cost + .12*cost; System.out.println(price);&#125; // 使用lambda表达式List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).forEach(System.out::println);// 为每个订单加上12%的税// 老方法：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double total = 0;for (Integer cost : costBeforeTax) &#123; double price = cost + .12*cost; total = total + price;&#125;System.out.println(\"Total : \" + total); // 新方法：List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double bill = costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).reduce((sum, cost) -&gt; sum + cost).get();System.out.println(\"Total : \" + bill);// 创建一个字符串列表，每个字符串长度大于2List&lt;String&gt; filtered = strList.stream().filter(x -&gt; x.length()&gt; 2).collect(Collectors.toList());System.out.printf(\"Original List : %s, filtered list : %s %n\", strList, filtered);// 将字符串换成大写并用逗号链接起来List&lt;String&gt; G7 = Arrays.asList(\"USA\", \"Japan\", \"France\", \"Germany\", \"Italy\", \"U.K.\",\"Canada\");String G7Countries = G7.stream().map(x -&gt; x.toUpperCase()).collect(Collectors.joining(\", \"));System.out.println(G7Countries);// 用所有不同的数字创建一个正方形列表List&lt;Integer&gt; numbers = Arrays.asList(9, 10, 3, 4, 7, 3, 4);List&lt;Integer&gt; distinct = numbers.stream().map( i -&gt; i*i).distinct().collect(Collectors.toList());System.out.printf(\"Original List : %s, Square Without duplicates : %s %n\", numbers, distinct); 6、计算集合元素的最大值、最小值、总和以及平均值 IntStream、LongStream 和 DoubleStream 等流的类中，有个非常有用的方法叫做 summaryStatistics() 。可以返回 IntSummaryStatistics、LongSummaryStatistics 或者 DoubleSummaryStatistic s，描述流中元素的各种摘要数据。在本例中，我们用这个方法来计算列表的最大值和最小值。它也有 getSum() 和 getAverage() 方法来获得列表的所有元素的总和及平均值。 1234567//获取数字的个数、最小值、最大值、总和以及平均值List&lt;Integer&gt; primes = Arrays.asList(2, 3, 5, 7, 11, 13, 17, 19, 23, 29);IntSummaryStatistics stats = primes.stream().mapToInt((x) -&gt; x).summaryStatistics();System.out.println(\"Highest prime number in List : \" + stats.getMax());System.out.println(\"Lowest prime number in List : \" + stats.getMin());System.out.println(\"Sum of all prime numbers : \" + stats.getSum());System.out.println(\"Average of all prime numbers : \" + stats.getAverage()); 7、结束 泛型、枚举、自动装箱（Autoboxing）、静态导入、并发API和变量参数 1、lambda表达式有个限制，那就是只能引用 final 或 final 局部变量，这就是说不能在lambda内部修改定义在域外的变量 2、lambda表达式仅能放入如下代码：预定义使用了 @Functional 注释的函数式接口，自带一个抽象函数的方法，或者SAM（Single Abstract Method 单个抽象方法）类型。这些称为lambda表达式的目标类型，可以用作返回类型，或lambda目标代码的参数。例如，若一个方法接收Runnable、Comparable或者 Callable 接口，都有单个抽象方法，可以传入lambda表达式。类似的，如果一个方法接受声明于 java.util.function 包内的接口，例如 Predicate、Function、Consumer 或 Supplier，那么可以向其传lambda表达式","categories":[],"tags":[]},{"title":"mysql常用","slug":"mysql总结","date":"2018-03-12T09:36:17.000Z","updated":"2018-10-19T06:08:12.000Z","comments":true,"path":"2018/03/12/mysql总结/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/mysql总结/","excerpt":"","text":"mysql常用 1、查找子字符串在字符串中的位置，类似oracle的indexof方法 12345LOCATE(substr,str), LOCATE(substr,str,pos) 第一个语法返回substr在字符串str 的第一个出现的位置。 第二个语法返回子符串 substr 在字符串str，从pos处开始的第一次出现的位置。如果substr 不在str 中，则返回值为0 。 2、ON UPDATE CURRENT_TIMESTAMPgmt_modified datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT ‘修改时间’ 3、 char_length、length函数length:是计算字段的长度一个汉字是算三个字符,一个数字或字母算一个字符char_length:不管汉字还是数字或者是字母都算是一个字符","categories":[],"tags":[]},{"title":"ThreadLocal","slug":"ThreadLocal","date":"2018-03-12T09:36:17.000Z","updated":"2018-03-12T10:07:41.000Z","comments":true,"path":"2018/03/12/ThreadLocal/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/ThreadLocal/","excerpt":"","text":"ThreadLocal synchronized 以时间换空间 ThreadLocal 以空间换时间 Thread类保存了ThreadLocalMap类型的变量, ThreadLocalMap的key为ThreadLoacal对象 1ThreadLocal.ThreadLocalMap threadLocals = null; ThreadLocal类，支持范型 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 示例1234567891011121314151617181920212223242526272829import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;public class ConnectionManager &#123; private static ThreadLocal&lt;Connection&gt; connectionHolder = new ThreadLocal&lt;Connection&gt;() &#123; @Override protected Connection initialValue() &#123; Connection conn = null; try &#123; conn = DriverManager.getConnection( \"jdbc:mysql://localhost:3306/test\", \"username\", \"password\"); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return conn; &#125; &#125;; public static Connection getConnection() &#123; return connectionHolder.get(); &#125; public static void setConnection(Connection conn) &#123; connectionHolder.set(conn); &#125;&#125; 可以创建不同的ThreadLocal实例来实现多个变量在不同线程间的访问隔离，为什么可以这么做？因为不同的ThreadLocal对象作为不同键，当然也可以在线程的ThreadLocalMap对象中设置不同的值了。通过ThreadLocal对象，在多线程中共享一个值和多个值的区别，就像你在一个HashMap对象中存储一个键值对和多个键值对一样，仅此而已","categories":[],"tags":[]},{"title":"mac linux","slug":"mac linux","date":"2018-03-12T09:36:17.000Z","updated":"2018-10-12T08:55:43.000Z","comments":true,"path":"2018/03/12/mac linux/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/mac linux/","excerpt":"","text":"linux 1、端口占用及杀死占用进程sudo lsof -i:8080sudo kill -9 2123 2、搜索日志，并打印前后100行的内容cat jetty_stdout.log | grep -C 100 注意接受到流程消息 3、从服务器上下载文件scp publish@172.21.10.70:/home/publish/antx/finance/dev/antx-volks.properties /Users/user/ 4、docker容器命令docker logs -f ld9 看日志 docker ps -a | grep volks 查看应用iddocker exec -it 1d9 /bin/bash 执行指定应用id的应用 sudo su - admin 切换admin后才能执行docker命令 5、显示或隐藏隐藏文件快捷键：Command + Shift + .","categories":[],"tags":[]},{"title":"mysql常用","slug":"dubbo服务调用三次的问题","date":"2018-03-12T09:36:17.000Z","updated":"2018-05-25T16:52:55.000Z","comments":true,"path":"2018/03/12/dubbo服务调用三次的问题/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/dubbo服务调用三次的问题/","excerpt":"","text":"dubbo服务被调用三次的问题 该服务为涉及新增操作的服务，服务调用多次，导致数据保存了多条相同数据出现该问题，排查过程：1、通过查看数据库数据，发现有三条一样的数据，调试服务方代码，发现也进入了三次。最终在服务方打印调用日志，结果为打印了三次 2、是否消费方也请求了三次，消费方打印日志，消费方且只调用了一次，消费方只调用了一次，服务方且执行了三次，有点摸不到头脑了 3、百度搜索“dubbo服务莫名调用多次”,发现有人遇到相同问题，网上说有两种情况会导致服务调用多次，一是dubbo架包存在多个，二是服务超时重试导致的 4、网上说的原因给我提供思路，我就去检查项目中是否存在多个dubbo架包，发现存在两个不同版本的架包，我试着删除其中一个依赖其中一个版本dubbo架包的依赖配置，但是发现不管用，服务方还是调用三次；换另外一种解决方法，在服务提供方配置的暴露的服务地方设置retries属性为0，发现起作用了 检查修改服务方retries属性为0时 1、消费方日志： org.springframework.web.util.NestedServletException: Request processing failed; nested exception is com.alibaba.dubbo.rpc.RpcException: Failed to invoke the method commitApply in the service com.mhc.spyker.api.service.AdmittanceApplyFacade. Tried 1 times of the providers [192.168.0.105:20882] (1/1) from the registry 172.21.10.42:2181 on the consumer 192.168.0.105 using the dubbo version 2.5.3. Last error is: Invoke remote method timeout. method: commitApply Caused by: com.alibaba.dubbo.rpc.RpcException: Failed to invoke the method commitApply in the service com.mhc.spyker.api.service.AdmittanceApplyFacade. Tried 1 times of the providers [192.168.0.105:20882] (1/1) from the registry 172.21.10.42:2181 on the consumer 192.168.0.105 using the dubbo version 2.5.3. Last error is: Invoke remote method timeout. method: commitApply, Caused by: com.alibaba.dubbo.remoting.TimeoutException: Waiting server-side response timeout by scan timer. start time: 2018-05-26 00:38:45.035, end time: 2018-05-26 00:38:46.044, client elapsed: 11 ms, server elapsed: 998 ms, timeout: 1000 ms, 2、服务方日志,打印服务方执行时间，结果为1684ms2018-05-26 00:38:46.697 DEBUG 5913 — [:20882-thread-2] c.m.s.d.d.A.updateById : ==&gt; Parameters: 4268340(String), 111(Long)2018-05-26 00:38:46.721 DEBUG 5913 — [:20882-thread-2] c.m.s.d.d.A.updateById : &lt;== Updates: 1 Time：24 ms - ID：com.mhc.spyker.dal.dao.AdmittanceApplyRecordDao.updateById Execute SQL： UPDATE b2b_admittance_apply_record SET process_InstanceId=’4268340’ WHERE id=111 时间：16842018-05-26 00:39:45.878 INFO 5913 — [dTimer-thread-1] c.a.dubbo.monitor.dubbo.DubboMonitor : [DUBBO] Send statistics to monitor zookeeper://172.21.10.42:2181/com.alibaba.dubbo.monitor.MonitorService?dubbo=2.6.0&amp;interface=com.alibaba.dubbo.monitor.MonitorService&amp;pid=5913&amp;timestamp=1527265217854, dubbo version: 2.6.0, current host: 192.168.0.1052018-05-26 00:39:45.880 ERROR 5913 — [dTimer-thread-1] c.a.dubbo.monitor.dubbo.DubboMonitor : [DUBBO] Unexpected error occur at send statistic, cause: No provider available from registry 172.21.10.42:2181 for service com.alibaba.dubbo.monitor.MonitorService on consumer 192.168.0.105 use dubbo version 2.6.0, may be providers disabled or not registered ?, dubbo version: 2.6.0, current host: 192.168.0.105 通过日志能看出服务默认超时时间timeout为1000ms，超时默认最多重试两次，导致该问题的原因服务方的执行时间大于超时时间1000ms，导致重试了两次 涉及修改操作： 1、需要把retries设置为0，建议在服务消费方设置 2、需要在服务方设置timeout属性，建议在服务提供方设置（服务提供方了解服务执行时间）","categories":[],"tags":[]},{"title":"json序列化、反序列化","slug":" json序列化、反序列化","date":"2018-03-12T09:36:17.000Z","updated":"2018-08-14T06:14:02.000Z","comments":true,"path":"2018/03/12/ json序列化、反序列化/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/ json序列化、反序列化/","excerpt":"","text":"json序列化、反序列化 一、fastjson： 1、序列化 设置某些字段不需要序列化在属性上面加@JSONField(serialize = false)注解 2、是否输出值为null的字段,默认为falsenull对应的key已经被过滤掉；这明显不是我们想要的结果，这时我们就需要用到fastjson的SerializerFeature序列化属性 也就是这个方法：JSONObject.toJSONString(Object object, SerializerFeature… features) Fastjson的SerializerFeature序列化属性- QuoteFieldNames———-输出key时是否使用双引号,默认为trueWriteMapNullValue——–是否输出值为null的字段,默认为falseWriteNullNumberAsZero—-数值字段如果为null,输出为0,而非nullWriteNullListAsEmpty—–List字段如果为null,输出为[],而非nullWriteNullStringAsEmpty—字符类型字段如果为null,输出为”“,而非nullWriteNullBooleanAsFalse–Boolean字段如果为null,输出为false,而非null QuoteFieldNames WriteMapNullValue application/json 二、Gson gsonBuilder.setLongSerializationPolicy(LongSerializationPolicy.STRING) .setDateFormat(“yyyy-MM-dd HH:mm”) .serializeNulls(); 在对象序列化为json字符串时，默认是不序列化NULL对象的，如果在序列化时设置serializeNulls了，就可以支持NULL的序列化。注意serializeNulls对反序列化没有影响 setPrettyPrinting:把json无格式字符串转换为带格式的字符串 excludeFieldsWithModifiers(Modifier.PRIVATE):Gson在解析时，把类中字段的PRIVATE访问权限排除，就是遇到private修饰的字段时，Gson不做解析；（还可以对有final，static等修饰的变量，或者修饰类的abstract，或者类是接口的等等，都可以做出控制解析 setLongSerializationPolicy:设置对Long类型的变量，是解析成字符串还是解析为long类型，可以这样设置如下：Gson gson = newGsonBuilder. setLongSerializationPolicy(LongSerializationPolicy.DEFAULT).create(),其中LongSerializationPolicy.DEFAULT为默认值，Long类型转换为Long型，LongSerializationPolicy.STRING为字符串型，就是把Long类型的值强制转换为字符串类型 默认情况下@Expose注解是不起作用的,除非你用GsonBuilder创建Gson的时候调用了GsonBuilder.excludeFieldsWithoutExposeAnnotation()方法 123456789101112131415161718192021222324252627282930public class User &#123; private String id; @Expose //默认情况下序列化和反序列化都会使用 private String userName; @Expose(serialize=true,deserialize=false)//序列化时使用，反序列化不使用 private String userPwd; @Expose private Integer age; private Float price; @Expose private Date birthday; public User(String id, String userName, String userPwd, Integer age, Float price, Date birthday) &#123; this.id = id; this.userName = userName; this.userPwd = userPwd; this.age = age; this.price = price; this.birthday = birthday; &#125; get()和set()方法省略！ @Override public String toString() &#123; return \"User [id=\" + id + \", userName=\" + userName + \", userPwd=\" + userPwd + \", age=\" + age + \", price=\" + price + \", birthday=\" + birthday + \"]\"; &#125; &#125; 123456789101112131415Gson gson = new GsonBuilder() .excludeFieldsWithoutExposeAnnotation() //不导出实体中没有用@Expose注解的属性 .serializeNulls() //当需要序列化的值为空时，采用null映射，否则会把该字段省略 .setDateFormat(\"yyyy-MM-dd HH:mm:ss\") //日期格式转换 .setFieldNamingPolicy(FieldNamingPolicy.UPPER_CAMEL_CASE) //将属性的首字母大写 .setPrettyPrinting() //将结果进行格式化 .create(); User user = new User(\"A001\", \"xl\",\"xl_123\",24,12000F,new Date()); user.setAge(null); String json = gson.toJson(user); System.out.println(\"序列化:\"+json); user = gson.fromJson(json,User.class); System.out.println(\"反序列化：\\n\"+user); 123456789101112131415public class User &#123; private String id; @Expose @SerializedName(\"name\") //序列化时会把userName字段名映射为name private String userName; //序列化时使用，反序列化不使用该字段,默认都等于true @Expose(serialize=true,deserialize=false) private String userPwd; @Expose private Integer age; private Float price; @Expose private Date birthday; get()和set()方法省略......! &#125; 三、 默认使用jackson序列化、反序列化json 1234567891011121314151617181920212223242526&lt;bean id=\"fastJsonConfig\" class=\"com.alibaba.fastjson.support.config.FastJsonConfig\"&gt; &lt;!-- Default charset --&gt; &lt;property name=\"charset\" value=\"UTF-8\" /&gt; &lt;!-- SerializerFeature --&gt; &lt;property name=\"serializerFeatures\"&gt; &lt;list&gt; &lt;value&gt;QuoteFieldNames&lt;/value&gt; &lt;value&gt;WriteMapNullValue&lt;/value&gt; &lt;/list&gt; &lt;/property&gt;&lt;/bean&gt;&lt;!-- handlermapping，支持@RequestMapping，@ResponseBody --&gt;&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class=\"com.alibaba.fastjson.support.spring.FastJsonHttpMessageConverter\"&gt; &lt;property name=\"supportedMediaTypes\"&gt; &lt;list&gt; &lt;value&gt;application/json;charset=UTF-8&lt;/value&gt; &lt;value&gt;text/html;charset=UTF-8&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;property name=\"fastJsonConfig\" ref=\"fastJsonConfig\"/&gt; &lt;/bean&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt;","categories":[],"tags":[]},{"title":"CAS、JUC","slug":"CAS与JUC","date":"2018-03-12T09:36:17.000Z","updated":"2018-05-11T15:06:56.000Z","comments":true,"path":"2018/03/12/CAS与JUC/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/CAS与JUC/","excerpt":"","text":"CAS与JUC","categories":[],"tags":[]},{"title":"OLTP、OLAP","slug":"OLTP、OLAP","date":"2018-03-12T09:36:17.000Z","updated":"2018-06-17T03:20:31.000Z","comments":true,"path":"2018/03/12/OLTP、OLAP/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/OLTP、OLAP/","excerpt":"","text":"OLTP、OLAP OLTP（on-line transaction processing），联机事务处理 特点： 1、实时性要求高 2、DML多 3、处理时间短 OLAP（On-Line Analytical Processing），联机分析处理 特点： 1、实时性要求不是很高 2、DML少，读多 3、数据量大","categories":[],"tags":[]},{"title":"mvn","slug":"mvn","date":"2018-03-12T09:36:17.000Z","updated":"2018-08-14T11:24:34.000Z","comments":true,"path":"2018/03/12/mvn/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/12/mvn/","excerpt":"","text":"mvn 1、使用以下命令做一次构建 mvn clean install 2、可以通过以下的构建命令来跳过单元测试 mvn install -Dmaven.test.skip 3、架包推送mvn clean package deploy -Dmaven.test.skip=true 4、冲突解决 mvn dependency:tree -Dverbose -Dincludes=commons-logging:commons-loggging 这条命令可以打印出所有依赖了groupId和artifactId都为commons-logging的jar包的依赖路径。 mvn dependency:tree -Dverbose -Dincludes=org.mybatis:mybatis -l /Users/user/log.txtmvn dependency:tree -Dverbose -Dincludes=org.mybatis:mybatis –&gt; /Users/user/log.txt输出到文件 -D 指定参数，如 -Dmaven.test.skip=true 跳过单元测试； 原则：1、第一声明优先原则 123456789101112131415&lt;dependencies&gt;&lt;!-- spring-beans-4.2.4 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring-beans-3.0.5 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.struts&lt;/groupId&gt; &lt;artifactId&gt;struts2-spring-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.24&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2、路径近者优先原则 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;4.2.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 3、排除原则 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.struts&lt;/groupId&gt; &lt;artifactId&gt;struts2-spring-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.24&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 4、版本锁定原则 1234567891011121314151617&lt;properties&gt; &lt;spring.version&gt;4.2.4.RELEASE&lt;/spring.version&gt; &lt;hibernate.version&gt;5.0.7.Final&lt;/hibernate.version&gt; &lt;struts.version&gt;2.3.24&lt;/struts.version&gt;&lt;/properties&gt; &lt;!-- 锁定版本，struts2-2.3.24、spring4.2.4、hibernate5.0.7 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; dependencies与dependencyManagement区别dependencyManagement只会影响现有依赖的配置，但不会引入依赖 dependencies即使在子项目中不写该依赖项，那么子项目仍然会从父项目中继承该依赖项（全部继承） dependencyManagement里只是声明依赖，并不实现引入，因此子项目需要显示的声明需要用的依赖。如果不在子项目中声明依赖，是不会从父项目中继承下来的；只有在子项目中写了该依赖项，并且没有指定具体版本，才会从父项目中继承该项，并且version和scope都读取自父pom;另外如果子项目中指定了版本号，那么会使用子项目中指定的jar版本。","categories":[],"tags":[]},{"title":"spring aop","slug":"spring aop","date":"2018-03-11T15:08:14.000Z","updated":"2018-03-11T15:24:10.000Z","comments":true,"path":"2018/03/11/spring aop/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/11/spring aop/","excerpt":"","text":"spring aop @Transactional 在需要事务管理的地方加@Transactional 注解。@Transactional 注解可以被应用于接口定义和接口方法、类定义和类的 public 方法上。 @Transactional 注解只能应用到 public 可见度的方法上。 如果你在 protected、private 或者 package-visible 的方法上使用 @Transactional 注解，它也不会报错， 但是这个被注解的方法将不会展示已配置的事务设置。 注意仅仅 @Transactional 注解的出现不足于开启事务行为，它仅仅 是一种元数据。必须在配置文件中使用配置元素，才真正开启了事务行为。 通过 元素的 “proxy-target-class” 属性值来控制是基于接口的还是基于类的代理被创建。如果 “proxy-target-class” 属值被设置为 “true”，那么基于类的代理将起作用（这时需要CGLIB库cglib.jar在CLASSPATH中）。如果 “proxy-target-class” 属值被设置为 “false” 或者这个属性被省略，那么标准的JDK基于接口的代理将起作用。 Spring团队建议在具体的类（或类的方法）上使用 @Transactional 注解，而不要使用在类所要实现的任何接口上。在接口上使用 @Transactional 注解，只能当你设置了基于接口的代理时它才生效。因为注解是 不能继承 的，这就意味着如果正在使用基于类的代理时，那么事务的设置将不能被基于类的代理所识别，而且对象也将不会被事务代理所包装。 @Transactional 的事务开启 ，或者是基于接口的 或者是基于类的代理被创建。所以在同一个类中一个方法调用另一个方法有事务的方法，事务是不会起作用的。 1、@Transactional 只能应用到 public 方法才有效 2、避免 Spring 的 AOP 的自调用问题 在 Spring 的 AOP 代理下，只有目标方法由外部调用，目标方法才由 Spring 生成的代理对象来管理，这会造成自调用问题。若同一类中的其他没有@Transactional 注解的方法内部调用有@Transactional 注解的方法，有@Transactional 注解的方法的事务被忽略，不会发生回滚。 123456789101112@Servicepublic class OrderService &#123; private void insert() &#123; insertOrder(); &#125; @Transactional public void insertOrder() &#123; //insert log info //insertOrder //updateAccount &#125;&#125;","categories":[],"tags":[]},{"title":"拦截器","slug":"拦截器","date":"2018-03-07T09:47:55.000Z","updated":"2018-03-08T11:27:38.000Z","comments":true,"path":"2018/03/07/拦截器/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/03/07/拦截器/","excerpt":"","text":"拦截器标签（空格分隔）： java 拦截器 过滤器 拦截器 过滤器 监听器 拦截器与过滤器的区别 过滤器可以简单的理解为“取你所想取”，过滤器关注的是web请求； 拦截器可以简单的理解为“拒你所想拒”，拦截器关注的是方法调用，比如拦截敏感词汇 拦截器是基于java反射机制的，而过滤器是基于函数回调。 拦截器不依赖于Servlet容器，而过滤器依赖于servlet容器。 拦截器只能对action请求起作用，而过滤器可以对几乎所有的请求起作用。 拦截器可以访问action上下文，值栈里的对象，而过滤器不能。在Action的生命周期周，拦截器可以被多次调用，而过滤器只能在容器初始化的时候被调用一次。 执行顺序 ：过滤前 - 拦截前 - Action处理 - 拦截后 - 过滤后过滤器是横向过程 你传入的request,response提前过滤掉一些信息，或者提前设置一些参数，然后再传入servlet或者struts的action进行业务逻辑，比如过滤掉非法url（不是login.do的地址请求，如果用户没有登陆都过滤掉）,或者在传入servlet或者struts的action前统一设置字符集，或者去除掉一些非法字符（聊天室经常用到的，一些骂人的话）。filter 流程是线性的，url传来之后，检查之后 拦截器拦截器的原理是基于jdk动态代理，需实现HandlerInterceptor接口或继承HandlerInterceptorAdapter类 1234567891011121314151617181920212223242526272829303132333435363738394041HandlerInterceptor接口：/*** preHandle方法是进行处理器拦截用的，顾名思义，该方法将在Controller处理之前进行调用，* SpringMVC中的Interceptor拦截器是链式的，可以同时存在多个Interceptor，* 然后SpringMVC会根据声明的前后顺序一个接一个的执行，* 而且所有的Interceptor中的preHandle方法都会在Controller方法调用之前调用。* SpringMVC的这种Interceptor链式结构也是可以进行中断的，* 这种中断方式是令preHandle的返回值为false，当preHandle的返回值为false的时候整个请求就结束了。*/@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)throws Exception &#123;return true;&#125;/*** 这个方法只会在当前这个Interceptor的preHandle方法返回值为true的时候才会执行。* postHandle是进行处理器拦截用的，它的执行时间是在处理器进行处理之 后， 也就是在Controller的方法调用之后执行，* 但是它会在DispatcherServlet进行视图的渲染之前执行，也就是说在这个方法中你可以对ModelAndView进行操作。* 这个方法的链式结构跟正常访问的方向是相反的，也就是说先声明的Interceptor拦截器该方法反而会后调用，* 这跟Struts2里面的拦截器的执行过程有点像，* 只是Struts2里面的intercept方法中要手动的调用ActionInvocation的invoke方法，* Struts2中调用ActionInvocation的invoke方法就是调用下一个Interceptor或者是调用action，* 然后要在Interceptor之前调用的内容都写在调用invoke之前，要在Interceptor之后调用的内容都写在调用invoke方法之后。*/@Overridepublic void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView)throws Exception &#123;&#125;/*** 该方法也是需要当前对应的Interceptor的preHandle方法的返回值为true时才会执行。* 该方法将在整个请求完成之后，也就是DispatcherServlet渲染了视图执行， 这个方法的主要作用是用于清理资源的，*/@Overridepublic void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)throws Exception &#123;&#125; 配置123456789101112131415&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"xmlns:mvc=\"http://www.springframework.org/schema/mvc\"xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsdhttp://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd\"&gt;&lt;mvc:interceptors&gt;&lt;!-- 日志拦截器 --&gt;&lt;mvc:interceptor&gt;&lt;mvc:mapping path=\"/**\" /&gt;&lt;mvc:exclude-mapping path=\"/static/**\" /&gt;&lt;bean class=\"拦截器java代码路径\" /&gt;&lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt;&lt;/beans&gt; 工作流程一个拦截器，只有preHandle方法返回true，postHandle、afterCompletion才有可能被执行；如果preHandle方法返回false，则该拦截器的postHandle、afterCompletion必然不会被执行。 假设我们有两个拦截器，例如叫Interceptor1和Interceptor2，当一个请求过来，正常的流程和中断的流程分别如下。 正常流程注意两个拦截器在执行preHandle方法和执行postHandle、afterCompletion方法时，顺序是颠倒的。 1234567891011121314151. Interceptor1.preHandle2. Interceptor2.preHandle3. Controller处理请求4. Interceptor2.postHandle5. Interceptor1.postHandle6. 渲染视图7. Interceptor2.afterCompletion8. Interceptor1.afterCompletion 中断流程假设执行Interceptor2.preHandle中报错，那么流程被中断，之前被执行过的拦截器的afterCompletion仍然会执行。在本例中，即执行了Interceptor1.afterCompletion。 12345671. Interceptor1.preHandle2. Interceptor2.preHandle//中间流程被中断，不再执行3. Interceptor1.afterCompletion 与过滤器共存时的执行顺序拦截器是在DispatcherServlet这个servlet中执行的，因此所有的请求最先进入Filter，最后离开Filter。其顺序如下。 Filter-&gt;Interceptor.preHandle-&gt;Handler-&gt;Interceptor.postHandle-&gt;Interceptor.afterCompletion-&gt;Filter 应用场景拦截器本质上是面向切面编程（AOP），符合横切关注点的功能都可以放在拦截器中来实现，主要的应用场景包括： 登录验证，判断用户是否登录。权限验证，判断用户是否有权限访问资源。日志记录，记录请求日志，以便统计请求访问量。处理cookie、本地化、国际化、主题等。性能监控，监控请求处理时长等。 spring boot配置拦截器为了使自定义的拦截器生效，需要注册拦截器到spring容器中，具体的做法是继承WebMvcConfigurerAdapter类，覆盖其addInterceptors(InterceptorRegistry registry)方法。最后别忘了把Bean注册到Spring容器中，可以选择@Component 或者 @Configuration 123456789101112131415@Componentpublic class InterceptorConfiguration extends WebMvcConfigurerAdapter&#123;@Overridepublic void addInterceptors(InterceptorRegistry registry) &#123;// 注册拦截器InterceptorRegistration ir = registry.addInterceptor(new LoginInterceptor());// 配置拦截的路径ir.addPathPatterns(&quot;/**&quot;);// 配置不拦截的路径ir.excludePathPatterns(&quot;/**.html&quot;);// 还可以在这里注册其它的拦截器//registry.addInterceptor(new OtherInterceptor()).addPathPatterns(&quot;/**&quot;);&#125;&#125;","categories":[],"tags":[]},{"title":"JAVA动态代理","slug":"动态代理","date":"2018-02-09T09:47:55.000Z","updated":"2018-04-03T05:44:39.000Z","comments":true,"path":"2018/02/09/动态代理/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/02/09/动态代理/","excerpt":"","text":"JAVA动态代理 静态代理的代理关系在编译时就确定了，而动态代理的代理关系是在运行期确定的。静态代理实现简单，适合于代理类较少且确定的情况，而动态代理则给我们提供了更大的灵活性 JDK原生动态代理是Java原生支持的，不需要任何外部依赖，但是它只能基于接口进行代理；CGLIB通过继承的方式进行代理，无论目标对象有没有实现接口都可以代理，但是无法处理final、private方法 CGLib创建的动态代理对象性能比JDK创建的动态代理对象的性能高不少，但是CGLib在创建代理对象时所花费的时间却比JDK多得多，所以对于单例的对象，因为无需频繁创建对象，用CGLib合适，反之，使用JDK方式要更为合适一些 jdk采用反射机制调用委托类的方法，cglib采用类似索引的方式直接调用委托类方法 标签（空格分隔）： jdk动态代理 cglib jdk动态代理 jdk动态代理机制中，有两个重要的类或接口，一个是Proxy，另一个是InvocationHandler Proxy类Proxy类是用来动态创建一个代理对象，经常使用newProxyInstance静态方法12345public static Object newProxyInstance(ClassLoader loader,Class&lt;?&gt;[] interfaces,InvocationHandler h) throws IllegalArgumentException参数：loader 类加载器interfaces 真实类所拥有的所有接口的数组h 调用处理器对象 InvocationHandler接口InvocationHandler接口只有唯一一个invoke方法12345public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;参数：proxy 代理类对象method 调用真实类对象某个方法对应的method对象args 调用真实类对象某个方法传入的参数 示例1、主题接口 123456package com.example.ford.proxy;public interface Subject &#123; String sayHello(String name); String sayGoodBye();&#125; 2、 被代理类 12345678910111213package com.example.ford.proxy;public class RealSubject implements Subject&#123; @Override public String sayHello(String name) &#123; return \"hello \"+name; &#125; @Override public String sayGoodBye() &#123; return \" good bye\"; &#125;&#125; 3、调用处理器 123456789101112131415161718192021package com.example.ford.proxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;public class TestInvocationHandler implements InvocationHandler&#123; private Subject subject; public TestInvocationHandler(Subject subject)&#123; this.subject = subject; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(proxy.getClass()); System.out.println(\"开始执行 \"+method.getName()); Object returnValue = method.invoke(subject,args); System.out.println(\"结束执行 \"+method.getName()); return returnValue; &#125;&#125; 3、测试 12345678910111213141516171819package com.example.ford.proxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Proxy;public class TestMain &#123; public static void main(String[] args) &#123; Subject subject = new RealSubject(); InvocationHandler handler = new TestInvocationHandler(subject); Class cls = subject.getClass(); ClassLoader loader = cls.getClassLoader(); Class[] interfaces = cls.getInterfaces(); Subject proxy = (Subject) Proxy.newProxyInstance(loader, interfaces, handler); String returnValue1 = proxy.sayHello(\"changfeng\"); System.out.println(returnValue1); String returnValue2 = proxy.sayGoodBye(); System.out.println(returnValue2); &#125;&#125; 测试结果 12345678class com.sun.proxy.$Proxy0开始执行 sayHello结束执行 sayHellohello changfengclass com.sun.proxy.$Proxy0开始执行 sayGoodBye结束执行 sayGoodBye good bye 原理分析生成代理类类文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.example.ford.proxy;import sun.misc.ProxyGenerator;import java.io.File;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Proxy;public class JDKProxyTest &#123; public static void main(String[] args)&#123; Subject subject = new RealSubject(); InvocationHandler handler = new TestInvocationHandler(subject); Class cls = subject.getClass(); ClassLoader loader = cls.getClassLoader(); Class[] interfaces = cls.getInterfaces(); Subject proxy = (Subject) Proxy.newProxyInstance(loader, interfaces, handler); createProxyClassFile(); &#125; private static void createProxyClassFile()&#123; String name = \"ProxySubject\"; byte[] data = ProxyGenerator.generateProxyClass(name,new Class[]&#123;Subject.class&#125;); FileOutputStream out =null; try &#123; out = new FileOutputStream(name+\".class\"); System.out.println((new File(\"hello\")).getAbsolutePath()); out.write(data); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if(null!=out) try &#123; out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 利用jd-gui反编译代理类class文件，可以发现最终生成的代理类继承Proxy类、实现Subject接口,代理类实现了Subject接口的sayHello方法、sayGoodBye方法,在实现Subject接口方法的内部，通过反射调用了InvocationHandlerImpl的invoke方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122import com.example.ford.proxy.Subject;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;public final class ProxySubject extends Proxy implements Subject&#123; private static Method m1; private static Method m3; private static Method m2; private static Method m4; private static Method m0; public ProxySubject(InvocationHandler paramInvocationHandler) &#123; super(paramInvocationHandler); &#125; public final boolean equals(Object paramObject) &#123; try &#123; return ((Boolean)this.h.invoke(this, m1, new Object[] &#123; paramObject &#125;)).booleanValue(); &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; public final String sayHello(String paramString) &#123; try &#123; return (String)this.h.invoke(this, m3, new Object[] &#123; paramString &#125;); &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; public final String toString() &#123; try &#123; return (String)this.h.invoke(this, m2, null); &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; public final String sayGoodBye() &#123; try &#123; return (String)this.h.invoke(this, m4, null); &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; public final int hashCode() &#123; try &#123; return ((Integer)this.h.invoke(this, m0, null)).intValue(); &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; static &#123; try &#123; m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", new Class[] &#123; Class.forName(\"java.lang.Object\") &#125;); m3 = Class.forName(\"com.example.ford.proxy.Subject\").getMethod(\"sayHello\", new Class[] &#123; Class.forName(\"java.lang.String\") &#125;); m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\", new Class[0]); m4 = Class.forName(\"com.example.ford.proxy.Subject\").getMethod(\"sayGoodBye\", new Class[0]); m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\", new Class[0]); return; &#125; catch (NoSuchMethodException localNoSuchMethodException) &#123; throw new NoSuchMethodError(localNoSuchMethodException.getMessage()); &#125; catch (ClassNotFoundException localClassNotFoundException) &#123; throw new NoClassDefFoundError(localClassNotFoundException.getMessage()); &#125; &#125;&#125; 注意:对于从Object中继承的方法，JDK Proxy会把hashCode()、equals()、toString()这三个非接口方法转发给InvocationHandler，其余的Object方法则不会转发 cglib动态代理 cglib动态代理必须实现MethodInterceptor接口 MethodInterceptor接口1234567891011package org.springframework.cglib.proxy;import java.lang.reflect.Method;public interface MethodInterceptor extends Callback &#123; Object intercept(Object var1, Method var2, Object[] var3, MethodProxy var4) throws Throwable; 参数1 代理对象 参数2 方法对象 参数3 方法参数 参数4 方法对应的&#125; 示例12345678910111213141516171819202122232425262728293031323334353637package com.example.ford.proxy;import org.springframework.cglib.proxy.Enhancer;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;import java.lang.reflect.Method;public class CglibProxy implements MethodInterceptor&#123; private Enhancer enhancer = new Enhancer(); public Object getProxy(Class cls)&#123; enhancer.setSuperclass(cls); enhancer.setCallback(this); return enhancer.create(); &#125; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(o.getClass()); System.out.println(\"开始执行 \"+method.getName()); //我们一般使用proxy.invokeSuper(obj,args)方法。这个很好理解，就是执行原始类的方法。还有一个方法proxy.invoke(obj,args)，这是执行生成子类的方法。 //如果传入的obj就是子类的话，会发生内存溢出，因为子类的方法不停地进入intercept方法，而这个方法又去调用子类的方法，两个方法直接循环调用了。 Object returnValue = methodProxy.invokeSuper(o,objects); //Object returnValue = methodProxy.invoke(o,objects); System.out.println(\"结束执行 \"+method.getName()); return returnValue; &#125; public static void main(String[] args)&#123; CglibProxy cglibProxy = new CglibProxy(); RealSubject realSubject = (RealSubject)cglibProxy.getProxy(RealSubject.class); Object returnValue1 = realSubject.sayHello(\"changfeng\"); System.out.println(returnValue1); Object returnValue2 = realSubject.sayGoodBye(); System.out.println(returnValue2); &#125;&#125; 注意：对于从Object中继承的方法，CGLIB代理也会进行代理，如hashCode()、equals()、toString()等，但是getClass()、wait()等方法不会，因为它是final方法，CGLIB无法代理 注意：既然是继承就不得不考虑final的问题。我们知道final类型不能有子类，所以CGLIB不能代理final类型，遇到这种情况会抛出类似如下异常： java.lang.IllegalArgumentException: Cannot subclass final class cglib.HelloConcrete 注意：同样的，final方法是不能重载的，所以也不能通过CGLIB代理，遇到这种情况不会抛异常，而是会跳过final方法只代理其他方法。 源码分析通过以下方式可以生成代理类class文件System.setProperty(DebuggingClassWriter.DEBUG_LOCATION_PROPERTY, “C:\\\\Code\\\\whywhy\\\\target\\\\classes\\\\zzzzzz”) 用jd-gui反编译代理类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460package com.example.ford.proxy;import java.lang.reflect.Method;import org.springframework.cglib.proxy.Callback;import org.springframework.cglib.proxy.Factory;import org.springframework.cglib.proxy.MethodInterceptor;import org.springframework.cglib.proxy.MethodProxy;public class RealSubject$$EnhancerByCGLIB$$6a387257 extends RealSubject implements Factory&#123; private boolean CGLIB$BOUND; public static Object CGLIB$FACTORY_DATA; private static final ThreadLocal CGLIB$THREAD_CALLBACKS; private static final Callback[] CGLIB$STATIC_CALLBACKS; private MethodInterceptor CGLIB$CALLBACK_0; private static Object CGLIB$CALLBACK_FILTER; private static final Method CGLIB$sayHello$0$Method; private static final MethodProxy CGLIB$sayHello$0$Proxy; private static final Object[] CGLIB$emptyArgs; private static final Method CGLIB$sayGoodBye$1$Method; private static final MethodProxy CGLIB$sayGoodBye$1$Proxy; private static final Method CGLIB$equals$2$Method; private static final MethodProxy CGLIB$equals$2$Proxy; private static final Method CGLIB$toString$3$Method; private static final MethodProxy CGLIB$toString$3$Proxy; private static final Method CGLIB$hashCode$4$Method; private static final MethodProxy CGLIB$hashCode$4$Proxy; private static final Method CGLIB$clone$5$Method; private static final MethodProxy CGLIB$clone$5$Proxy; /* Error */ static void CGLIB$STATICHOOK1() &#123; // Byte code: // 0: new 22 java/lang/ThreadLocal // 3: dup // 4: invokespecial 25 java/lang/ThreadLocal:&lt;init&gt; ()V // 7: putstatic 27 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$THREAD_CALLBACKS Ljava/lang/ThreadLocal; // 10: iconst_0 // 11: anewarray 48 java/lang/Object // 14: putstatic 69 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$emptyArgs [Ljava/lang/Object; // 17: ldc -108 // 19: invokestatic 154 java/lang/Class:forName (Ljava/lang/String;)Ljava/lang/Class; // 22: astore_0 // 23: iconst_4 // 24: anewarray 58 java/lang/String // 27: dup // 28: iconst_0 // 29: ldc -101 // 31: aastore // 32: dup // 33: iconst_1 // 34: ldc -100 // 36: aastore // 37: dup // 38: iconst_2 // 39: ldc -99 // 41: aastore // 42: dup // 43: iconst_3 // 44: ldc -98 // 46: aastore // 47: ldc -96 // 49: invokestatic 154 java/lang/Class:forName (Ljava/lang/String;)Ljava/lang/Class; // 52: dup // 53: astore_1 // 54: invokevirtual 164 java/lang/Class:getDeclaredMethods ()[Ljava/lang/reflect/Method; // 57: invokestatic 170 org/springframework/cglib/core/ReflectUtils:findMethods ([Ljava/lang/String;[Ljava/lang/reflect/Method;)[Ljava/lang/reflect/Method; // 60: dup // 61: iconst_0 // 62: aaload // 63: putstatic 46 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$sayHello$0$Method Ljava/lang/reflect/Method; // 66: aload_1 // 67: aload_0 // 68: ldc -100 // 70: ldc -101 // 72: ldc -85 // 74: invokestatic 177 org/springframework/cglib/proxy/MethodProxy:create (Ljava/lang/Class;Ljava/lang/Class;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Lorg/springframework/cglib/proxy/MethodProxy; // 77: putstatic 50 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$sayHello$0$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 80: dup // 81: iconst_1 // 82: aaload // 83: putstatic 67 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$sayGoodBye$1$Method Ljava/lang/reflect/Method; // 86: aload_1 // 87: aload_0 // 88: ldc -98 // 90: ldc -99 // 92: ldc -78 // 94: invokestatic 177 org/springframework/cglib/proxy/MethodProxy:create (Ljava/lang/Class;Ljava/lang/Class;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Lorg/springframework/cglib/proxy/MethodProxy; // 97: putstatic 71 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$sayGoodBye$1$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 100: pop // 101: bipush 8 // 103: anewarray 58 java/lang/String // 106: dup // 107: iconst_0 // 108: ldc -77 // 110: aastore // 111: dup // 112: iconst_1 // 113: ldc -76 // 115: aastore // 116: dup // 117: iconst_2 // 118: ldc -75 // 120: aastore // 121: dup // 122: iconst_3 // 123: ldc -98 // 125: aastore // 126: dup // 127: iconst_4 // 128: ldc -74 // 130: aastore // 131: dup // 132: iconst_5 // 133: ldc -73 // 135: aastore // 136: dup // 137: bipush 6 // 139: ldc -72 // 141: aastore // 142: dup // 143: bipush 7 // 145: ldc -71 // 147: aastore // 148: ldc -69 // 150: invokestatic 154 java/lang/Class:forName (Ljava/lang/String;)Ljava/lang/Class; // 153: dup // 154: astore_1 // 155: invokevirtual 164 java/lang/Class:getDeclaredMethods ()[Ljava/lang/reflect/Method; // 158: invokestatic 170 org/springframework/cglib/core/ReflectUtils:findMethods ([Ljava/lang/String;[Ljava/lang/reflect/Method;)[Ljava/lang/reflect/Method; // 161: dup // 162: iconst_0 // 163: aaload // 164: putstatic 80 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$equals$2$Method Ljava/lang/reflect/Method; // 167: aload_1 // 168: aload_0 // 169: ldc -76 // 171: ldc -77 // 173: ldc -68 // 175: invokestatic 177 org/springframework/cglib/proxy/MethodProxy:create (Ljava/lang/Class;Ljava/lang/Class;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Lorg/springframework/cglib/proxy/MethodProxy; // 178: putstatic 82 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$equals$2$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 181: dup // 182: iconst_1 // 183: aaload // 184: putstatic 96 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$toString$3$Method Ljava/lang/reflect/Method; // 187: aload_1 // 188: aload_0 // 189: ldc -98 // 191: ldc -75 // 193: ldc -67 // 195: invokestatic 177 org/springframework/cglib/proxy/MethodProxy:create (Ljava/lang/Class;Ljava/lang/Class;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Lorg/springframework/cglib/proxy/MethodProxy; // 198: putstatic 98 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$toString$3$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 201: dup // 202: iconst_2 // 203: aaload // 204: putstatic 107 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$hashCode$4$Method Ljava/lang/reflect/Method; // 207: aload_1 // 208: aload_0 // 209: ldc -73 // 211: ldc -74 // 213: ldc -66 // 215: invokestatic 177 org/springframework/cglib/proxy/MethodProxy:create (Ljava/lang/Class;Ljava/lang/Class;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Lorg/springframework/cglib/proxy/MethodProxy; // 218: putstatic 109 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$hashCode$4$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 221: dup // 222: iconst_3 // 223: aaload // 224: putstatic 125 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$clone$5$Method Ljava/lang/reflect/Method; // 227: aload_1 // 228: aload_0 // 229: ldc -71 // 231: ldc -72 // 233: ldc -65 // 235: invokestatic 177 org/springframework/cglib/proxy/MethodProxy:create (Ljava/lang/Class;Ljava/lang/Class;Ljava/lang/String;Ljava/lang/String;Ljava/lang/String;)Lorg/springframework/cglib/proxy/MethodProxy; // 238: putstatic 127 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$clone$5$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 241: pop // 242: return // 243: athrow &#125; final String CGLIB$sayHello$0(String paramString) &#123; return super.sayHello(paramString); &#125; public final String sayHello(String paramString) &#123; MethodInterceptor tmp4_1 = this.CGLIB$CALLBACK_0; if (tmp4_1 == null) &#123; tmp4_1; CGLIB$BIND_CALLBACKS(this); &#125; MethodInterceptor tmp17_14 = this.CGLIB$CALLBACK_0; if (tmp17_14 != null) &#123; return (String)tmp17_14.intercept(this, CGLIB$sayHello$0$Method, new Object[] &#123; paramString &#125;, CGLIB$sayHello$0$Proxy); &#125; return super.sayHello(paramString); &#125; final String CGLIB$sayGoodBye$1() &#123; return super.sayGoodBye(); &#125; public final String sayGoodBye() &#123; MethodInterceptor tmp4_1 = this.CGLIB$CALLBACK_0; if (tmp4_1 == null) &#123; tmp4_1; CGLIB$BIND_CALLBACKS(this); &#125; MethodInterceptor tmp17_14 = this.CGLIB$CALLBACK_0; if (tmp17_14 != null) &#123; return (String)tmp17_14.intercept(this, CGLIB$sayGoodBye$1$Method, CGLIB$emptyArgs, CGLIB$sayGoodBye$1$Proxy); &#125; return super.sayGoodBye(); &#125; final boolean CGLIB$equals$2(Object paramObject) &#123; return super.equals(paramObject); &#125; public final boolean equals(Object paramObject) &#123; MethodInterceptor tmp4_1 = this.CGLIB$CALLBACK_0; if (tmp4_1 == null) &#123; tmp4_1; CGLIB$BIND_CALLBACKS(this); &#125; MethodInterceptor tmp17_14 = this.CGLIB$CALLBACK_0; if (tmp17_14 != null) &#123; Object tmp41_36 = tmp17_14.intercept(this, CGLIB$equals$2$Method, new Object[] &#123; paramObject &#125;, CGLIB$equals$2$Proxy); tmp41_36; return tmp41_36 == null ? false : ((Boolean)tmp41_36).booleanValue(); &#125; return super.equals(paramObject); &#125; final String CGLIB$toString$3() &#123; return super.toString(); &#125; public final String toString() &#123; MethodInterceptor tmp4_1 = this.CGLIB$CALLBACK_0; if (tmp4_1 == null) &#123; tmp4_1; CGLIB$BIND_CALLBACKS(this); &#125; MethodInterceptor tmp17_14 = this.CGLIB$CALLBACK_0; if (tmp17_14 != null) &#123; return (String)tmp17_14.intercept(this, CGLIB$toString$3$Method, CGLIB$emptyArgs, CGLIB$toString$3$Proxy); &#125; return super.toString(); &#125; final int CGLIB$hashCode$4() &#123; return super.hashCode(); &#125; public final int hashCode() &#123; MethodInterceptor tmp4_1 = this.CGLIB$CALLBACK_0; if (tmp4_1 == null) &#123; tmp4_1; CGLIB$BIND_CALLBACKS(this); &#125; MethodInterceptor tmp17_14 = this.CGLIB$CALLBACK_0; if (tmp17_14 != null) &#123; Object tmp36_31 = tmp17_14.intercept(this, CGLIB$hashCode$4$Method, CGLIB$emptyArgs, CGLIB$hashCode$4$Proxy); tmp36_31; return tmp36_31 == null ? 0 : ((Number)tmp36_31).intValue(); &#125; return super.hashCode(); &#125; final Object CGLIB$clone$5() throws CloneNotSupportedException &#123; return super.clone(); &#125; protected final Object clone() throws CloneNotSupportedException &#123; MethodInterceptor tmp4_1 = this.CGLIB$CALLBACK_0; if (tmp4_1 == null) &#123; tmp4_1; CGLIB$BIND_CALLBACKS(this); &#125; MethodInterceptor tmp17_14 = this.CGLIB$CALLBACK_0; if (tmp17_14 != null) &#123; return tmp17_14.intercept(this, CGLIB$clone$5$Method, CGLIB$emptyArgs, CGLIB$clone$5$Proxy); &#125; return super.clone(); &#125; /* Error */ public static MethodProxy CGLIB$findMethodProxy(org.springframework.cglib.core.Signature arg0) &#123; // Byte code: // 0: aload_0 // 1: invokevirtual 130 java/lang/Object:toString ()Ljava/lang/String; // 4: dup // 5: invokevirtual 131 java/lang/Object:hashCode ()I // 8: lookupswitch default:+132-&gt;140, -1816210712:+60-&gt;68, -508378822:+72-&gt;80, 1577955665:+84-&gt;92, 1826985398:+96-&gt;104, 1913648695:+108-&gt;116, 1984935277:+120-&gt;128 // 68: ldc -123 // 70: invokevirtual 134 java/lang/Object:equals (Ljava/lang/Object;)Z // 73: ifeq +68 -&gt; 141 // 76: getstatic 50 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$sayHello$0$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 79: areturn // 80: ldc -120 // 82: invokevirtual 134 java/lang/Object:equals (Ljava/lang/Object;)Z // 85: ifeq +56 -&gt; 141 // 88: getstatic 127 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$clone$5$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 91: areturn // 92: ldc -118 // 94: invokevirtual 134 java/lang/Object:equals (Ljava/lang/Object;)Z // 97: ifeq +44 -&gt; 141 // 100: getstatic 71 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$sayGoodBye$1$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 103: areturn // 104: ldc -116 // 106: invokevirtual 134 java/lang/Object:equals (Ljava/lang/Object;)Z // 109: ifeq +32 -&gt; 141 // 112: getstatic 82 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$equals$2$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 115: areturn // 116: ldc -114 // 118: invokevirtual 134 java/lang/Object:equals (Ljava/lang/Object;)Z // 121: ifeq +20 -&gt; 141 // 124: getstatic 98 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$toString$3$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 127: areturn // 128: ldc -112 // 130: invokevirtual 134 java/lang/Object:equals (Ljava/lang/Object;)Z // 133: ifeq +8 -&gt; 141 // 136: getstatic 109 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$hashCode$4$Proxy Lorg/springframework/cglib/proxy/MethodProxy; // 139: areturn // 140: pop // 141: aconst_null // 142: areturn &#125; public RealSubject$$EnhancerByCGLIB$$6a387257() &#123; CGLIB$BIND_CALLBACKS(this); &#125; public static void CGLIB$SET_THREAD_CALLBACKS(Callback[] paramArrayOfCallback) &#123; CGLIB$THREAD_CALLBACKS.set(paramArrayOfCallback); &#125; public static void CGLIB$SET_STATIC_CALLBACKS(Callback[] paramArrayOfCallback) &#123; CGLIB$STATIC_CALLBACKS = paramArrayOfCallback; &#125; private static final void CGLIB$BIND_CALLBACKS(Object paramObject) &#123; 6a387257 local6a387257 = (6a387257)paramObject; if (!local6a387257.CGLIB$BOUND) &#123; local6a387257.CGLIB$BOUND = true; Object tmp23_20 = CGLIB$THREAD_CALLBACKS.get(); if (tmp23_20 == null) &#123; tmp23_20; CGLIB$STATIC_CALLBACKS; &#125; local6a387257.CGLIB$CALLBACK_0 = (tmp31_28 == null ? tmp31_28 : (MethodInterceptor)((Callback[])tmp23_20)[0]); &#125; &#125; public Object newInstance(Callback[] paramArrayOfCallback) &#123; CGLIB$SET_THREAD_CALLBACKS(paramArrayOfCallback); CGLIB$SET_THREAD_CALLBACKS(null); return new 6a387257(); &#125; public Object newInstance(Callback paramCallback) &#123; CGLIB$SET_THREAD_CALLBACKS(new Callback[] &#123; paramCallback &#125;); CGLIB$SET_THREAD_CALLBACKS(null); return new 6a387257(); &#125; /* Error */ public Object newInstance(Class[] arg1, Object[] arg2, Callback[] arg3) &#123; // Byte code: // 0: aload_3 // 1: invokestatic 210 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$SET_THREAD_CALLBACKS ([Lorg/springframework/cglib/proxy/Callback;)V // 4: new 2 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257 // 7: dup // 8: aload_1 // 9: dup // 10: arraylength // 11: tableswitch default:+24-&gt;35, 0:+17-&gt;28 // 28: pop // 29: invokespecial 211 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:&lt;init&gt; ()V // 32: goto +17 -&gt; 49 // 35: goto +3 -&gt; 38 // 38: pop // 39: new 217 java/lang/IllegalArgumentException // 42: dup // 43: ldc -37 // 45: invokespecial 222 java/lang/IllegalArgumentException:&lt;init&gt; (Ljava/lang/String;)V // 48: athrow // 49: aconst_null // 50: invokestatic 210 com/example/ford/proxy/RealSubject$$EnhancerByCGLIB$$6a387257:CGLIB$SET_THREAD_CALLBACKS ([Lorg/springframework/cglib/proxy/Callback;)V // 53: areturn &#125; public Callback getCallback(int paramInt) &#123; CGLIB$BIND_CALLBACKS(this); switch (paramInt) &#123; case 0: break; &#125; return null; &#125; public void setCallback(int paramInt, Callback paramCallback) &#123; switch (paramInt) &#123; case 0: this.CGLIB$CALLBACK_0 = ((MethodInterceptor)paramCallback); break; &#125; &#125; public Callback[] getCallbacks() &#123; CGLIB$BIND_CALLBACKS(this); return new Callback[] &#123; this.CGLIB$CALLBACK_0 &#125;; &#125; public void setCallbacks(Callback[] paramArrayOfCallback) &#123; this.CGLIB$CALLBACK_0 = ((MethodInterceptor)paramArrayOfCallback[0]); &#125; static &#123;&#125;&#125; 每个被代理的方法都对应一个MethodProxy对象，methodProxy.invokeSuper方法最终调用委托类的add方法 123456789public Object invokeSuper(Object obj, Object[] args) throws Throwable &#123; try &#123; init(); FastClassInfo fci = fastClassInfo; return fci.f2.invoke(fci.i2, obj, args); &#125; catch (InvocationTargetException e) &#123; throw e.getTargetException(); &#125;&#125; 单看invokeSuper方法的实现，似乎看不出委托类add方法调用，在MethodProxy实现中，通过FastClassInfo维护了委托类和代理类的FastClass。 123456private static class FastClassInfo &#123; FastClass f1; FastClass f2; int i1; int i2;&#125; 以sayHello方法的methodProxy为例，f1指向委托类对象，f2指向代理类对象，i1和i2分别是方法sayHello和CGLIB$sayHello$0在对象中索引位置。 FastClass实现机制FastClass其实就是对Class对象进行特殊处理，提出下标概念index，通过索引保存方法的引用信息，将原先的反射调用，转化为方法的直接调用，从而体现所谓的fast，下面通过一个例子了解一下FastClass的实现机制。 1、定义原类 123456789class Test &#123; public void f()&#123; System.out.println(\"f method\"); &#125; public void g()&#123; System.out.println(\"g method\"); &#125;&#125; 2、定义Fast类 123456789101112131415161718192021222324class FastTest &#123; public int getIndex(String signature)&#123; switch(signature.hashCode())&#123; case 3078479: return 1; case 3108270: return 2; &#125; return -1; &#125; public Object invoke(int index, Object o, Object[] ol)&#123; Test t = (Test) o; switch(index)&#123; case 1: t.f(); return null; case 2: t.g(); return null; &#125; return null; &#125;&#125; 在FastTest中有两个方法，getIndex中对Test类的每个方法根据hash建立索引，invoke根据指定的索引，直接调用目标方法，避免了反射调用。所以当调用methodProxy.invokeSuper方法时，实际上是调用代理类的CGLIB$sayHello$0方法，CGLIB$sayHello$0直接调用了委托类的sayHello方法","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2018-02-07T16:25:49.000Z","updated":"2018-02-07T16:25:49.000Z","comments":true,"path":"2018/02/08/hello-world/","link":"","permalink":"https://killgc.github.io/shortfeng/2018/02/08/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}